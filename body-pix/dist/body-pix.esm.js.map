{"version":3,"file":"body-pix.esm.js","sources":["../src/decode_part_map.ts","../src/base_model.ts","../src/mobilenet.ts","../src/keypoints.ts","../src/multi_person/util.ts","../src/multi_person/decode_multiple_masks_cpu.ts","../src/multi_person/decode_multiple_masks_webgl.ts","../src/multi_person/decode_instance_masks.ts","../src/multi_person/max_heap.ts","../src/multi_person/build_part_with_score_queue.ts","../src/multi_person/decode_pose.ts","../src/multi_person/decode_multiple_poses.ts","../src/resnet.ts","../src/saved_models.ts","../src/util.ts","../src/body_pix_model.ts","../src/blur.ts","../src/output_rendering_util.ts","../src/part_channels.ts","../src/version.ts"],"sourcesContent":["/**\r\n * @license\r\n * Copyright 2019 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nimport * as tf from '@tensorflow/tfjs-core';\r\n\r\n/**\r\n * Takes the sigmoid of the part heatmap output and generates a 2d one-hot\r\n * tensor with ones where the part's score has the maximum value.\r\n *\r\n * @param partHeatmapScores\r\n */\r\nfunction toFlattenedOneHotPartMap(partHeatmapScores: tf.Tensor3D): tf.Tensor2D {\r\n  const numParts = partHeatmapScores.shape[2];\r\n  const partMapLocations = partHeatmapScores.argMax(2);\r\n\r\n  const partMapFlattened = partMapLocations.reshape([-1]);\r\n\r\n  return tf.oneHot(partMapFlattened, numParts) as tf.Tensor2D;\r\n}\r\n\r\nfunction clipByMask2d(image: tf.Tensor2D, mask: tf.Tensor2D): tf.Tensor2D {\r\n  return image.mul(mask);\r\n}\r\n\r\n/**\r\n * Takes the sigmoid of the segmentation output, and generates a segmentation\r\n * mask with a 1 or 0 at each pixel where there is a person or not a person. The\r\n * segmentation threshold determines the threshold of a score for a pixel for it\r\n * to be considered part of a person.\r\n * @param segmentScores A 3d-tensor of the sigmoid of the segmentation output.\r\n * @param segmentationThreshold The minimum that segmentation values must have\r\n * to be considered part of the person.  Affects the generation of the\r\n * segmentation mask and the clipping of the colored part image.\r\n *\r\n * @returns A segmentation mask with a 1 or 0 at each pixel where there is a\r\n * person or not a person.\r\n */\r\nexport function toMaskTensor(\r\n    segmentScores: tf.Tensor2D, threshold: number): tf.Tensor2D {\r\n  return tf.tidy(\r\n      () =>\r\n          (segmentScores.greater(tf.scalar(threshold)).toInt() as tf.Tensor2D));\r\n}\r\n\r\n/**\r\n * Takes the sigmoid of the person and part map output, and returns a 2d tensor\r\n * of an image with the corresponding value at each pixel corresponding to the\r\n * part with the highest value. These part ids are clipped by the segmentation\r\n * mask. Wherever the a pixel is clipped by the segmentation mask, its value\r\n * will set to -1, indicating that there is no part in that pixel.\r\n * @param segmentScores A 3d-tensor of the sigmoid of the segmentation output.\r\n * @param partHeatmapScores A 3d-tensor of the sigmoid of the part heatmap\r\n * output. The third dimension corresponds to the part.\r\n *\r\n * @returns A 2d tensor of an image with the corresponding value at each pixel\r\n * corresponding to the part with the highest value. These part ids are clipped\r\n * by the segmentation mask.  It will have values of -1 for pixels that are\r\n * outside of the body and do not have a corresponding part.\r\n */\r\nexport function decodePartSegmentation(\r\n    segmentationMask: tf.Tensor2D,\r\n    partHeatmapScores: tf.Tensor3D): tf.Tensor2D {\r\n  const [partMapHeight, partMapWidth, numParts] = partHeatmapScores.shape;\r\n  return tf.tidy(() => {\r\n    const flattenedMap = toFlattenedOneHotPartMap(partHeatmapScores);\r\n    const partNumbers = tf.range(0, numParts, 1, 'int32').expandDims(1);\r\n\r\n    const partMapFlattened =\r\n        flattenedMap.matMul(partNumbers as tf.Tensor2D).toInt();\r\n\r\n    const partMap = partMapFlattened.reshape([partMapHeight, partMapWidth]);\r\n\r\n    const partMapShiftedUpForClipping = partMap.add(tf.scalar(1, 'int32'));\r\n\r\n    return clipByMask2d(\r\n               partMapShiftedUpForClipping as tf.Tensor2D, segmentationMask)\r\n        .sub(tf.scalar(1, 'int32'));\r\n  });\r\n}\r\n\r\nexport function decodeOnlyPartSegmentation(partHeatmapScores: tf.Tensor3D):\r\n    tf.Tensor2D {\r\n  const [partMapHeight, partMapWidth, numParts] = partHeatmapScores.shape;\r\n  return tf.tidy(() => {\r\n    const flattenedMap = toFlattenedOneHotPartMap(partHeatmapScores);\r\n    const partNumbers = tf.range(0, numParts, 1, 'int32').expandDims(1);\r\n\r\n    const partMapFlattened =\r\n        flattenedMap.matMul(partNumbers as tf.Tensor2D).toInt();\r\n\r\n    return partMapFlattened.reshape([partMapHeight, partMapWidth]);\r\n  });\r\n}\r\n","\r\n/**\r\n * @license\r\n * Copyright 2019 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nimport * as tfconv from '@tensorflow/tfjs-converter';\r\nimport * as tf from '@tensorflow/tfjs-core';\r\nimport {BodyPixOutputStride} from './types';\r\n\r\n/**\r\n * BodyPix supports using various convolution neural network models\r\n * (e.g. ResNet and MobileNetV1) as its underlying base model.\r\n * The following BaseModel interface defines a unified interface for\r\n * creating such BodyPix base models. Currently both MobileNet (in\r\n * ./mobilenet.ts) and ResNet (in ./resnet.ts) implements the BaseModel\r\n * interface. New base models that conform to the BaseModel interface can be\r\n * added to BodyPix.\r\n */\r\nexport abstract class BaseModel {\r\n  constructor(\r\n      protected readonly model: tfconv.GraphModel,\r\n      public readonly outputStride: BodyPixOutputStride) {\r\n    const inputShape =\r\n        this.model.inputs[0].shape as [number, number, number, number];\r\n    tf.util.assert(\r\n        (inputShape[1] === -1) && (inputShape[2] === -1),\r\n        () => `Input shape [${inputShape[1]}, ${inputShape[2]}] ` +\r\n            `must both be equal to or -1`);\r\n  }\r\n\r\n  abstract preprocessInput(input: tf.Tensor3D): tf.Tensor3D;\r\n\r\n  /**\r\n   * Predicts intermediate Tensor representations.\r\n   *\r\n   * @param input The input RGB image of the base model.\r\n   * A Tensor of shape: [`inputResolution`, `inputResolution`, 3].\r\n   *\r\n   * @return A dictionary of base model's intermediate predictions.\r\n   * The returned dictionary should contains the following elements:\r\n   * - heatmapScores: A Tensor3D that represents the keypoint heatmap scores.\r\n   * - offsets: A Tensor3D that represents the offsets.\r\n   * - displacementFwd: A Tensor3D that represents the forward displacement.\r\n   * - displacementBwd: A Tensor3D that represents the backward displacement.\r\n   * - segmentation: A Tensor3D that represents the segmentation of all\r\n   * people.\r\n   * - longOffsets: A Tensor3D that represents the long offsets used for\r\n   * instance grouping.\r\n   * - partHeatmaps: A Tensor3D that represents the body part segmentation.\r\n   */\r\n  predict(input: tf.Tensor3D): {\r\n    heatmapScores: tf.Tensor3D,\r\n    offsets: tf.Tensor3D,\r\n    displacementFwd: tf.Tensor3D,\r\n    displacementBwd: tf.Tensor3D,\r\n    segmentation: tf.Tensor3D,\r\n    partHeatmaps: tf.Tensor3D,\r\n    longOffsets: tf.Tensor3D,\r\n    partOffsets: tf.Tensor3D\r\n  } {\r\n    return tf.tidy(() => {\r\n      const asFloat = this.preprocessInput(input.toFloat());\r\n      const asBatch = asFloat.expandDims(0);\r\n      const results = this.model.predict(asBatch) as tf.Tensor4D[];\r\n      const results3d: tf.Tensor3D[] = results.map(y => y.squeeze([0]));\r\n      const namedResults = this.nameOutputResults(results3d);\r\n\r\n      return {\r\n        heatmapScores: namedResults.heatmap.sigmoid(),\r\n        offsets: namedResults.offsets,\r\n        displacementFwd: namedResults.displacementFwd,\r\n        displacementBwd: namedResults.displacementBwd,\r\n        segmentation: namedResults.segmentation,\r\n        partHeatmaps: namedResults.partHeatmaps,\r\n        longOffsets: namedResults.longOffsets,\r\n        partOffsets: namedResults.partOffsets\r\n      };\r\n    });\r\n  }\r\n\r\n  // Because MobileNet and ResNet predict() methods output a different order for\r\n  // these values, we have a method that needs to be implemented to order them.\r\n  abstract nameOutputResults(results: tf.Tensor3D[]): {\r\n    heatmap: tf.Tensor3D,\r\n    offsets: tf.Tensor3D,\r\n    displacementFwd: tf.Tensor3D,\r\n    displacementBwd: tf.Tensor3D,\r\n    segmentation: tf.Tensor3D,\r\n    partHeatmaps: tf.Tensor3D,\r\n    longOffsets: tf.Tensor3D,\r\n    partOffsets: tf.Tensor3D\r\n  };\r\n\r\n  /**\r\n   * Releases the CPU and GPU memory allocated by the model.\r\n   */\r\n  dispose() {\r\n    this.model.dispose();\r\n  }\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2019 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nimport * as tf from '@tensorflow/tfjs-core';\r\n\r\nimport {BaseModel} from './base_model';\r\n\r\nexport class MobileNet extends BaseModel {\r\n  preprocessInput(input: tf.Tensor3D): tf.Tensor3D {\r\n    // Normalize the pixels [0, 255] to be between [-1, 1].\r\n    return tf.tidy(() => tf.div(input, 127.5).sub(1.0));\r\n  }\r\n\r\n  nameOutputResults(results: tf.Tensor3D[]) {\r\n    const [\r\n      offsets,\r\n      segmentation,\r\n      partHeatmaps,\r\n      longOffsets,\r\n      heatmap,\r\n      displacementFwd,\r\n      displacementBwd,\r\n      partOffsets,\r\n  ] = results;\r\n    return {\r\n      offsets,\r\n      segmentation,\r\n      partHeatmaps,\r\n      longOffsets,\r\n      heatmap,\r\n      displacementFwd,\r\n      displacementBwd,\r\n      partOffsets\r\n    };\r\n  }\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2019 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nexport type Tuple<T> = [T, T];\r\nexport type StringTuple = Tuple<string>;\r\nexport type NumberTuple = Tuple<number>;\r\n\r\nexport const PART_NAMES = [\r\n  'nose', 'leftEye', 'rightEye', 'leftEar', 'rightEar', 'leftShoulder',\r\n  'rightShoulder', 'leftElbow', 'rightElbow', 'leftWrist', 'rightWrist',\r\n  'leftHip', 'rightHip', 'leftKnee', 'rightKnee', 'leftAnkle', 'rightAnkle'\r\n];\r\n\r\nexport const NUM_KEYPOINTS = PART_NAMES.length;\r\n\r\nexport interface NumberDict {\r\n  [jointName: string]: number;\r\n}\r\n\r\nexport const PART_IDS =\r\n    PART_NAMES.reduce((result: NumberDict, jointName, i): NumberDict => {\r\n      result[jointName] = i;\r\n      return result;\r\n    }, {}) as NumberDict;\r\n\r\nconst CONNECTED_PART_NAMES: StringTuple[] = [\r\n  ['leftHip', 'leftShoulder'], ['leftElbow', 'leftShoulder'],\r\n  ['leftElbow', 'leftWrist'], ['leftHip', 'leftKnee'],\r\n  ['leftKnee', 'leftAnkle'], ['rightHip', 'rightShoulder'],\r\n  ['rightElbow', 'rightShoulder'], ['rightElbow', 'rightWrist'],\r\n  ['rightHip', 'rightKnee'], ['rightKnee', 'rightAnkle'],\r\n  ['leftShoulder', 'rightShoulder'], ['leftHip', 'rightHip']\r\n];\r\n\r\n/*\r\n * Define the skeleton. This defines the parent->child relationships of our\r\n * tree. Arbitrarily this defines the nose as the root of the tree, however\r\n * since we will infer the displacement for both parent->child and\r\n * child->parent, we can define the tree root as any node.\r\n */\r\nexport const POSE_CHAIN: StringTuple[] = [\r\n  ['nose', 'leftEye'], ['leftEye', 'leftEar'], ['nose', 'rightEye'],\r\n  ['rightEye', 'rightEar'], ['nose', 'leftShoulder'],\r\n  ['leftShoulder', 'leftElbow'], ['leftElbow', 'leftWrist'],\r\n  ['leftShoulder', 'leftHip'], ['leftHip', 'leftKnee'],\r\n  ['leftKnee', 'leftAnkle'], ['nose', 'rightShoulder'],\r\n  ['rightShoulder', 'rightElbow'], ['rightElbow', 'rightWrist'],\r\n  ['rightShoulder', 'rightHip'], ['rightHip', 'rightKnee'],\r\n  ['rightKnee', 'rightAnkle']\r\n];\r\n\r\nexport const CONNECTED_PART_INDICES = CONNECTED_PART_NAMES.map(\r\n    ([jointNameA, jointNameB]) =>\r\n        ([PART_IDS[jointNameA], PART_IDS[jointNameB]]));\r\n","/**\r\n * @license\r\n * Copyright 2019 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nimport {NUM_KEYPOINTS} from '../keypoints';\r\nimport {Padding, Part, TensorBuffer3D, Vector2D} from '../types';\r\n\r\nexport function getScale(\r\n    [height, width]: [number, number],\r\n    [inputResolutionY, inputResolutionX]: [number, number],\r\n    padding: Padding): [number, number] {\r\n  const {top: padT, bottom: padB, left: padL, right: padR} = padding;\r\n  const scaleY = inputResolutionY / (padT + padB + height);\r\n  const scaleX = inputResolutionX / (padL + padR + width);\r\n  return [scaleX, scaleY];\r\n}\r\n\r\nexport function getOffsetPoint(\r\n    y: number, x: number, keypoint: number, offsets: TensorBuffer3D): Vector2D {\r\n  return {\r\n    y: offsets.get(y, x, keypoint),\r\n    x: offsets.get(y, x, keypoint + NUM_KEYPOINTS)\r\n  };\r\n}\r\n\r\nexport function getImageCoords(\r\n    part: Part, outputStride: number, offsets: TensorBuffer3D): Vector2D {\r\n  const {heatmapY, heatmapX, id: keypoint} = part;\r\n  const {y, x} = getOffsetPoint(heatmapY, heatmapX, keypoint, offsets);\r\n  return {\r\n    x: part.heatmapX * outputStride + x,\r\n    y: part.heatmapY * outputStride + y\r\n  };\r\n}\r\n\r\nexport function fillArray<T>(element: T, size: number): T[] {\r\n  const result: T[] = new Array(size);\r\n\r\n  for (let i = 0; i < size; i++) {\r\n    result[i] = element;\r\n  }\r\n\r\n  return result;\r\n}\r\n\r\nexport function clamp(a: number, min: number, max: number): number {\r\n  if (a < min) {\r\n    return min;\r\n  }\r\n  if (a > max) {\r\n    return max;\r\n  }\r\n  return a;\r\n}\r\n\r\nexport function squaredDistance(\r\n    y1: number, x1: number, y2: number, x2: number): number {\r\n  const dy = y2 - y1;\r\n  const dx = x2 - x1;\r\n  return dy * dy + dx * dx;\r\n}\r\n\r\nexport function addVectors(a: Vector2D, b: Vector2D): Vector2D {\r\n  return {x: a.x + b.x, y: a.y + b.y};\r\n}\r\n\r\nexport function clampVector(a: Vector2D, min: number, max: number): Vector2D {\r\n  return {y: clamp(a.y, min, max), x: clamp(a.x, min, max)};\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2019 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nimport {NUM_KEYPOINTS} from '../keypoints';\r\nimport {Padding, Pose} from '../types';\r\n\r\nimport {getScale} from './util';\r\n\r\ninterface Pair {\r\n  x: number;\r\n  y: number;\r\n}\r\n\r\nfunction computeDistance(embedding: Pair[], pose: Pose, minPartScore = 0.3) {\r\n  let distance = 0.0;\r\n  let numKpt = 0;\r\n  for (let p = 0; p < embedding.length; p++) {\r\n    if (pose.keypoints[p].score > minPartScore) {\r\n      numKpt += 1;\r\n      distance += (embedding[p].x - pose.keypoints[p].position.x) ** 2 +\r\n          (embedding[p].y - pose.keypoints[p].position.y) ** 2;\r\n    }\r\n  }\r\n  if (numKpt === 0) {\r\n    distance = Infinity;\r\n  } else {\r\n    distance = distance / numKpt;\r\n  }\r\n  return distance;\r\n}\r\n\r\nfunction convertToPositionInOuput(\r\n    position: Pair, [padT, padL]: [number, number],\r\n    [scaleX, scaleY]: [number, number], stride: number): Pair {\r\n  const y = Math.round(((padT + position.y + 1.0) * scaleY - 1.0) / stride);\r\n  const x = Math.round(((padL + position.x + 1.0) * scaleX - 1.0) / stride);\r\n  return {x, y};\r\n}\r\n\r\nfunction getEmbedding(\r\n    location: Pair, keypointIndex: number,\r\n    convertToPosition: (pair: Pair) => Pair, outputResolutionX: number,\r\n    longOffsets: Float32Array, refineSteps: number,\r\n    [height, width]: [number, number]): Pair {\r\n  const newLocation = convertToPosition(location);\r\n\r\n  const nn = newLocation.y * outputResolutionX + newLocation.x;\r\n  let dy = longOffsets[NUM_KEYPOINTS * (2 * nn) + keypointIndex];\r\n  let dx = longOffsets[NUM_KEYPOINTS * (2 * nn + 1) + keypointIndex];\r\n  let y = location.y + dy;\r\n  let x = location.x + dx;\r\n  for (let t = 0; t < refineSteps; t++) {\r\n    y = Math.min(y, height - 1);\r\n    x = Math.min(x, width - 1);\r\n    const newPos = convertToPosition({x, y});\r\n    const nn = newPos.y * outputResolutionX + newPos.x;\r\n    dy = longOffsets[NUM_KEYPOINTS * (2 * nn) + keypointIndex];\r\n    dx = longOffsets[NUM_KEYPOINTS * (2 * nn + 1) + keypointIndex];\r\n    y = y + dy;\r\n    x = x + dx;\r\n  }\r\n\r\n  return {x, y};\r\n}\r\n\r\nfunction matchEmbeddingToInstance(\r\n    location: Pair, longOffsets: Float32Array, poses: Pose[],\r\n    numKptForMatching: number, [padT, padL]: [number, number],\r\n    [scaleX, scaleY]: [number, number], outputResolutionX: number,\r\n    [height, width]: [number, number], stride: number,\r\n    refineSteps: number): number {\r\n  const embed: Pair[] = [];\r\n  const convertToPosition = (pair: Pair) =>\r\n      convertToPositionInOuput(pair, [padT, padL], [scaleX, scaleY], stride);\r\n\r\n  for (let keypointsIndex = 0; keypointsIndex < numKptForMatching;\r\n       keypointsIndex++) {\r\n    const embedding = getEmbedding(\r\n        location, keypointsIndex, convertToPosition, outputResolutionX,\r\n        longOffsets, refineSteps, [height, width]);\r\n\r\n    embed.push(embedding);\r\n  }\r\n\r\n  let kMin = -1;\r\n  let kMinDist = Infinity;\r\n  for (let k = 0; k < poses.length; k++) {\r\n    const dist = computeDistance(embed, poses[k]);\r\n    if (dist < kMinDist) {\r\n      kMin = k;\r\n      kMinDist = dist;\r\n    }\r\n  }\r\n  return kMin;\r\n}\r\n\r\nfunction getOutputResolution(\r\n    [inputResolutionY, inputResolutionX]: [number, number],\r\n    stride: number): [number, number] {\r\n  const outputResolutionX = Math.round((inputResolutionX - 1.0) / stride + 1.0);\r\n  const outputResolutionY = Math.round((inputResolutionY - 1.0) / stride + 1.0);\r\n  return [outputResolutionX, outputResolutionY];\r\n}\r\n\r\nexport function decodeMultipleMasksCPU(\r\n    segmentation: Uint8Array, longOffsets: Float32Array,\r\n    posesAboveScore: Pose[], height: number, width: number, stride: number,\r\n    [inHeight, inWidth]: [number, number], padding: Padding,\r\n    refineSteps: number, numKptForMatching = 5): Uint8Array[] {\r\n  const dataArrays =\r\n      posesAboveScore.map(x => new Uint8Array(height * width).fill(0));\r\n\r\n  const {top: padT, left: padL} = padding;\r\n\r\n  const [scaleX, scaleY] =\r\n      getScale([height, width], [inHeight, inWidth], padding);\r\n  const [outputResolutionX, ] =\r\n    getOutputResolution([inHeight, inWidth], stride);\r\n  for (let i = 0; i < height; i += 1) {\r\n    for (let j = 0; j < width; j += 1) {\r\n      const n = i * width + j;\r\n      const prob = segmentation[n];\r\n      if (prob === 1) {\r\n        const kMin = matchEmbeddingToInstance(\r\n            {x: j, y: i}, longOffsets, posesAboveScore, numKptForMatching,\r\n            [padT, padL], [scaleX, scaleY], outputResolutionX, [height, width],\r\n            stride, refineSteps);\r\n        if (kMin >= 0) {\r\n          dataArrays[kMin][n] = 1;\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  return dataArrays;\r\n}\r\n\r\nexport function decodeMultiplePartMasksCPU(\r\n    segmentation: Uint8Array, longOffsets: Float32Array,\r\n    partSegmentaion: Uint8Array, posesAboveScore: Pose[], height: number,\r\n    width: number, stride: number, [inHeight, inWidth]: [number, number],\r\n    padding: Padding, refineSteps: number,\r\n    numKptForMatching = 5): Int32Array[] {\r\n  const dataArrays =\r\n      posesAboveScore.map(x => new Int32Array(height * width).fill(-1));\r\n\r\n  const {top: padT, left: padL} = padding;\r\n\r\n  const [scaleX, scaleY] =\r\n      getScale([height, width], [inHeight, inWidth], padding);\r\n  const [outputResolutionX, ] =\r\n    getOutputResolution([inHeight, inWidth], stride);\r\n\r\n  for (let i = 0; i < height; i += 1) {\r\n    for (let j = 0; j < width; j += 1) {\r\n      const n = i * width + j;\r\n      const prob = segmentation[n];\r\n      if (prob === 1) {\r\n        const kMin = matchEmbeddingToInstance(\r\n            {x: j, y: i}, longOffsets, posesAboveScore, numKptForMatching,\r\n            [padT, padL], [scaleX, scaleY], outputResolutionX, [height, width],\r\n            stride, refineSteps);\r\n        if (kMin >= 0) {\r\n          dataArrays[kMin][n] = partSegmentaion[n];\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  return dataArrays;\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2019 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nimport * as tf from '@tensorflow/tfjs-core';\r\n\r\nimport {NUM_KEYPOINTS} from '../keypoints';\r\nimport {Padding, Pose} from '../types';\r\nimport {getScale} from './util';\r\n\r\nexport function decodeMultipleMasksWebGl(\r\n    segmentation: tf.Tensor2D, longOffsets: tf.Tensor3D,\r\n    posesAboveScore: Pose[], height: number, width: number, stride: number,\r\n    [inHeight, inWidth]: [number, number], padding: Padding,\r\n    refineSteps: number, minKptScore: number,\r\n    maxNumPeople: number): tf.Tensor2D {\r\n  // The height/width of the image/canvas itself.\r\n  const [origHeight, origWidth] = segmentation.shape;\r\n  // The height/width of the output of the model.\r\n  const [outHeight, outWidth] = longOffsets.shape.slice(0, 2);\r\n\r\n  const shapedLongOffsets: tf.Tensor4D =\r\n      longOffsets.reshape([outHeight, outWidth, 2, NUM_KEYPOINTS]);\r\n\r\n  // Make pose tensor of shape [MAX_NUM_PEOPLE, NUM_KEYPOINTS, 3] where\r\n  // the last 3 coordinates correspond to the score, h and w coordinate of that\r\n  // keypoint.\r\n  const poseVals = new Float32Array(maxNumPeople * NUM_KEYPOINTS * 3).fill(0.0);\r\n  for (let i = 0; i < posesAboveScore.length; i++) {\r\n    const poseOffset = i * NUM_KEYPOINTS * 3;\r\n    const pose = posesAboveScore[i];\r\n    for (let kp = 0; kp < NUM_KEYPOINTS; kp++) {\r\n      const keypoint = pose.keypoints[kp];\r\n      const offset = poseOffset + kp * 3;\r\n      poseVals[offset] = keypoint.score;\r\n      poseVals[offset + 1] = keypoint.position.y;\r\n      poseVals[offset + 2] = keypoint.position.x;\r\n    }\r\n  }\r\n\r\n  const [scaleX, scaleY] =\r\n      getScale([height, width], [inHeight, inWidth], padding);\r\n\r\n  const posesTensor = tf.tensor(poseVals, [maxNumPeople, NUM_KEYPOINTS, 3]);\r\n\r\n  const {top: padT, left: padL} = padding;\r\n\r\n  const program: tf.webgl.GPGPUProgram = {\r\n    variableNames: ['segmentation', 'longOffsets', 'poses'],\r\n    outputShape: [origHeight, origWidth],\r\n    userCode: `\r\n    int convertToPositionInOutput(int pos, int pad, float scale, int stride) {\r\n      return round(((float(pos + pad) + 1.0) * scale - 1.0) / float(stride));\r\n    }\r\n\r\n    float convertToPositionInOutputFloat(\r\n        int pos, int pad, float scale, int stride) {\r\n      return ((float(pos + pad) + 1.0) * scale - 1.0) / float(stride);\r\n    }\r\n\r\n    float dist(float x1, float y1, float x2, float y2) {\r\n      return pow(x1 - x2, 2.0) + pow(y1 - y2, 2.0);\r\n    }\r\n\r\n    float sampleLongOffsets(float h, float w, int d, int k) {\r\n      float fh = fract(h);\r\n      float fw = fract(w);\r\n      int clH = int(ceil(h));\r\n      int clW = int(ceil(w));\r\n      int flH = int(floor(h));\r\n      int flW = int(floor(w));\r\n      float o11 = getLongOffsets(flH, flW, d, k);\r\n      float o12 = getLongOffsets(flH, clW, d, k);\r\n      float o21 = getLongOffsets(clH, flW, d, k);\r\n      float o22 = getLongOffsets(clH, clW, d, k);\r\n      float o1 = mix(o11, o12, fw);\r\n      float o2 = mix(o21, o22, fw);\r\n      return mix(o1, o2, fh);\r\n    }\r\n\r\n    int findNearestPose(int h, int w) {\r\n      float prob = getSegmentation(h, w);\r\n      if (prob < 1.0) {\r\n        return -1;\r\n      }\r\n\r\n      // Done(Tyler): convert from output space h/w to strided space.\r\n      float stridedH = convertToPositionInOutputFloat(\r\n        h, ${padT}, ${scaleY}, ${stride});\r\n      float stridedW = convertToPositionInOutputFloat(\r\n        w, ${padL}, ${scaleX}, ${stride});\r\n\r\n      float minDist = 1000000.0;\r\n      int iMin = -1;\r\n      for (int i = 0; i < ${maxNumPeople}; i++) {\r\n        float curDistSum = 0.0;\r\n        int numKpt = 0;\r\n        for (int k = 0; k < ${NUM_KEYPOINTS}; k++) {\r\n          float dy = sampleLongOffsets(stridedH, stridedW, 0, k);\r\n          float dx = sampleLongOffsets(stridedH, stridedW, 1, k);\r\n\r\n          float y = float(h) + dy;\r\n          float x = float(w) + dx;\r\n\r\n          for (int s = 0; s < ${refineSteps}; s++) {\r\n            int yRounded = round(min(y, float(${height - 1.0})));\r\n            int xRounded = round(min(x, float(${width - 1.0})));\r\n\r\n            float yStrided = convertToPositionInOutputFloat(\r\n              yRounded, ${padT}, ${scaleY}, ${stride});\r\n            float xStrided = convertToPositionInOutputFloat(\r\n              xRounded, ${padL}, ${scaleX}, ${stride});\r\n\r\n            float dy = sampleLongOffsets(yStrided, xStrided, 0, k);\r\n            float dx = sampleLongOffsets(yStrided, xStrided, 1, k);\r\n\r\n            y = y + dy;\r\n            x = x + dx;\r\n          }\r\n\r\n          float poseScore = getPoses(i, k, 0);\r\n          float poseY = getPoses(i, k, 1);\r\n          float poseX = getPoses(i, k, 2);\r\n          if (poseScore > ${minKptScore}) {\r\n            numKpt = numKpt + 1;\r\n            curDistSum = curDistSum + dist(x, y, poseX, poseY);\r\n          }\r\n        }\r\n        if (numKpt > 0 && curDistSum / float(numKpt) < minDist) {\r\n          minDist = curDistSum / float(numKpt);\r\n          iMin = i;\r\n        }\r\n      }\r\n      return iMin;\r\n    }\r\n\r\n    void main() {\r\n        ivec2 coords = getOutputCoords();\r\n        int nearestPose = findNearestPose(coords[0], coords[1]);\r\n        setOutput(float(nearestPose));\r\n      }\r\n  `\r\n  };\r\n  const webglBackend = tf.backend() as tf.webgl.MathBackendWebGL;\r\n  return webglBackend.compileAndRun(\r\n      program, [segmentation, shapedLongOffsets, posesTensor]);\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2019 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nimport * as tf from '@tensorflow/tfjs-core';\r\nimport {getBackend} from '@tensorflow/tfjs-core';\r\n\r\nimport {Padding, PartSegmentation, PersonSegmentation, Pose} from '../types';\r\n\r\nimport {decodeMultipleMasksCPU, decodeMultiplePartMasksCPU} from './decode_multiple_masks_cpu';\r\nimport {decodeMultipleMasksWebGl} from './decode_multiple_masks_webgl';\r\n\r\nexport function toPersonKSegmentation(\r\n    segmentation: tf.Tensor2D, k: number): tf.Tensor2D {\r\n  return tf.tidy(\r\n      () => (segmentation.equal(tf.scalar(k)).toInt() as tf.Tensor2D));\r\n}\r\n\r\nexport function toPersonKPartSegmentation(\r\n    segmentation: tf.Tensor2D, bodyParts: tf.Tensor2D, k: number): tf.Tensor2D {\r\n  return tf.tidy(\r\n      () => segmentation.equal(tf.scalar(k))\r\n                .toInt()\r\n                .mul(bodyParts.add(1))\r\n                .sub(1));\r\n}\r\n\r\nfunction isWebGlBackend() {\r\n  return getBackend() === 'webgl';\r\n}\r\n\r\nexport async function decodePersonInstanceMasks(\r\n    segmentation: tf.Tensor2D, longOffsets: tf.Tensor3D, poses: Pose[],\r\n    height: number, width: number, stride: number,\r\n    [inHeight, inWidth]: [number, number], padding: Padding, minPoseScore = 0.2,\r\n    refineSteps = 8, minKeypointScore = 0.3,\r\n    maxNumPeople = 10): Promise<PersonSegmentation[]> {\r\n  // Filter out poses with smaller score.\r\n  const posesAboveScore = poses.filter(pose => pose.score >= minPoseScore);\r\n\r\n  let personSegmentationsData: Uint8Array[];\r\n\r\n  if (isWebGlBackend()) {\r\n    const personSegmentations = tf.tidy(() => {\r\n      const masksTensor = decodeMultipleMasksWebGl(\r\n          segmentation, longOffsets, posesAboveScore, height, width, stride,\r\n          [inHeight, inWidth], padding, refineSteps, minKeypointScore,\r\n          maxNumPeople);\r\n\r\n      return posesAboveScore.map(\r\n          (_, k) => toPersonKSegmentation(masksTensor, k));\r\n    });\r\n\r\n    personSegmentationsData =\r\n        (await Promise.all(personSegmentations.map(mask => mask.data())) as\r\n         Uint8Array[]);\r\n\r\n    personSegmentations.forEach(x => x.dispose());\r\n  } else {\r\n    const segmentationsData = await segmentation.data() as Uint8Array;\r\n    const longOffsetsData = await longOffsets.data() as Float32Array;\r\n\r\n    personSegmentationsData = decodeMultipleMasksCPU(\r\n        segmentationsData, longOffsetsData, posesAboveScore, height, width,\r\n        stride, [inHeight, inWidth], padding, refineSteps);\r\n  }\r\n\r\n  return personSegmentationsData.map(\r\n      (data, i) => ({data, pose: posesAboveScore[i], width, height}));\r\n}\r\n\r\nexport async function decodePersonInstancePartMasks(\r\n    segmentation: tf.Tensor2D, longOffsets: tf.Tensor3D,\r\n    partSegmentation: tf.Tensor2D, poses: Pose[], height: number, width: number,\r\n    stride: number, [inHeight, inWidth]: [number, number], padding: Padding,\r\n    minPoseScore = 0.2, refineSteps = 8, minKeypointScore = 0.3,\r\n    maxNumPeople = 10): Promise<PartSegmentation[]> {\r\n  const posesAboveScore = poses.filter(pose => pose.score >= minPoseScore);\r\n\r\n  let partSegmentationsByPersonData: Int32Array[];\r\n\r\n  if (isWebGlBackend()) {\r\n    const partSegmentations = tf.tidy(() => {\r\n      const masksTensor = decodeMultipleMasksWebGl(\r\n          segmentation, longOffsets, posesAboveScore, height, width, stride,\r\n          [inHeight, inWidth], padding, refineSteps, minKeypointScore,\r\n          maxNumPeople);\r\n\r\n      return posesAboveScore.map(\r\n          (_, k) =>\r\n              toPersonKPartSegmentation(masksTensor, partSegmentation, k));\r\n    });\r\n\r\n    partSegmentationsByPersonData =\r\n        (await Promise.all(partSegmentations.map(x => x.data()))) as\r\n        Int32Array[];\r\n\r\n    partSegmentations.forEach(x => x.dispose());\r\n  } else {\r\n    const segmentationsData = await segmentation.data() as Uint8Array;\r\n    const longOffsetsData = await longOffsets.data() as Float32Array;\r\n    const partSegmentaionData = await partSegmentation.data() as Uint8Array;\r\n\r\n    partSegmentationsByPersonData = decodeMultiplePartMasksCPU(\r\n        segmentationsData, longOffsetsData, partSegmentaionData,\r\n        posesAboveScore, height, width, stride, [inHeight, inWidth], padding,\r\n        refineSteps);\r\n  }\r\n\r\n  return partSegmentationsByPersonData.map(\r\n      (data, k) => ({pose: posesAboveScore[k], data, height, width}));\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2019 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\n// algorithm based on Coursera Lecture from Algorithms, Part 1:\r\n// https://www.coursera.org/learn/algorithms-part1/lecture/ZjoSM/heapsort\r\n\r\nfunction half(k: number) {\r\n  return Math.floor(k / 2);\r\n}\r\n\r\nexport class MaxHeap<T> {\r\n  private priorityQueue: T[];\r\n  private numberOfElements: number;\r\n  private getElementValue: (element: T) => number;\r\n\r\n  constructor(maxSize: number, getElementValue: (element: T) => number) {\r\n    this.priorityQueue = new Array(maxSize);\r\n    this.numberOfElements = -1;\r\n    this.getElementValue = getElementValue;\r\n  }\r\n\r\n  public enqueue(x: T): void {\r\n    this.priorityQueue[++this.numberOfElements] = x;\r\n    this.swim(this.numberOfElements);\r\n  }\r\n\r\n  public dequeue(): T {\r\n    const max = this.priorityQueue[0];\r\n    this.exchange(0, this.numberOfElements--);\r\n    this.sink(0);\r\n    this.priorityQueue[this.numberOfElements + 1] = null;\r\n    return max;\r\n  }\r\n\r\n  public empty(): boolean {\r\n    return this.numberOfElements === -1;\r\n  }\r\n\r\n  public size(): number {\r\n    return this.numberOfElements + 1;\r\n  }\r\n\r\n  public all(): T[] {\r\n    return this.priorityQueue.slice(0, this.numberOfElements + 1);\r\n  }\r\n\r\n  public max(): T {\r\n    return this.priorityQueue[0];\r\n  }\r\n\r\n  private swim(k: number): void {\r\n    while (k > 0 && this.less(half(k), k)) {\r\n      this.exchange(k, half(k));\r\n      k = half(k);\r\n    }\r\n  }\r\n\r\n  private sink(k: number): void {\r\n    while (2 * k <= this.numberOfElements) {\r\n      let j = 2 * k;\r\n      if (j < this.numberOfElements && this.less(j, j + 1)) {\r\n        j++;\r\n      }\r\n      if (!this.less(k, j)) {\r\n        break;\r\n      }\r\n      this.exchange(k, j);\r\n      k = j;\r\n    }\r\n  }\r\n\r\n  private getValueAt(i: number): number {\r\n    return this.getElementValue(this.priorityQueue[i]);\r\n  }\r\n\r\n  private less(i: number, j: number): boolean {\r\n    return this.getValueAt(i) < this.getValueAt(j);\r\n  }\r\n\r\n  private exchange(i: number, j: number): void {\r\n    const t = this.priorityQueue[i];\r\n    this.priorityQueue[i] = this.priorityQueue[j];\r\n    this.priorityQueue[j] = t;\r\n  }\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2019 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nimport {PartWithScore, TensorBuffer3D} from '../types';\r\n\r\nimport {MaxHeap} from './max_heap';\r\n\r\nfunction scoreIsMaximumInLocalWindow(\r\n    keypointId: number, score: number, heatmapY: number, heatmapX: number,\r\n    localMaximumRadius: number, scores: TensorBuffer3D): boolean {\r\n  const [height, width] = scores.shape;\r\n\r\n  let localMaximum = true;\r\n  const yStart = Math.max(heatmapY - localMaximumRadius, 0);\r\n  const yEnd = Math.min(heatmapY + localMaximumRadius + 1, height);\r\n  for (let yCurrent = yStart; yCurrent < yEnd; ++yCurrent) {\r\n    const xStart = Math.max(heatmapX - localMaximumRadius, 0);\r\n    const xEnd = Math.min(heatmapX + localMaximumRadius + 1, width);\r\n    for (let xCurrent = xStart; xCurrent < xEnd; ++xCurrent) {\r\n      if (scores.get(yCurrent, xCurrent, keypointId) > score) {\r\n        localMaximum = false;\r\n        break;\r\n      }\r\n    }\r\n    if (!localMaximum) {\r\n      break;\r\n    }\r\n  }\r\n\r\n  return localMaximum;\r\n}\r\n\r\n/**\r\n * Builds a priority queue with part candidate positions for a specific image in\r\n * the batch. For this we find all local maxima in the score maps with score\r\n * values above a threshold. We create a single priority queue across all parts.\r\n */\r\nexport function buildPartWithScoreQueue(\r\n    scoreThreshold: number, localMaximumRadius: number,\r\n    scores: TensorBuffer3D): MaxHeap<PartWithScore> {\r\n  const [height, width, numKeypoints] = scores.shape;\r\n\r\n  const queue = new MaxHeap<PartWithScore>(\r\n      height * width * numKeypoints, ({score}) => score);\r\n\r\n  for (let heatmapY = 0; heatmapY < height; ++heatmapY) {\r\n    for (let heatmapX = 0; heatmapX < width; ++heatmapX) {\r\n      for (let keypointId = 0; keypointId < numKeypoints; ++keypointId) {\r\n        const score = scores.get(heatmapY, heatmapX, keypointId);\r\n\r\n        // Only consider parts with score greater or equal to threshold as\r\n        // root candidates.\r\n        if (score < scoreThreshold) {\r\n          continue;\r\n        }\r\n\r\n        // Only consider keypoints whose score is maximum in a local window.\r\n        if (scoreIsMaximumInLocalWindow(\r\n                keypointId, score, heatmapY, heatmapX, localMaximumRadius,\r\n                scores)) {\r\n          queue.enqueue({score, part: {heatmapY, heatmapX, id: keypointId}});\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  return queue;\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2019 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nimport {NumberTuple, PART_IDS, PART_NAMES, POSE_CHAIN} from '../keypoints';\r\nimport {Keypoint, PartWithScore, TensorBuffer3D, Vector2D} from '../types';\r\n\r\nimport {clamp, getOffsetPoint} from './util';\r\nimport {addVectors, getImageCoords} from './util';\r\n\r\nconst parentChildrenTuples: NumberTuple[] = POSE_CHAIN.map(\r\n    ([parentJoinName, childJoinName]): NumberTuple =>\r\n        ([PART_IDS[parentJoinName], PART_IDS[childJoinName]]));\r\n\r\nconst parentToChildEdges: number[] =\r\n    parentChildrenTuples.map(([, childJointId]) => childJointId);\r\n\r\nconst childToParentEdges: number[] =\r\n    parentChildrenTuples.map(([\r\n                               parentJointId,\r\n                             ]) => parentJointId);\r\n\r\nfunction getDisplacement(\r\n    edgeId: number, point: Vector2D, displacements: TensorBuffer3D): Vector2D {\r\n  const numEdges = displacements.shape[2] / 2;\r\n  return {\r\n    y: displacements.get(point.y, point.x, edgeId),\r\n    x: displacements.get(point.y, point.x, numEdges + edgeId)\r\n  };\r\n}\r\n\r\nfunction getStridedIndexNearPoint(\r\n    point: Vector2D, outputStride: number, height: number,\r\n    width: number): Vector2D {\r\n  return {\r\n    y: clamp(Math.round(point.y / outputStride), 0, height - 1),\r\n    x: clamp(Math.round(point.x / outputStride), 0, width - 1)\r\n  };\r\n}\r\n\r\n/**\r\n * We get a new keypoint along the `edgeId` for the pose instance, assuming\r\n * that the position of the `idSource` part is already known. For this, we\r\n * follow the displacement vector from the source to target part (stored in\r\n * the `i`-t channel of the displacement tensor). The displaced keypoint\r\n * vector is refined using the offset vector by `offsetRefineStep` times.\r\n */\r\nfunction traverseToTargetKeypoint(\r\n    edgeId: number, sourceKeypoint: Keypoint, targetKeypointId: number,\r\n    scoresBuffer: TensorBuffer3D, offsets: TensorBuffer3D, outputStride: number,\r\n    displacements: TensorBuffer3D, offsetRefineStep = 2): Keypoint {\r\n  const [height, width] = scoresBuffer.shape;\r\n\r\n  // Nearest neighbor interpolation for the source->target displacements.\r\n  const sourceKeypointIndices = getStridedIndexNearPoint(\r\n      sourceKeypoint.position, outputStride, height, width);\r\n\r\n  const displacement =\r\n      getDisplacement(edgeId, sourceKeypointIndices, displacements);\r\n\r\n  const displacedPoint = addVectors(sourceKeypoint.position, displacement);\r\n  let targetKeypoint = displacedPoint;\r\n  for (let i = 0; i < offsetRefineStep; i++) {\r\n    const targetKeypointIndices =\r\n        getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\r\n\r\n    const offsetPoint = getOffsetPoint(\r\n        targetKeypointIndices.y, targetKeypointIndices.x, targetKeypointId,\r\n        offsets);\r\n\r\n    targetKeypoint = addVectors(\r\n        {\r\n          x: targetKeypointIndices.x * outputStride,\r\n          y: targetKeypointIndices.y * outputStride\r\n        },\r\n        {x: offsetPoint.x, y: offsetPoint.y});\r\n  }\r\n  const targetKeyPointIndices =\r\n      getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\r\n  const score = scoresBuffer.get(\r\n      targetKeyPointIndices.y, targetKeyPointIndices.x, targetKeypointId);\r\n\r\n  return {position: targetKeypoint, part: PART_NAMES[targetKeypointId], score};\r\n}\r\n\r\n/**\r\n * Follows the displacement fields to decode the full pose of the object\r\n * instance given the position of a part that acts as root.\r\n *\r\n * @return An array of decoded keypoints and their scores for a single pose\r\n */\r\nexport function decodePose(\r\n    root: PartWithScore, scores: TensorBuffer3D, offsets: TensorBuffer3D,\r\n    outputStride: number, displacementsFwd: TensorBuffer3D,\r\n    displacementsBwd: TensorBuffer3D): Keypoint[] {\r\n  const numParts = scores.shape[2];\r\n  const numEdges = parentToChildEdges.length;\r\n\r\n  const instanceKeypoints: Keypoint[] = new Array(numParts);\r\n  // Start a new detection instance at the position of the root.\r\n  const {part: rootPart, score: rootScore} = root;\r\n  const rootPoint = getImageCoords(rootPart, outputStride, offsets);\r\n\r\n  instanceKeypoints[rootPart.id] = {\r\n    score: rootScore,\r\n    part: PART_NAMES[rootPart.id],\r\n    position: rootPoint\r\n  };\r\n\r\n  // Decode the part positions upwards in the tree, following the backward\r\n  // displacements.\r\n  for (let edge = numEdges - 1; edge >= 0; --edge) {\r\n    const sourceKeypointId = parentToChildEdges[edge];\r\n    const targetKeypointId = childToParentEdges[edge];\r\n    if (instanceKeypoints[sourceKeypointId] &&\r\n        !instanceKeypoints[targetKeypointId]) {\r\n      instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(\r\n          edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores,\r\n          offsets, outputStride, displacementsBwd);\r\n    }\r\n  }\r\n\r\n  // Decode the part positions downwards in the tree, following the forward\r\n  // displacements.\r\n  for (let edge = 0; edge < numEdges; ++edge) {\r\n    const sourceKeypointId = childToParentEdges[edge];\r\n    const targetKeypointId = parentToChildEdges[edge];\r\n    if (instanceKeypoints[sourceKeypointId] &&\r\n        !instanceKeypoints[targetKeypointId]) {\r\n      instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(\r\n          edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores,\r\n          offsets, outputStride, displacementsFwd);\r\n    }\r\n  }\r\n\r\n  return instanceKeypoints;\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2019 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nimport {Keypoint, Pose, TensorBuffer3D} from '../types';\r\n\r\nimport {buildPartWithScoreQueue} from './build_part_with_score_queue';\r\nimport {decodePose} from './decode_pose';\r\nimport {getImageCoords, squaredDistance} from './util';\r\n\r\nfunction withinNmsRadiusOfCorrespondingPoint(\r\n    poses: Pose[], squaredNmsRadius: number, {x, y}: {x: number, y: number},\r\n    keypointId: number): boolean {\r\n  return poses.some(({keypoints}) => {\r\n    const correspondingKeypoint = keypoints[keypointId].position;\r\n    return squaredDistance(\r\n               y, x, correspondingKeypoint.y, correspondingKeypoint.x) <=\r\n        squaredNmsRadius;\r\n  });\r\n}\r\n\r\n/* Score the newly proposed object instance without taking into account\r\n * the scores of the parts that overlap with any previously detected\r\n * instance.\r\n */\r\nfunction getInstanceScore(\r\n    existingPoses: Pose[], squaredNmsRadius: number,\r\n    instanceKeypoints: Keypoint[]): number {\r\n  let notOverlappedKeypointScores = instanceKeypoints.reduce(\r\n      (result, {position, score}, keypointId): number => {\r\n        if (!withinNmsRadiusOfCorrespondingPoint(\r\n                existingPoses, squaredNmsRadius, position, keypointId)) {\r\n          result += score;\r\n        }\r\n        return result;\r\n      }, 0.0);\r\n\r\n  return notOverlappedKeypointScores /= instanceKeypoints.length;\r\n}\r\n\r\n// A point (y, x) is considered as root part candidate if its score is a\r\n// maximum in a window |y - y'| <= kLocalMaximumRadius, |x - x'| <=\r\n// kLocalMaximumRadius.\r\nconst kLocalMaximumRadius = 1;\r\n\r\n/**\r\n * Detects multiple poses and finds their parts from part scores and\r\n * displacement vectors. It returns up to `maxDetections` object instance\r\n * detections in decreasing root score order. It works as follows: We first\r\n * create a priority queue with local part score maxima above\r\n * `scoreThreshold`, considering all parts at the same time. Then we\r\n * iteratively pull the top  element of the queue (in decreasing score order)\r\n * and treat it as a root candidate for a new object instance. To avoid\r\n * duplicate detections, we reject the root candidate if it is within a disk\r\n * of `nmsRadius` pixels from the corresponding part of a previously detected\r\n * instance, which is a form of part-based non-maximum suppression (NMS). If\r\n * the root candidate passes the NMS check, we start a new object instance\r\n * detection, treating the corresponding part as root and finding the\r\n * positions of the remaining parts by following the displacement vectors\r\n * along the tree-structured part graph. We assign to the newly detected\r\n * instance a score equal to the sum of scores of its parts which have not\r\n * been claimed by a previous instance (i.e., those at least `nmsRadius`\r\n * pixels away from the corresponding part of all previously detected\r\n * instances), divided by the total number of parts `numParts`.\r\n *\r\n * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.\r\n * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th\r\n * object part at position `(y, x)`.\r\n *\r\n * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.\r\n * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the\r\n * short range offset vector of the `k`-th  object part at heatmap\r\n * position `(y, x)`.\r\n *\r\n * @param displacementsFwd 3-D tensor of shape\r\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\r\n * number of edges (parent-child pairs) in the tree. It contains the forward\r\n * displacements between consecutive part from the root towards the leaves.\r\n *\r\n * @param displacementsBwd 3-D tensor of shape\r\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\r\n * number of edges (parent-child pairs) in the tree. It contains the backward\r\n * displacements between consecutive part from the root towards the leaves.\r\n *\r\n * @param outputStride The output stride that was used when feed-forwarding\r\n * through the PoseNet model.  Must be 32, 16, or 8.\r\n *\r\n * @param maxPoseDetections Maximum number of returned instance detections per\r\n * image.\r\n *\r\n * @param scoreThreshold Only return instance detections that have root part\r\n * score greater or equal to this value. Defaults to 0.5.\r\n *\r\n * @param nmsRadius Non-maximum suppression part distance. It needs to be\r\n * strictly positive. Two parts suppress each other if they are less than\r\n * `nmsRadius` pixels away. Defaults to 20.\r\n *\r\n * @return An array of poses and their scores, each containing keypoints and\r\n * the corresponding keypoint scores.\r\n */\r\nexport function decodeMultiplePoses(\r\n    scoresBuffer: TensorBuffer3D, offsetsBuffer: TensorBuffer3D,\r\n    displacementsFwdBuffer: TensorBuffer3D,\r\n    displacementsBwdBuffer: TensorBuffer3D, outputStride: number,\r\n    maxPoseDetections: number, scoreThreshold = 0.5, nmsRadius = 20): Pose[] {\r\n  const poses: Pose[] = [];\r\n\r\n  const queue = buildPartWithScoreQueue(\r\n      scoreThreshold, kLocalMaximumRadius, scoresBuffer);\r\n\r\n  const squaredNmsRadius = nmsRadius * nmsRadius;\r\n\r\n  // Generate at most maxDetections object instances per image in\r\n  // decreasing root part score order.\r\n  while (poses.length < maxPoseDetections && !queue.empty()) {\r\n    // The top element in the queue is the next root candidate.\r\n    const root = queue.dequeue();\r\n\r\n    // Part-based non-maximum suppression: We reject a root candidate if it\r\n    // is within a disk of `nmsRadius` pixels from the corresponding part of\r\n    // a previously detected instance.\r\n    const rootImageCoords =\r\n        getImageCoords(root.part, outputStride, offsetsBuffer);\r\n    if (withinNmsRadiusOfCorrespondingPoint(\r\n            poses, squaredNmsRadius, rootImageCoords, root.part.id)) {\r\n      continue;\r\n    }\r\n\r\n    // Start a new detection instance at the position of the root.\r\n    const keypoints = decodePose(\r\n        root, scoresBuffer, offsetsBuffer, outputStride, displacementsFwdBuffer,\r\n        displacementsBwdBuffer);\r\n\r\n    const score = getInstanceScore(poses, squaredNmsRadius, keypoints);\r\n\r\n    poses.push({keypoints, score});\r\n  }\r\n\r\n  return poses;\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2019 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * https://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nimport * as tf from '@tensorflow/tfjs-core';\r\n\r\nimport {BaseModel} from './base_model';\r\n\r\nconst imageNetMean = [-123.15, -115.90, -103.06];\r\n\r\nexport class ResNet extends BaseModel {\r\n  preprocessInput(input: tf.Tensor3D): tf.Tensor3D {\r\n    return input.add(imageNetMean);\r\n  }\r\n\r\n  nameOutputResults(results: tf.Tensor3D[]) {\r\n    const [\r\n      displacementBwd,\r\n      displacementFwd,\r\n      heatmap,\r\n      longOffsets,\r\n      offsets,\r\n      partHeatmaps,\r\n      segmentation,\r\n      partOffsets,\r\n  ] = results;\r\n    return {\r\n      offsets,\r\n      segmentation,\r\n      partHeatmaps,\r\n      longOffsets,\r\n      heatmap,\r\n      displacementFwd,\r\n      displacementBwd,\r\n      partOffsets\r\n    };\r\n  }\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2019 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * https://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nconst RESNET50_BASE_URL =\r\n    'https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/resnet50/';\r\nconst MOBILENET_BASE_URL =\r\n    'https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/mobilenet/';\r\n\r\n// The BodyPix 2.0 ResNet50 models use the latest TensorFlow.js 1.0 model\r\n// format.\r\nexport function resNet50SavedModel(stride: number, quantBytes: number): string {\r\n  const graphJson = `model-stride${stride}.json`;\r\n  // quantBytes=4 corresponding to the non-quantized full-precision SavedModel.\r\n  if (quantBytes === 4) {\r\n    return RESNET50_BASE_URL + `float/` + graphJson;\r\n  } else {\r\n    return RESNET50_BASE_URL + `quant${quantBytes}/` + graphJson;\r\n  }\r\n}\r\n\r\n// The BodyPix 2.0 MobileNetV1 models use the latest TensorFlow.js 1.0 model\r\n// format.\r\nexport function mobileNetSavedModel(\r\n    stride: number, multiplier: number, quantBytes: number): string {\r\n  const toStr: {[key: number]: string} = {1.0: '100', 0.75: '075', 0.50: '050'};\r\n  const graphJson = `model-stride${stride}.json`;\r\n  // quantBytes=4 corresponding to the non-quantized full-precision SavedModel.\r\n  if (quantBytes === 4) {\r\n    return MOBILENET_BASE_URL + `float/${toStr[multiplier]}/` + graphJson;\r\n  } else {\r\n    return MOBILENET_BASE_URL + `quant${quantBytes}/${toStr[multiplier]}/` +\r\n        graphJson;\r\n  }\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2020 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n *\r\n * =============================================================================\r\n */\r\n\r\nimport * as tf from '@tensorflow/tfjs-core';\r\n\r\nimport {BodyPixInput, BodyPixOutputStride, Padding} from './types';\r\nimport {Pose, TensorBuffer3D} from './types';\r\nimport {BodyPixInternalResolution} from './types';\r\n\r\nfunction getSizeFromImageLikeElement(input: HTMLImageElement|\r\n                                     HTMLCanvasElement): [number, number] {\r\n  if (input.offsetHeight !== 0 && input.offsetWidth !== 0) {\r\n    return [input.offsetHeight, input.offsetWidth];\r\n  } else if (input.height != null && input.width != null) {\r\n    return [input.height, input.width];\r\n  } else {\r\n    throw new Error(\r\n        `HTMLImageElement must have height and width attributes set.`);\r\n  }\r\n}\r\n\r\nfunction getSizeFromVideoElement(input: HTMLVideoElement): [number, number] {\r\n  if (input.height != null && input.width != null) {\r\n    // Prioritizes user specified height and width.\r\n    return [input.height, input.width];\r\n  } else {\r\n    return [input.videoHeight, input.videoWidth];\r\n  }\r\n}\r\n\r\nexport function getInputSize(input: BodyPixInput): [number, number] {\r\n  if ((typeof (HTMLCanvasElement) !== 'undefined' &&\r\n       input instanceof HTMLCanvasElement) ||\r\n      (typeof (HTMLImageElement) !== 'undefined' &&\r\n       input instanceof HTMLImageElement)) {\r\n    return getSizeFromImageLikeElement(input);\r\n  } else if (typeof (ImageData) !== 'undefined' && input instanceof ImageData) {\r\n    return [input.height, input.width];\r\n  } else if (\r\n      typeof (HTMLVideoElement) !== 'undefined' &&\r\n      input instanceof HTMLVideoElement) {\r\n    return getSizeFromVideoElement(input);\r\n  } else if (input instanceof tf.Tensor) {\r\n    return [input.shape[0], input.shape[1]];\r\n  } else {\r\n    throw new Error(`error: Unknown input type: ${input}.`);\r\n  }\r\n}\r\n\r\nfunction isValidInputResolution(\r\n    resolution: number, outputStride: number): boolean {\r\n  return (resolution - 1) % outputStride === 0;\r\n}\r\n\r\nexport function toValidInputResolution(\r\n    inputResolution: number, outputStride: BodyPixOutputStride): number {\r\n  if (isValidInputResolution(inputResolution, outputStride)) {\r\n    return inputResolution;\r\n  }\r\n\r\n  return Math.floor(inputResolution / outputStride) * outputStride + 1;\r\n}\r\n\r\nconst INTERNAL_RESOLUTION_STRING_OPTIONS = {\r\n  low: 'low',\r\n  medium: 'medium',\r\n  high: 'high',\r\n  full: 'full'\r\n};\r\n\r\nconst INTERNAL_RESOLUTION_PERCENTAGES = {\r\n  [INTERNAL_RESOLUTION_STRING_OPTIONS.low]: 0.25,\r\n  [INTERNAL_RESOLUTION_STRING_OPTIONS.medium]: 0.5,\r\n  [INTERNAL_RESOLUTION_STRING_OPTIONS.high]: 0.75,\r\n  [INTERNAL_RESOLUTION_STRING_OPTIONS.full]: 1.0\r\n};\r\n\r\nconst MIN_INTERNAL_RESOLUTION = 0.1;\r\nconst MAX_INTERNAL_RESOLUTION = 2.0;\r\n\r\nfunction toInternalResolutionPercentage(\r\n    internalResolution: BodyPixInternalResolution): number {\r\n  if (typeof internalResolution === 'string') {\r\n    const result = INTERNAL_RESOLUTION_PERCENTAGES[internalResolution];\r\n\r\n    tf.util.assert(\r\n        typeof result === 'number',\r\n        () => `string value of inputResolution must be one of ${\r\n            Object.values(INTERNAL_RESOLUTION_STRING_OPTIONS)\r\n                .join(',')} but was ${internalResolution}.`);\r\n    return result;\r\n  } else {\r\n    tf.util.assert(\r\n        typeof internalResolution === 'number' &&\r\n            internalResolution <= MAX_INTERNAL_RESOLUTION &&\r\n            internalResolution >= MIN_INTERNAL_RESOLUTION,\r\n        () =>\r\n            `inputResolution must be a string or number between ${\r\n                MIN_INTERNAL_RESOLUTION} and ${MAX_INTERNAL_RESOLUTION}, but ` +\r\n            `was ${internalResolution}`);\r\n\r\n    return internalResolution;\r\n  }\r\n}\r\n\r\nexport function toInputResolutionHeightAndWidth(\r\n    internalResolution: BodyPixInternalResolution,\r\n    outputStride: BodyPixOutputStride,\r\n    [inputHeight, inputWidth]: [number, number]): [number, number] {\r\n  const internalResolutionPercentage =\r\n      toInternalResolutionPercentage(internalResolution);\r\n\r\n  return [\r\n    toValidInputResolution(\r\n        inputHeight * internalResolutionPercentage, outputStride),\r\n    toValidInputResolution(\r\n        inputWidth * internalResolutionPercentage, outputStride)\r\n  ];\r\n}\r\n\r\nexport function toInputTensor(input: BodyPixInput) {\r\n  return input instanceof tf.Tensor ? input : tf.browser.fromPixels(input);\r\n}\r\n\r\nexport function resizeAndPadTo(\r\n    imageTensor: tf.Tensor3D, [targetH, targetW]: [number, number],\r\n    flipHorizontal = false): {\r\n  resizedAndPadded: tf.Tensor3D,\r\n  paddedBy: [[number, number], [number, number]]\r\n} {\r\n  const [height, width] = imageTensor.shape;\r\n\r\n  const targetAspect = targetW / targetH;\r\n  const aspect = width / height;\r\n\r\n  let resizeW: number;\r\n  let resizeH: number;\r\n  let padL: number;\r\n  let padR: number;\r\n  let padT: number;\r\n  let padB: number;\r\n\r\n  if (aspect > targetAspect) {\r\n    // resize to have the larger dimension match the shape.\r\n    resizeW = targetW;\r\n    resizeH = Math.ceil(resizeW / aspect);\r\n\r\n    const padHeight = targetH - resizeH;\r\n    padL = 0;\r\n    padR = 0;\r\n    padT = Math.floor(padHeight / 2);\r\n    padB = targetH - (resizeH + padT);\r\n  } else {\r\n    resizeH = targetH;\r\n    resizeW = Math.ceil(targetH * aspect);\r\n\r\n    const padWidth = targetW - resizeW;\r\n    padL = Math.floor(padWidth / 2);\r\n    padR = targetW - (resizeW + padL);\r\n    padT = 0;\r\n    padB = 0;\r\n  }\r\n\r\n  const resizedAndPadded = tf.tidy(() => {\r\n    // resize to have largest dimension match image\r\n    let resized: tf.Tensor3D;\r\n    if (flipHorizontal) {\r\n      resized = imageTensor.reverse(1).resizeBilinear([resizeH, resizeW]);\r\n    } else {\r\n      resized = imageTensor.resizeBilinear([resizeH, resizeW]);\r\n    }\r\n\r\n    const padded = tf.pad3d(resized, [[padT, padB], [padL, padR], [0, 0]]);\r\n\r\n    return padded;\r\n  });\r\n\r\n  return {resizedAndPadded, paddedBy: [[padT, padB], [padL, padR]]};\r\n}\r\n\r\nexport function scaleAndCropToInputTensorShape(\r\n    tensor: tf.Tensor3D,\r\n    [inputTensorHeight, inputTensorWidth]: [number, number],\r\n    [resizedAndPaddedHeight, resizedAndPaddedWidth]: [number, number],\r\n    [[padT, padB], [padL, padR]]: [[number, number], [number, number]],\r\n    applySigmoidActivation = false): tf.Tensor3D {\r\n  return tf.tidy(() => {\r\n    let inResizedAndPadded: tf.Tensor3D = tensor.resizeBilinear(\r\n        [resizedAndPaddedHeight, resizedAndPaddedWidth], true);\r\n\r\n    if (applySigmoidActivation) {\r\n      inResizedAndPadded = inResizedAndPadded.sigmoid();\r\n    }\r\n\r\n    return removePaddingAndResizeBack(\r\n        inResizedAndPadded, [inputTensorHeight, inputTensorWidth],\r\n        [[padT, padB], [padL, padR]]);\r\n  });\r\n}\r\n\r\nexport function removePaddingAndResizeBack(\r\n    resizedAndPadded: tf.Tensor3D,\r\n    [originalHeight, originalWidth]: [number, number],\r\n    [[padT, padB], [padL, padR]]: [[number, number], [number, number]]):\r\n    tf.Tensor3D {\r\n  return tf.tidy(() => {\r\n    const batchedImage: tf.Tensor4D = resizedAndPadded.expandDims();\r\n    return tf.image\r\n        .cropAndResize(\r\n            batchedImage, [[\r\n              padT / (originalHeight + padT + padB - 1.0),\r\n              padL / (originalWidth + padL + padR - 1.0),\r\n              (padT + originalHeight - 1.0) /\r\n                  (originalHeight + padT + padB - 1.0),\r\n              (padL + originalWidth - 1.0) / (originalWidth + padL + padR - 1.0)\r\n            ]],\r\n            [0], [originalHeight, originalWidth])\r\n        .squeeze([0]);\r\n  });\r\n}\r\n\r\nexport function resize2d(\r\n    tensor: tf.Tensor2D, resolution: [number, number],\r\n    nearestNeighbor?: boolean): tf.Tensor2D {\r\n  return tf.tidy(() => {\r\n    const batchedImage: tf.Tensor4D = tensor.expandDims(2);\r\n    return batchedImage.resizeBilinear(resolution, nearestNeighbor).squeeze();\r\n  });\r\n}\r\n\r\nexport function padAndResizeTo(\r\n    input: BodyPixInput, [targetH, targetW]: [number, number]):\r\n    {resized: tf.Tensor3D, padding: Padding} {\r\n  const [height, width] = getInputSize(input);\r\n  const targetAspect = targetW / targetH;\r\n  const aspect = width / height;\r\n  let [padT, padB, padL, padR] = [0, 0, 0, 0];\r\n  if (aspect < targetAspect) {\r\n    // pads the width\r\n    padT = 0;\r\n    padB = 0;\r\n    padL = Math.round(0.5 * (targetAspect * height - width));\r\n    padR = Math.round(0.5 * (targetAspect * height - width));\r\n  } else {\r\n    // pads the height\r\n    padT = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\r\n    padB = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\r\n    padL = 0;\r\n    padR = 0;\r\n  }\r\n\r\n  const resized: tf.Tensor3D = tf.tidy(() => {\r\n    let imageTensor = toInputTensor(input);\r\n    imageTensor = tf.pad3d(imageTensor, [[padT, padB], [padL, padR], [0, 0]]);\r\n\r\n    return imageTensor.resizeBilinear([targetH, targetW]);\r\n  });\r\n\r\n  return {resized, padding: {top: padT, left: padL, right: padR, bottom: padB}};\r\n}\r\n\r\nexport async function toTensorBuffers3D(tensors: tf.Tensor3D[]):\r\n    Promise<TensorBuffer3D[]> {\r\n  return Promise.all(tensors.map(tensor => tensor.buffer()));\r\n}\r\n\r\nexport function scalePose(\r\n    pose: Pose, scaleY: number, scaleX: number, offsetY = 0,\r\n    offsetX = 0): Pose {\r\n  return {\r\n    score: pose.score,\r\n    keypoints: pose.keypoints.map(({score, part, position}) => ({\r\n                                    score,\r\n                                    part,\r\n                                    position: {\r\n                                      x: position.x * scaleX + offsetX,\r\n                                      y: position.y * scaleY + offsetY\r\n                                    }\r\n                                  }))\r\n  };\r\n}\r\n\r\nexport function scalePoses(\r\n    poses: Pose[], scaleY: number, scaleX: number, offsetY = 0, offsetX = 0) {\r\n  if (scaleX === 1 && scaleY === 1 && offsetY === 0 && offsetX === 0) {\r\n    return poses;\r\n  }\r\n  return poses.map(pose => scalePose(pose, scaleY, scaleX, offsetY, offsetX));\r\n}\r\n\r\nexport function flipPoseHorizontal(pose: Pose, imageWidth: number): Pose {\r\n  return {\r\n    score: pose.score,\r\n    keypoints: pose.keypoints.map(\r\n        ({score, part, position}) => ({\r\n          score,\r\n          part,\r\n          position: {x: imageWidth - 1 - position.x, y: position.y}\r\n        }))\r\n  };\r\n}\r\n\r\nexport function flipPosesHorizontal(poses: Pose[], imageWidth: number) {\r\n  if (imageWidth <= 0) {\r\n    return poses;\r\n  }\r\n  return poses.map(pose => flipPoseHorizontal(pose, imageWidth));\r\n}\r\n\r\nexport function scaleAndFlipPoses(\r\n    poses: Pose[], [height, width]: [number, number],\r\n    [inputResolutionHeight, inputResolutionWidth]: [number, number],\r\n    padding: Padding, flipHorizontal: boolean): Pose[] {\r\n  const scaleY =\r\n      (height + padding.top + padding.bottom) / (inputResolutionHeight);\r\n  const scaleX =\r\n      (width + padding.left + padding.right) / (inputResolutionWidth);\r\n\r\n  const scaledPoses =\r\n      scalePoses(poses, scaleY, scaleX, -padding.top, -padding.left);\r\n\r\n  if (flipHorizontal) {\r\n    return flipPosesHorizontal(scaledPoses, width);\r\n  } else {\r\n    return scaledPoses;\r\n  }\r\n}\r\n","\r\n/**\r\n * @license\r\n * Copyright 2019 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nimport * as tfconv from '@tensorflow/tfjs-converter';\r\nimport * as tf from '@tensorflow/tfjs-core';\r\n\r\nimport {BaseModel} from './base_model';\r\nimport {decodeOnlyPartSegmentation, decodePartSegmentation, toMaskTensor} from './decode_part_map';\r\nimport {MobileNet} from './mobilenet';\r\nimport {decodePersonInstanceMasks, decodePersonInstancePartMasks} from './multi_person/decode_instance_masks';\r\nimport {decodeMultiplePoses} from './multi_person/decode_multiple_poses';\r\nimport {ResNet} from './resnet';\r\nimport {mobileNetSavedModel, resNet50SavedModel} from './saved_models';\r\nimport {BodyPixArchitecture, BodyPixInput, BodyPixInternalResolution, BodyPixMultiplier, BodyPixOutputStride, BodyPixQuantBytes, Padding} from './types';\r\nimport {PartSegmentation, PersonSegmentation, SemanticPartSegmentation, ExtendedSemanticPersonSegmentation} from './types';\r\nimport {getInputSize, padAndResizeTo, scaleAndCropToInputTensorShape, scaleAndFlipPoses, toInputResolutionHeightAndWidth, toTensorBuffers3D} from './util';\r\n\r\nconst APPLY_SIGMOID_ACTIVATION = true;\r\nconst FLIP_POSES_AFTER_SCALING = false;\r\n\r\n/**\r\n * BodyPix model loading is configurable using the following config dictionary.\r\n *\r\n * `architecture`: BodyPixArchitecture. It determines which BodyPix architecture\r\n * to load. The supported architectures are: MobileNetV1 and ResNet50.\r\n *\r\n * `outputStride`: Specifies the output stride of the BodyPix model.\r\n * The smaller the value, the larger the output resolution, and more accurate\r\n * the model at the cost of speed. Set this to a larger value to increase speed\r\n * at the cost of accuracy. Stride 32 is supported for ResNet and\r\n * stride 8,16,32 are supported for various MobileNetV1 models.\r\n *\r\n * `multiplier`: An optional number with values: 1.01, 1.0, 0.75, or\r\n * 0.50. The value is used only by MobileNet architecture. It is the float\r\n * multiplier for the depth (number of channels) for all convolution ops.\r\n * The larger the value, the larger the size of the layers, and more accurate\r\n * the model at the cost of speed. Set this to a smaller value to increase speed\r\n * at the cost of accuracy.\r\n *\r\n * `modelUrl`: An optional string that specifies custom url of the model. This\r\n * is useful for area/countries that don't have access to the model hosted on\r\n * GCP.\r\n *\r\n * `quantBytes`: An optional number with values: 1, 2, or 4.  This parameter\r\n * affects weight quantization in the models. The available options are\r\n * 1 byte, 2 bytes, and 4 bytes. The higher the value, the larger the model size\r\n * and thus the longer the loading time, the lower the value, the shorter the\r\n * loading time but lower the accuracy.\r\n */\r\nexport interface ModelConfig {\r\n  architecture: BodyPixArchitecture;\r\n  outputStride: BodyPixOutputStride;\r\n  multiplier?: BodyPixMultiplier;\r\n  modelUrl?: string;\r\n  quantBytes?: BodyPixQuantBytes;\r\n}\r\n\r\n// The default configuration for loading MobileNetV1 based BodyPix.\r\n//\r\n// (And for references, the default configuration for loading ResNet\r\n// based PoseNet is also included).\r\n//\r\n// ```\r\n// const RESNET_CONFIG = {\r\n//   architecture: 'ResNet50',\r\n//   outputStride: 32,\r\n//   quantBytes: 4,\r\n// } as ModelConfig;\r\n// ```\r\n\r\nconst MOBILENET_V1_CONFIG = {\r\n  architecture: 'MobileNetV1',\r\n  outputStride: 16,\r\n  quantBytes: 4,\r\n  multiplier: 0.75,\r\n} as ModelConfig;\r\n\r\nconst VALID_ARCHITECTURE: BodyPixArchitecture[] = ['MobileNetV1', 'ResNet50'];\r\nconst VALID_STRIDE: {[id: string]: BodyPixOutputStride[]} = {\r\n  'MobileNetV1': [8, 16, 32],\r\n  'ResNet50': [32, 16]\r\n};\r\nconst VALID_MULTIPLIER: {[id: string]: BodyPixMultiplier[]} = {\r\n  'MobileNetV1': [0.50, 0.75, 1.0],\r\n  'ResNet50': [1.0]\r\n};\r\nconst VALID_QUANT_BYTES: BodyPixQuantBytes[] = [1, 2, 4];\r\n\r\nfunction validateModelConfig(config: ModelConfig): ModelConfig {\r\n  config = config || MOBILENET_V1_CONFIG;\r\n\r\n  if (config.architecture == null) {\r\n    config.architecture = 'MobileNetV1';\r\n  }\r\n  if (VALID_ARCHITECTURE.indexOf(config.architecture) < 0) {\r\n    throw new Error(\r\n        `Invalid architecture ${config.architecture}. ` +\r\n        `Should be one of ${VALID_ARCHITECTURE}`);\r\n  }\r\n  if (config.outputStride == null) {\r\n    config.outputStride = 16;\r\n  }\r\n  if (VALID_STRIDE[config.architecture].indexOf(config.outputStride) < 0) {\r\n    throw new Error(\r\n        `Invalid outputStride ${config.outputStride}. ` +\r\n        `Should be one of ${VALID_STRIDE[config.architecture]} ` +\r\n        `for architecture ${config.architecture}.`);\r\n  }\r\n\r\n  if (config.multiplier == null) {\r\n    config.multiplier = 1.0;\r\n  }\r\n  if (VALID_MULTIPLIER[config.architecture].indexOf(config.multiplier) < 0) {\r\n    throw new Error(\r\n        `Invalid multiplier ${config.multiplier}. ` +\r\n        `Should be one of ${VALID_MULTIPLIER[config.architecture]} ` +\r\n        `for architecture ${config.architecture}.`);\r\n  }\r\n\r\n  if (config.quantBytes == null) {\r\n    config.quantBytes = 4;\r\n  }\r\n  if (VALID_QUANT_BYTES.indexOf(config.quantBytes) < 0) {\r\n    throw new Error(\r\n        `Invalid quantBytes ${config.quantBytes}. ` +\r\n        `Should be one of ${VALID_QUANT_BYTES} ` +\r\n        `for architecture ${config.architecture}.`);\r\n  }\r\n\r\n  return config;\r\n}\r\n\r\n/**\r\n * BodyPix inference is configurable using the following config dictionary.\r\n *\r\n * `flipHorizontal`: If the left-right keypoint of poses/part segmentation\r\n * should be flipped/mirrored horizontally. This should be set to true for\r\n * videos where the video is by default flipped horizontally (i.e. a webcam),\r\n * and you want the person & body part segmentation to be returned in the proper\r\n * orientation.\r\n *\r\n * `internalResolution`: Defaults to 'medium'. The internal resolution\r\n * percentage that the input is resized to before inference. The larger the\r\n * internalResolution the more accurate the model at the cost of slower\r\n * prediction times. Available values are 'low', 'medium', 'high', 'full', or a\r\n * percentage value between 0 and 1. The values 'low', 'medium', 'high', and\r\n * 'full' map to 0.25, 0.5, 0.75, and 1.0 correspondingly.\r\n *\r\n * `segmentationThreshold`: The minimum that segmentation values must\r\n * have to be considered part of the person. Affects the generation of the\r\n * segmentation mask. More specifically, it is the threshold used to binarize\r\n * the intermediate person segmentation probability. The probability of each\r\n * pixel belongs to a person is in range [0, 1]. If the probability is greater\r\n * than the `segmentationThreshold`, it will be set to 1 otherwise 0.\r\n *\r\n */\r\nexport interface InferenceConfig {\r\n  flipHorizontal?: boolean;\r\n  internalResolution?: BodyPixInternalResolution;\r\n  segmentationThreshold?: number;\r\n}\r\n\r\n/**\r\n * Person Inference Config\r\n *\r\n * `maxDetections`: Defaults to 10. Maximum number of person pose detections per\r\n * image.\r\n *\r\n * `scoreThreshold`: Defaults to 0.4. Only return person pose that have root\r\n * part score greater or equal to this value.\r\n *\r\n * `nmsRadius`: Defaults to 20. Non-maximum suppression part distance in pixels.\r\n * It needs to be strictly positive. Two pose keypoints suppress each other if\r\n * they are less than `nmsRadius` pixels away.\r\n */\r\nexport interface PersonInferenceConfig extends InferenceConfig {\r\n  maxDetections?: number;\r\n  scoreThreshold?: number;\r\n  nmsRadius?: number;\r\n}\r\n\r\n/**\r\n * Multiple Person Instance Inference Config\r\n *\r\n * `maxDetections`: Defaults to 10. Maximum number of returned instance\r\n * segmentation and pose detections per image.\r\n *\r\n * `scoreThreshold`: Defaults to 0.4. Only returns and uses person\r\n * poses for instance segmentation assignment when the pose has root part score\r\n * greater or equal to this value.\r\n *\r\n * `nmsRadius`: Defaults to 20. Non-maximum suppression part distance in pixels.\r\n * It needs to be strictly positive. Two parts suppress each other if they are\r\n * less than `nmsRadius` pixels away.\r\n *\r\n * `minKeypointScore`: Default to 0.3. Keypoints above the score are used\r\n * for matching and assigning segmentation mask to each person.\r\n *\r\n * `refineSteps`: Default to 10. The number of refinement steps used when\r\n * assigning the instance segmentation. It needs to be strictly positive. The\r\n * larger the higher the accuracy and slower the inference.\r\n *\r\n */\r\nexport interface MultiPersonInstanceInferenceConfig extends InferenceConfig {\r\n  maxDetections?: number;\r\n  scoreThreshold?: number;\r\n  nmsRadius?: number;\r\n  minKeypointScore?: number;\r\n  refineSteps?: number;\r\n}\r\n\r\nexport const PERSON_INFERENCE_CONFIG: PersonInferenceConfig = {\r\n  flipHorizontal: false,\r\n  internalResolution: 'medium',\r\n  segmentationThreshold: 0.7,\r\n  maxDetections: 10,\r\n  scoreThreshold: 0.4,\r\n  nmsRadius: 20,\r\n};\r\n\r\nexport const MULTI_PERSON_INSTANCE_INFERENCE_CONFIG:\r\n    MultiPersonInstanceInferenceConfig = {\r\n      flipHorizontal: false,\r\n      internalResolution: 'medium',\r\n      segmentationThreshold: 0.7,\r\n      maxDetections: 10,\r\n      scoreThreshold: 0.4,\r\n      nmsRadius: 20,\r\n      minKeypointScore: 0.3,\r\n      refineSteps: 10\r\n    };\r\n\r\nfunction validatePersonInferenceConfig(config: PersonInferenceConfig) {\r\n  const {segmentationThreshold, maxDetections, scoreThreshold, nmsRadius} =\r\n      config;\r\n\r\n  if (segmentationThreshold < 0.0 || segmentationThreshold > 1.0) {\r\n    throw new Error(\r\n        `segmentationThreshold ${segmentationThreshold}. ` +\r\n        `Should be in range [0.0, 1.0]`);\r\n  }\r\n\r\n  if (maxDetections <= 0) {\r\n    throw new Error(\r\n        `Invalid maxDetections ${maxDetections}. ` +\r\n        `Should be > 0`);\r\n  }\r\n\r\n  if (scoreThreshold < 0.0 || scoreThreshold > 1.0) {\r\n    throw new Error(\r\n        `Invalid scoreThreshold ${scoreThreshold}. ` +\r\n        `Should be in range [0.0, 1.0]`);\r\n  }\r\n\r\n  if (nmsRadius <= 0) {\r\n    throw new Error(`Invalid nmsRadius ${nmsRadius}.`);\r\n  }\r\n}\r\n\r\nfunction validateMultiPersonInstanceInferenceConfig(\r\n    config: MultiPersonInstanceInferenceConfig) {\r\n  const {\r\n    segmentationThreshold,\r\n    maxDetections,\r\n    scoreThreshold,\r\n    nmsRadius,\r\n    minKeypointScore,\r\n    refineSteps\r\n  } = config;\r\n\r\n  if (segmentationThreshold < 0.0 || segmentationThreshold > 1.0) {\r\n    throw new Error(\r\n        `segmentationThreshold ${segmentationThreshold}. ` +\r\n        `Should be in range [0.0, 1.0]`);\r\n  }\r\n\r\n  if (maxDetections <= 0) {\r\n    throw new Error(\r\n        `Invalid maxDetections ${maxDetections}. ` +\r\n        `Should be > 0`);\r\n  }\r\n\r\n  if (scoreThreshold < 0.0 || scoreThreshold > 1.0) {\r\n    throw new Error(\r\n        `Invalid scoreThreshold ${scoreThreshold}. ` +\r\n        `Should be in range [0.0, 1.0]`);\r\n  }\r\n\r\n  if (nmsRadius <= 0) {\r\n    throw new Error(`Invalid nmsRadius ${nmsRadius}.`);\r\n  }\r\n\r\n  if (minKeypointScore < 0 || minKeypointScore > 1) {\r\n    throw new Error(\r\n        `Invalid minKeypointScore ${minKeypointScore}.` +\r\n        `Should be in range [0.0, 1.0]`);\r\n  }\r\n\r\n  if (refineSteps <= 0 || refineSteps > 20) {\r\n    throw new Error(\r\n        `Invalid refineSteps ${refineSteps}.` +\r\n        `Should be in range [1, 20]`);\r\n  }\r\n}\r\n\r\nexport class BodyPix {\r\n  baseModel: BaseModel;\r\n\r\n  constructor(net: BaseModel) {\r\n    this.baseModel = net;\r\n  }\r\n\r\n  private predictForPersonSegmentation(input: tf.Tensor3D): {\r\n    segmentLogits: tf.Tensor3D,\r\n    heatmapScores: tf.Tensor3D,\r\n    offsets: tf.Tensor3D,\r\n    displacementFwd: tf.Tensor3D,\r\n    displacementBwd: tf.Tensor3D,\r\n  } {\r\n    const {\r\n      segmentation,\r\n      heatmapScores,\r\n      offsets,\r\n      displacementFwd,\r\n      displacementBwd,\r\n    } = this.baseModel.predict(input);\r\n    return {\r\n      segmentLogits: segmentation,\r\n      heatmapScores,\r\n      offsets,\r\n      displacementFwd,\r\n      displacementBwd,\r\n    };\r\n  }\r\n\r\n  private predictForPersonSegmentationAndPart(input: tf.Tensor3D): {\r\n    segmentLogits: tf.Tensor3D,\r\n    partHeatmapLogits: tf.Tensor3D,\r\n    heatmapScores: tf.Tensor3D,\r\n    offsets: tf.Tensor3D,\r\n    displacementFwd: tf.Tensor3D,\r\n    displacementBwd: tf.Tensor3D,\r\n  } {\r\n    const {\r\n      segmentation,\r\n      partHeatmaps,\r\n      heatmapScores,\r\n      offsets,\r\n      displacementFwd,\r\n      displacementBwd\r\n    } = this.baseModel.predict(input);\r\n    return {\r\n      segmentLogits: segmentation,\r\n      partHeatmapLogits: partHeatmaps,\r\n      heatmapScores,\r\n      offsets,\r\n      displacementFwd,\r\n      displacementBwd,\r\n    };\r\n  }\r\n\r\n  private predictForMultiPersonInstanceSegmentationAndPart(input: tf.Tensor3D):\r\n      {\r\n        segmentLogits: tf.Tensor3D,\r\n        longOffsets: tf.Tensor3D,\r\n        heatmapScores: tf.Tensor3D,\r\n        offsets: tf.Tensor3D,\r\n        displacementFwd: tf.Tensor3D,\r\n        displacementBwd: tf.Tensor3D,\r\n        partHeatmaps: tf.Tensor3D\r\n      } {\r\n    const {\r\n      segmentation,\r\n      longOffsets,\r\n      heatmapScores,\r\n      offsets,\r\n      displacementFwd,\r\n      displacementBwd,\r\n      partHeatmaps,\r\n    } = this.baseModel.predict(input);\r\n    return {\r\n      segmentLogits: segmentation,\r\n      longOffsets,\r\n      heatmapScores,\r\n      offsets,\r\n      displacementFwd,\r\n      displacementBwd,\r\n      partHeatmaps\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Given an image with people, returns a dictionary of all intermediate\r\n   * tensors including: 1) a binary array with 1 for the pixels that are part of\r\n   * the person, and 0 otherwise, 2) heatmapScores, 3) offsets, and 4) paddings.\r\n   *\r\n   * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\r\n   * The input image to feed through the network.\r\n   *\r\n   * @param internalResolution Defaults to 'medium'. The internal resolution\r\n   * that the input is resized to before inference. The larger the\r\n   * internalResolution the more accurate the model at the cost of slower\r\n   * prediction times. Available values are 'low', 'medium', 'high', 'full', or\r\n   * a percentage value between 0 and 1. The values 'low', 'medium', 'high', and\r\n   * 'full' map to 0.25, 0.5, 0.75, and 1.0 correspondingly.\r\n   *\r\n   * @param segmentationThreshold The minimum that segmentation values must have\r\n   * to be considered part of the person. Affects the generation of the\r\n   * segmentation mask.\r\n   *\r\n   * @return A dictionary containing `segmentation`, `heatmapScores`, `offsets`,\r\n   * and `padding`:\r\n   * - `segmentation`: A 2d Tensor with 1 for the pixels that are part of the\r\n   * person, and 0 otherwise. The width and height correspond to the same\r\n   * dimensions of the input image.\r\n   * - `heatmapScores`: A 3d Tensor of the keypoint heatmaps used by\r\n   * pose estimation decoding.\r\n   * - `offsets`: A 3d Tensor of the keypoint offsets used by pose\r\n   * estimation decoding.\r\n   * - `displacementFwd`: A 3d Tensor of the keypoint forward displacement used\r\n   * by pose estimation decoding.\r\n   * - `displacementBwd`: A 3d Tensor of the keypoint backward displacement used\r\n   * by pose estimation decoding.\r\n   * - `padding`: The padding (unit pixels) being applied to the input image\r\n   * before it is fed into the model.\r\n   */\r\n  segmentPersonActivation(\r\n      input: BodyPixInput, internalResolution: BodyPixInternalResolution,\r\n      segmentationThreshold = 0.5): {\r\n    segmentation: tf.Tensor2D,\r\n    segmentationScores: tf.Tensor2D,\r\n    heatmapScores: tf.Tensor3D,\r\n    offsets: tf.Tensor3D,\r\n    displacementFwd: tf.Tensor3D,\r\n    displacementBwd: tf.Tensor3D,\r\n    padding: Padding,\r\n    internalResolutionHeightAndWidth: [number, number]\r\n  } {\r\n    const [height, width] = getInputSize(input);\r\n    const internalResolutionHeightAndWidth = toInputResolutionHeightAndWidth(\r\n        internalResolution, this.baseModel.outputStride, [height, width]);\r\n    const {resized, padding} =\r\n        padAndResizeTo(input, internalResolutionHeightAndWidth);\r\n\r\n    const {\r\n      segmentationScores,\r\n      segmentation,\r\n      heatmapScores,\r\n      offsets,\r\n      displacementFwd,\r\n      displacementBwd\r\n    } = tf.tidy(() => {\r\n      const {\r\n        segmentLogits,\r\n        heatmapScores,\r\n        offsets,\r\n        displacementFwd,\r\n        displacementBwd\r\n      } = this.predictForPersonSegmentation(resized);\r\n\r\n      const [resizedHeight, resizedWidth] = resized.shape;\r\n\r\n      const scaledSegmentScores = scaleAndCropToInputTensorShape(\r\n          segmentLogits, [height, width], [resizedHeight, resizedWidth],\r\n          [[padding.top, padding.bottom], [padding.left, padding.right]],\r\n          APPLY_SIGMOID_ACTIVATION);\r\n      const segmentationScores = scaledSegmentScores.squeeze() as tf.Tensor2D;\r\n      return {\r\n        segmentationScores,\r\n        segmentation:\r\n            toMaskTensor(segmentationScores, segmentationThreshold),\r\n        heatmapScores,\r\n        offsets,\r\n        displacementFwd,\r\n        displacementBwd,\r\n      };\r\n    });\r\n    resized.dispose();\r\n    return {\r\n      segmentationScores,\r\n      segmentation,\r\n      heatmapScores,\r\n      offsets,\r\n      displacementFwd,\r\n      displacementBwd,\r\n      padding,\r\n      internalResolutionHeightAndWidth\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Given an image with many people, returns a PersonSegmentation dictionary\r\n   * that contains the segmentation mask for all people and a single pose.\r\n   *\r\n   * Note: The segmentation mask returned by this method covers all people but\r\n   * the pose works well for one person. If you want to estimate instance-level\r\n   * multiple person segmentation & pose for each person, use\r\n   * `segmentMultiPerson` instead.\r\n   *\r\n   * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\r\n   * The input image to feed through the network.\r\n   *\r\n   * @param config PersonInferenceConfig object that contains\r\n   * parameters for the BodyPix inference using person decoding.\r\n   *\r\n   * @return A SemanticPersonSegmentation dictionary that contains height,\r\n   * width, the flattened binary segmentation mask and the poses for all people.\r\n   * The width and height correspond to the same dimensions of the input image.\r\n   * - `height`: The height of the segmentation data in pixel unit.\r\n   * - `width`: The width of the segmentation data in pixel unit.\r\n   * - `data`: The flattened Uint8Array of segmentation data. 1 means the pixel\r\n   * belongs to a person and 0 means the pixel doesn't belong to a person. The\r\n   * size of the array is equal to `height` x `width` in row-major order.\r\n   * - `allPoses`: The 2d poses of all people.\r\n   */\r\n  async segmentPerson(\r\n      input: BodyPixInput,\r\n      config: PersonInferenceConfig = PERSON_INFERENCE_CONFIG):\r\n      Promise<ExtendedSemanticPersonSegmentation> {\r\n    config = {...PERSON_INFERENCE_CONFIG, ...config};\r\n\r\n    validatePersonInferenceConfig(config);\r\n\r\n    const {\r\n      segmentationScores,\r\n      segmentation,\r\n      heatmapScores,\r\n      offsets,\r\n      displacementFwd,\r\n      displacementBwd,\r\n      padding,\r\n      internalResolutionHeightAndWidth\r\n    } =\r\n        this.segmentPersonActivation(\r\n            input, config.internalResolution, config.segmentationThreshold);\r\n\r\n    const [height, width] = segmentation.shape;\r\n\r\n    const result = await segmentation.data() as Uint8Array;\r\n    segmentation.dispose();\r\n    const scores = await segmentationScores.data() as Float32Array;\r\n    segmentationScores.dispose();\r\n\r\n    const tensorBuffers = await toTensorBuffers3D(\r\n        [heatmapScores, offsets, displacementFwd, displacementBwd]);\r\n    const [scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf] =\r\n        tensorBuffers;\r\n\r\n    let poses = decodeMultiplePoses(\r\n        scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf,\r\n        this.baseModel.outputStride, config.maxDetections,\r\n        config.scoreThreshold, config.nmsRadius);\r\n\r\n    poses = scaleAndFlipPoses(\r\n        poses, [height, width], internalResolutionHeightAndWidth, padding,\r\n        FLIP_POSES_AFTER_SCALING);\r\n\r\n    heatmapScores.dispose();\r\n    offsets.dispose();\r\n    displacementFwd.dispose();\r\n    displacementBwd.dispose();\r\n\r\n    return {height, width, data: result, scores, allPoses: poses};\r\n  }\r\n\r\n  /**\r\n   * Given an image with multiple people, returns an *array* of\r\n   * PersonSegmentation object. Each element in the array corresponding to one\r\n   * of the people in the input image. In other words, it predicts\r\n   * instance-level multiple person segmentation & pose for each person.\r\n   *\r\n   * The model does standard ImageNet pre-processing before inferring through\r\n   * the model. The image pixels should have values [0-255].\r\n   *\r\n   * @param input\r\n   * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\r\n   * image to feed through the network.\r\n   *\r\n   * @param config MultiPersonInferenceConfig object that contains\r\n   * parameters for the BodyPix inference using multi-person decoding.\r\n   *\r\n   * @return An array of PersonSegmentation object, each containing a width,\r\n   * height, a binary array (1 for the pixels that are part of the\r\n   * person, and 0 otherwise) and 2D pose. The array size corresponds to the\r\n   * number of pixels in the image. The width and height correspond to the\r\n   * dimensions of the image the binary array is shaped to, which are the same\r\n   * dimensions of the input image.\r\n   */\r\n  async segmentMultiPerson(\r\n      input: BodyPixInput,\r\n      config: MultiPersonInstanceInferenceConfig =\r\n          MULTI_PERSON_INSTANCE_INFERENCE_CONFIG):\r\n      Promise<PersonSegmentation[]> {\r\n    config = {...MULTI_PERSON_INSTANCE_INFERENCE_CONFIG, ...config};\r\n    validateMultiPersonInstanceInferenceConfig(config);\r\n    const [height, width] = getInputSize(input);\r\n    const internalResolutionHeightAndWidth = toInputResolutionHeightAndWidth(\r\n        config.internalResolution, this.baseModel.outputStride,\r\n        [height, width]);\r\n\r\n    const {resized, padding} =\r\n        padAndResizeTo(input, internalResolutionHeightAndWidth);\r\n    const {\r\n      segmentation,\r\n      longOffsets,\r\n      heatmapScoresRaw,\r\n      offsetsRaw,\r\n      displacementFwdRaw,\r\n      displacementBwdRaw,\r\n    } = tf.tidy(() => {\r\n      const {\r\n        segmentLogits,\r\n        longOffsets,\r\n        heatmapScores,\r\n        offsets,\r\n        displacementFwd,\r\n        displacementBwd,\r\n      } = this.predictForMultiPersonInstanceSegmentationAndPart(resized);\r\n      const scaledSegmentScores = scaleAndCropToInputTensorShape(\r\n          segmentLogits, [height, width], internalResolutionHeightAndWidth,\r\n          [[padding.top, padding.bottom], [padding.left, padding.right]],\r\n          APPLY_SIGMOID_ACTIVATION);\r\n      const longOffsetsResized = false;\r\n      let scaledLongOffsets;\r\n      if (longOffsetsResized) {\r\n        scaledLongOffsets = scaleAndCropToInputTensorShape(\r\n            longOffsets, [height, width], internalResolutionHeightAndWidth,\r\n            [[padding.top, padding.bottom], [padding.left, padding.right]],\r\n            APPLY_SIGMOID_ACTIVATION);\r\n      } else {\r\n        scaledLongOffsets = longOffsets;\r\n      }\r\n\r\n      const segmentation = toMaskTensor(\r\n          scaledSegmentScores.squeeze(), config.segmentationThreshold);\r\n\r\n      return {\r\n        segmentation,\r\n        longOffsets: scaledLongOffsets,\r\n        heatmapScoresRaw: heatmapScores,\r\n        offsetsRaw: offsets,\r\n        displacementFwdRaw: displacementFwd,\r\n        displacementBwdRaw: displacementBwd,\r\n      };\r\n    });\r\n\r\n    const tensorBuffers = await toTensorBuffers3D(\r\n        [heatmapScoresRaw, offsetsRaw, displacementFwdRaw, displacementBwdRaw]);\r\n    const [scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf] =\r\n        tensorBuffers;\r\n\r\n    let poses = decodeMultiplePoses(\r\n        scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf,\r\n        this.baseModel.outputStride, config.maxDetections,\r\n        config.scoreThreshold, config.nmsRadius);\r\n\r\n    poses = scaleAndFlipPoses(\r\n        poses, [height, width], internalResolutionHeightAndWidth, padding,\r\n        FLIP_POSES_AFTER_SCALING);\r\n\r\n    const instanceMasks = await decodePersonInstanceMasks(\r\n        segmentation, longOffsets, poses, height, width,\r\n        this.baseModel.outputStride, internalResolutionHeightAndWidth, padding,\r\n        config.scoreThreshold, config.refineSteps, config.minKeypointScore,\r\n        config.maxDetections);\r\n\r\n    resized.dispose();\r\n    segmentation.dispose();\r\n    longOffsets.dispose();\r\n    heatmapScoresRaw.dispose();\r\n    offsetsRaw.dispose();\r\n    displacementFwdRaw.dispose();\r\n    displacementBwdRaw.dispose();\r\n\r\n    return instanceMasks;\r\n  }\r\n\r\n  /**\r\n   * Given an image with many people, returns a dictionary containing: height,\r\n   * width, a tensor with a part id from 0-24 for the pixels that are\r\n   * part of a corresponding body part, and -1 otherwise. This does standard\r\n   * ImageNet pre-processing before inferring through the model.  The image\r\n   * should pixels should have values [0-255].\r\n   *\r\n   * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\r\n   * The input image to feed through the network.\r\n   *\r\n   * @param internalResolution Defaults to 'medium'. The internal resolution\r\n   * percentage that the input is resized to before inference. The larger the\r\n   * internalResolution the more accurate the model at the cost of slower\r\n   * prediction times. Available values are 'low', 'medium', 'high', 'full', or\r\n   * a percentage value between 0 and 1. The values 'low', 'medium', 'high', and\r\n   * 'full' map to 0.25, 0.5, 0.75, and 1.0 correspondingly.\r\n   *\r\n   * @param segmentationThreshold The minimum that segmentation values must have\r\n   * to be considered part of the person.  Affects the clipping of the colored\r\n   * part image.\r\n   *\r\n   * @return  A dictionary containing `partSegmentation`, `heatmapScores`,\r\n   * `offsets`, and `padding`:\r\n   * - `partSegmentation`: A 2d Tensor with a part id from 0-24 for\r\n   * the pixels that are part of a corresponding body part, and -1 otherwise.\r\n   * - `heatmapScores`: A 3d Tensor of the keypoint heatmaps used by\r\n   * single-person pose estimation decoding.\r\n   * - `offsets`: A 3d Tensor of the keypoint offsets used by single-person pose\r\n   * estimation decoding.\r\n   * - `displacementFwd`: A 3d Tensor of the keypoint forward displacement\r\n   * used by pose estimation decoding.\r\n   * - `displacementBwd`: A 3d Tensor of the keypoint backward displacement used\r\n   * by pose estimation decoding.\r\n   * - `padding`: The padding (unit pixels) being applied to the input image\r\n   * before it is fed into the model.\r\n   */\r\n  segmentPersonPartsActivation(\r\n      input: BodyPixInput, internalResolution: BodyPixInternalResolution,\r\n      segmentationThreshold = 0.5): {\r\n    partSegmentation: tf.Tensor2D,\r\n    heatmapScores: tf.Tensor3D,\r\n    offsets: tf.Tensor3D,\r\n    displacementFwd: tf.Tensor3D,\r\n    displacementBwd: tf.Tensor3D,\r\n    padding: Padding,\r\n    internalResolutionHeightAndWidth: [number, number]\r\n  } {\r\n    const [height, width] = getInputSize(input);\r\n    const internalResolutionHeightAndWidth = toInputResolutionHeightAndWidth(\r\n        internalResolution, this.baseModel.outputStride, [height, width]);\r\n    const {\r\n      resized,\r\n      padding,\r\n    } = padAndResizeTo(input, internalResolutionHeightAndWidth);\r\n\r\n    const {\r\n      partSegmentation,\r\n      heatmapScores,\r\n      offsets,\r\n      displacementFwd,\r\n      displacementBwd\r\n    } = tf.tidy(() => {\r\n      const {\r\n        segmentLogits,\r\n        partHeatmapLogits,\r\n        heatmapScores,\r\n        offsets,\r\n        displacementFwd,\r\n        displacementBwd\r\n      } = this.predictForPersonSegmentationAndPart(resized);\r\n\r\n      const [resizedHeight, resizedWidth] = resized.shape;\r\n\r\n      const scaledSegmentScores = scaleAndCropToInputTensorShape(\r\n          segmentLogits, [height, width], [resizedHeight, resizedWidth],\r\n          [[padding.top, padding.bottom], [padding.left, padding.right]],\r\n          APPLY_SIGMOID_ACTIVATION);\r\n\r\n      const scaledPartHeatmapScore = scaleAndCropToInputTensorShape(\r\n          partHeatmapLogits, [height, width], [resizedHeight, resizedWidth],\r\n          [[padding.top, padding.bottom], [padding.left, padding.right]],\r\n          APPLY_SIGMOID_ACTIVATION);\r\n      const segmentation =\r\n          toMaskTensor(scaledSegmentScores.squeeze(), segmentationThreshold);\r\n      return {\r\n        partSegmentation:\r\n            decodePartSegmentation(segmentation, scaledPartHeatmapScore),\r\n        heatmapScores,\r\n        offsets,\r\n        displacementFwd,\r\n        displacementBwd,\r\n      };\r\n    });\r\n    resized.dispose();\r\n    return {\r\n      partSegmentation,\r\n      heatmapScores,\r\n      offsets,\r\n      displacementFwd,\r\n      displacementBwd,\r\n      padding,\r\n      internalResolutionHeightAndWidth\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Given an image with many people, returns a PartSegmentation dictionary that\r\n   * contains the body part segmentation mask for all people and a single pose.\r\n   *\r\n   * Note: The body part segmentation mask returned by this method covers all\r\n   * people but the pose works well when there is one person. If you want to\r\n   * estimate instance-level multiple person body part segmentation & pose for\r\n   * each person, use `segmentMultiPersonParts` instead.\r\n   *\r\n   * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\r\n   * The input image to feed through the network.\r\n   *\r\n   * @param config PersonInferenceConfig object that contains\r\n   * parameters for the BodyPix inference using single person decoding.\r\n   *\r\n   * @return A SemanticPartSegmentation dictionary that contains height, width,\r\n   * the flattened binary segmentation mask and the pose for the person. The\r\n   * width and height correspond to the same dimensions of the input image.\r\n   * - `height`: The height of the person part segmentation data in pixel unit.\r\n   * - `width`: The width of the person part segmentation data in pixel unit.\r\n   * - `data`: The flattened Int32Array of person part segmentation data with a\r\n   * part id from 0-24 for the pixels that are part of a corresponding body\r\n   * part, and -1 otherwise. The size of the array is equal to `height` x\r\n   * `width` in row-major order.\r\n   * - `allPoses`: The 2d poses of all people.\r\n   */\r\n  async segmentPersonParts(\r\n      input: BodyPixInput,\r\n      config: PersonInferenceConfig = PERSON_INFERENCE_CONFIG):\r\n      Promise<SemanticPartSegmentation> {\r\n    config = {...PERSON_INFERENCE_CONFIG, ...config};\r\n\r\n    validatePersonInferenceConfig(config);\r\n    const {\r\n      partSegmentation,\r\n      heatmapScores,\r\n      offsets,\r\n      displacementFwd,\r\n      displacementBwd,\r\n      padding,\r\n      internalResolutionHeightAndWidth\r\n    } =\r\n        this.segmentPersonPartsActivation(\r\n            input, config.internalResolution, config.segmentationThreshold);\r\n\r\n    const [height, width] = partSegmentation.shape;\r\n    const data = await partSegmentation.data() as Int32Array;\r\n    partSegmentation.dispose();\r\n\r\n    const tensorBuffers = await toTensorBuffers3D(\r\n        [heatmapScores, offsets, displacementFwd, displacementBwd]);\r\n    const [scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf] =\r\n        tensorBuffers;\r\n\r\n    let poses = decodeMultiplePoses(\r\n        scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf,\r\n        this.baseModel.outputStride, config.maxDetections,\r\n        config.scoreThreshold, config.nmsRadius);\r\n\r\n    poses = scaleAndFlipPoses(\r\n        poses, [height, width], internalResolutionHeightAndWidth, padding,\r\n        FLIP_POSES_AFTER_SCALING);\r\n\r\n    heatmapScores.dispose();\r\n    offsets.dispose();\r\n    displacementFwd.dispose();\r\n    displacementBwd.dispose();\r\n\r\n    return {height, width, data, allPoses: poses};\r\n  }\r\n\r\n  /**\r\n   * Given an image with multiple people, returns an *array* of PartSegmentation\r\n   * object. Each element in the array corresponding to one\r\n   * of the people in the input image. In other words, it predicts\r\n   * instance-level multiple person body part segmentation & pose for each\r\n   * person.\r\n   *\r\n   * This does standard ImageNet pre-processing before inferring through\r\n   * the model. The image pixels should have values [0-255].\r\n   *\r\n   * @param input\r\n   * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\r\n   * image to feed through the network.\r\n   *\r\n   * @param config MultiPersonInferenceConfig object that contains\r\n   * parameters for the BodyPix inference using multi-person decoding.\r\n   *\r\n   * @return An array of PartSegmentation object, each containing a width,\r\n   * height, a flattened array (with part id from 0-24 for the pixels that are\r\n   * part of a corresponding body part, and -1 otherwise) and 2D pose. The width\r\n   * and height correspond to the dimensions of the image. Each flattened part\r\n   * segmentation array size is equal to `height` x `width`.\r\n   */\r\n  async segmentMultiPersonParts(\r\n      input: BodyPixInput,\r\n      config: MultiPersonInstanceInferenceConfig =\r\n          MULTI_PERSON_INSTANCE_INFERENCE_CONFIG): Promise<PartSegmentation[]> {\r\n    config = {...MULTI_PERSON_INSTANCE_INFERENCE_CONFIG, ...config};\r\n\r\n    validateMultiPersonInstanceInferenceConfig(config);\r\n    const [height, width] = getInputSize(input);\r\n    const internalResolutionHeightAndWidth = toInputResolutionHeightAndWidth(\r\n        config.internalResolution, this.baseModel.outputStride,\r\n        [height, width]);\r\n    const {resized, padding} =\r\n        padAndResizeTo(input, internalResolutionHeightAndWidth);\r\n    const {\r\n      segmentation,\r\n      longOffsets,\r\n      heatmapScoresRaw,\r\n      offsetsRaw,\r\n      displacementFwdRaw,\r\n      displacementBwdRaw,\r\n      partSegmentation,\r\n    } = tf.tidy(() => {\r\n      const {\r\n        segmentLogits,\r\n        longOffsets,\r\n        heatmapScores,\r\n        offsets,\r\n        displacementFwd,\r\n        displacementBwd,\r\n        partHeatmaps\r\n      } = this.predictForMultiPersonInstanceSegmentationAndPart(resized);\r\n\r\n      // decoding with scaling.\r\n      const scaledSegmentScores = scaleAndCropToInputTensorShape(\r\n          segmentLogits, [height, width], internalResolutionHeightAndWidth,\r\n          [[padding.top, padding.bottom], [padding.left, padding.right]],\r\n          APPLY_SIGMOID_ACTIVATION);\r\n\r\n      // decoding with scaling.\r\n      const scaledPartSegmentationScores = scaleAndCropToInputTensorShape(\r\n          partHeatmaps, [height, width], internalResolutionHeightAndWidth,\r\n          [[padding.top, padding.bottom], [padding.left, padding.right]],\r\n          APPLY_SIGMOID_ACTIVATION);\r\n\r\n      const scaledLongOffsets = longOffsets;\r\n      const segmentation = toMaskTensor(\r\n          scaledSegmentScores.squeeze(), config.segmentationThreshold);\r\n      const partSegmentation =\r\n          decodeOnlyPartSegmentation(scaledPartSegmentationScores);\r\n      return {\r\n        segmentation,\r\n        longOffsets: scaledLongOffsets,\r\n        heatmapScoresRaw: heatmapScores,\r\n        offsetsRaw: offsets,\r\n        displacementFwdRaw: displacementFwd,\r\n        displacementBwdRaw: displacementBwd,\r\n        partSegmentation\r\n      };\r\n    });\r\n\r\n    const tensorBuffers = await toTensorBuffers3D(\r\n        [heatmapScoresRaw, offsetsRaw, displacementFwdRaw, displacementBwdRaw]);\r\n    const [scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf] =\r\n        tensorBuffers;\r\n\r\n    let poses = decodeMultiplePoses(\r\n        scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf,\r\n        this.baseModel.outputStride, config.maxDetections,\r\n        config.scoreThreshold, config.nmsRadius);\r\n\r\n    poses = scaleAndFlipPoses(\r\n        poses, [height, width], internalResolutionHeightAndWidth, padding,\r\n        FLIP_POSES_AFTER_SCALING);\r\n\r\n    const instanceMasks = await decodePersonInstancePartMasks(\r\n        segmentation, longOffsets, partSegmentation, poses, height, width,\r\n        this.baseModel.outputStride, internalResolutionHeightAndWidth, padding,\r\n        config.scoreThreshold, config.refineSteps, config.minKeypointScore,\r\n        config.maxDetections);\r\n\r\n    resized.dispose();\r\n    segmentation.dispose();\r\n    longOffsets.dispose();\r\n    heatmapScoresRaw.dispose();\r\n    offsetsRaw.dispose();\r\n    displacementFwdRaw.dispose();\r\n    displacementBwdRaw.dispose();\r\n    partSegmentation.dispose();\r\n\r\n    return instanceMasks;\r\n  }\r\n\r\n  public dispose() {\r\n    this.baseModel.dispose();\r\n  }\r\n}\r\n\r\n/**\r\n * Loads the MobileNet BodyPix model.\r\n */\r\nasync function loadMobileNet(config: ModelConfig): Promise<BodyPix> {\r\n  const outputStride = config.outputStride;\r\n  const quantBytes = config.quantBytes;\r\n  const multiplier = config.multiplier;\r\n  if (tf == null) {\r\n    throw new Error(\r\n        `Cannot find TensorFlow.js. If you are using a <script> tag, please ` +\r\n        `also include @tensorflow/tfjs on the page before using this\r\n        model.`);\r\n  }\r\n\r\n  const url = mobileNetSavedModel(outputStride, multiplier, quantBytes);\r\n  const graphModel = await tfconv.loadGraphModel(config.modelUrl || url);\r\n  const mobilenet = new MobileNet(graphModel, outputStride);\r\n  return new BodyPix(mobilenet);\r\n}\r\n\r\n/**\r\n * Loads the ResNet BodyPix model.\r\n */\r\nasync function loadResNet(config: ModelConfig): Promise<BodyPix> {\r\n  const outputStride = config.outputStride;\r\n  const quantBytes = config.quantBytes;\r\n  if (tf == null) {\r\n    throw new Error(\r\n        `Cannot find TensorFlow.js. If you are using a <script> tag, please ` +\r\n        `also include @tensorflow/tfjs on the page before using this\r\n        model.`);\r\n  }\r\n\r\n  const url = resNet50SavedModel(outputStride, quantBytes);\r\n  const graphModel = await tfconv.loadGraphModel(config.modelUrl || url);\r\n  const resnet = new ResNet(graphModel, outputStride);\r\n  return new BodyPix(resnet);\r\n}\r\n\r\n/**\r\n * Loads the BodyPix model instance from a checkpoint, with the ResNet\r\n * or MobileNet architecture. The model to be loaded is configurable using the\r\n * config dictionary ModelConfig. Please find more details in the\r\n * documentation of the ModelConfig.\r\n *\r\n * @param config ModelConfig dictionary that contains parameters for\r\n * the BodyPix loading process. Please find more details of each parameters\r\n * in the documentation of the ModelConfig interface. The predefined\r\n * `MOBILENET_V1_CONFIG` and `RESNET_CONFIG` can also be used as references\r\n * for defining your customized config.\r\n */\r\nexport async function load(config: ModelConfig = MOBILENET_V1_CONFIG):\r\n    Promise<BodyPix> {\r\n  config = validateModelConfig(config);\r\n  if (config.architecture === 'ResNet50') {\r\n    return loadResNet(config);\r\n  } else if (config.architecture === 'MobileNetV1') {\r\n    return loadMobileNet(config);\r\n  } else {\r\n    return null;\r\n  }\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2019 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\n// method copied from bGlur in https://codepen.io/zhaojun/pen/zZmRQe\r\nexport function cpuBlur(\r\n    canvas: HTMLCanvasElement,\r\n    image: HTMLImageElement|HTMLVideoElement|HTMLCanvasElement, blur: number) {\r\n  const ctx = canvas.getContext('2d');\r\n\r\n  let sum = 0;\r\n  const delta = 5;\r\n  const alphaLeft = 1 / (2 * Math.PI * delta * delta);\r\n  const step = blur < 3 ? 1 : 2;\r\n  for (let y = -blur; y <= blur; y += step) {\r\n    for (let x = -blur; x <= blur; x += step) {\r\n      const weight =\r\n          alphaLeft * Math.exp(-(x * x + y * y) / (2 * delta * delta));\r\n      sum += weight;\r\n    }\r\n  }\r\n  for (let y = -blur; y <= blur; y += step) {\r\n    for (let x = -blur; x <= blur; x += step) {\r\n      ctx.globalAlpha = alphaLeft *\r\n          Math.exp(-(x * x + y * y) / (2 * delta * delta)) / sum * blur;\r\n      ctx.drawImage(image, x, y);\r\n    }\r\n  }\r\n  ctx.globalAlpha = 1;\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2019 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n * =============================================================================\r\n */\r\n\r\nimport {cpuBlur} from './blur';\r\nimport {Color, PartSegmentation, PersonSegmentation} from './types';\r\nimport {SemanticPartSegmentation, SemanticPersonSegmentation} from './types';\r\nimport {getInputSize} from './util';\r\n\r\nconst offScreenCanvases: {[name: string]: HTMLCanvasElement} = {};\r\n\r\ntype ImageType = HTMLImageElement|HTMLVideoElement|HTMLCanvasElement;\r\ntype HasDimensions = {\r\n  width: number,\r\n  height: number\r\n};\r\n\r\nfunction isSafari() {\r\n  return (/^((?!chrome|android).)*safari/i.test(navigator.userAgent));\r\n}\r\n\r\nfunction assertSameDimensions(\r\n    {width: widthA, height: heightA}: HasDimensions,\r\n    {width: widthB, height: heightB}: HasDimensions, nameA: string,\r\n    nameB: string) {\r\n  if (widthA !== widthB || heightA !== heightB) {\r\n    throw new Error(`error: dimensions must match. ${nameA} has dimensions ${\r\n        widthA}x${heightA}, ${nameB} has dimensions ${widthB}x${heightB}`);\r\n  }\r\n}\r\n\r\nfunction flipCanvasHorizontal(canvas: HTMLCanvasElement) {\r\n  const ctx = canvas.getContext('2d');\r\n  ctx.scale(-1, 1);\r\n  ctx.translate(-canvas.width, 0);\r\n}\r\n\r\nfunction drawWithCompositing(\r\n    ctx: CanvasRenderingContext2D, image: HTMLCanvasElement|ImageType,\r\n    compositOperation: string) {\r\n  ctx.globalCompositeOperation = compositOperation;\r\n  ctx.drawImage(image, 0, 0);\r\n}\r\n\r\nfunction createOffScreenCanvas(): HTMLCanvasElement {\r\n  const offScreenCanvas = document.createElement('canvas');\r\n  return offScreenCanvas;\r\n}\r\n\r\nfunction ensureOffscreenCanvasCreated(id: string): HTMLCanvasElement {\r\n  if (!offScreenCanvases[id]) {\r\n    offScreenCanvases[id] = createOffScreenCanvas();\r\n  }\r\n  return offScreenCanvases[id];\r\n}\r\n\r\nfunction drawAndBlurImageOnCanvas(\r\n    image: ImageType, blurAmount: number, canvas: HTMLCanvasElement) {\r\n  const {height, width} = image;\r\n  const ctx = canvas.getContext('2d');\r\n  canvas.width = width;\r\n  canvas.height = height;\r\n  ctx.clearRect(0, 0, width, height);\r\n  ctx.save();\r\n  if (isSafari()) {\r\n    cpuBlur(canvas, image, blurAmount);\r\n  } else {\r\n    // tslint:disable:no-any\r\n    (ctx as any).filter = `blur(${blurAmount}px)`;\r\n    ctx.drawImage(image, 0, 0, width, height);\r\n  }\r\n  ctx.restore();\r\n}\r\n\r\nfunction drawAndBlurImageOnOffScreenCanvas(\r\n    image: ImageType, blurAmount: number,\r\n    offscreenCanvasName: string): HTMLCanvasElement {\r\n  const canvas = ensureOffscreenCanvasCreated(offscreenCanvasName);\r\n  if (blurAmount === 0) {\r\n    renderImageToCanvas(image, canvas);\r\n  } else {\r\n    drawAndBlurImageOnCanvas(image, blurAmount, canvas);\r\n  }\r\n  return canvas;\r\n}\r\n\r\nfunction renderImageToCanvas(image: ImageType, canvas: HTMLCanvasElement) {\r\n  const {width, height} = image;\r\n  canvas.width = width;\r\n  canvas.height = height;\r\n  const ctx = canvas.getContext('2d');\r\n\r\n  ctx.drawImage(image, 0, 0, width, height);\r\n}\r\n/**\r\n * Draw an image on a canvas\r\n */\r\nfunction renderImageDataToCanvas(image: ImageData, canvas: HTMLCanvasElement) {\r\n  canvas.width = image.width;\r\n  canvas.height = image.height;\r\n  const ctx = canvas.getContext('2d');\r\n\r\n  ctx.putImageData(image, 0, 0);\r\n}\r\n\r\nfunction renderImageDataToOffScreenCanvas(\r\n    image: ImageData, canvasName: string): HTMLCanvasElement {\r\n  const canvas = ensureOffscreenCanvasCreated(canvasName);\r\n  renderImageDataToCanvas(image, canvas);\r\n\r\n  return canvas;\r\n}\r\n\r\n/**\r\n * Given the output from estimating multi-person segmentation, generates an\r\n * image with foreground and background color at each pixel determined by the\r\n * corresponding binary segmentation value at the pixel from the output.  In\r\n * other words, pixels where there is a person will be colored with foreground\r\n * color and where there is not a person will be colored with background color.\r\n *\r\n * @param personOrPartSegmentation The output from\r\n * `segmentPerson`, `segmentMultiPerson`,\r\n * `segmentPersonParts` or `segmentMultiPersonParts`. They can\r\n * be SemanticPersonSegmentation object, an array of PersonSegmentation object,\r\n * SemanticPartSegmentation object, or an array of PartSegmentation object.\r\n *\r\n * @param foreground Default to {r:0, g:0, b:0, a: 0}. The foreground color\r\n * (r,g,b,a) for visualizing pixels that belong to people.\r\n *\r\n * @param background Default to {r:0, g:0, b:0, a: 255}. The background color\r\n * (r,g,b,a) for visualizing pixels that don't belong to people.\r\n *\r\n * @param drawContour Default to false. Whether to draw the contour around each\r\n * person's segmentation mask or body part mask.\r\n *\r\n * @param foregroundIds Default to [1]. The integer values that represent\r\n * foreground. For person segmentation, 1 is the foreground. For body part\r\n * segmentation, it can be a subset of all body parts ids.\r\n *\r\n * @returns An ImageData with the same width and height of\r\n * all the PersonSegmentation in multiPersonSegmentation, with opacity and\r\n * transparency at each pixel determined by the corresponding binary\r\n * segmentation value at the pixel from the output.\r\n */\r\nexport function toMask(\r\n    personOrPartSegmentation: SemanticPersonSegmentation|\r\n    SemanticPartSegmentation|PersonSegmentation[]|PartSegmentation[],\r\n    foreground: Color = {\r\n      r: 0,\r\n      g: 0,\r\n      b: 0,\r\n      a: 0\r\n    },\r\n    background: Color = {\r\n      r: 0,\r\n      g: 0,\r\n      b: 0,\r\n      a: 255\r\n    },\r\n    drawContour = false, foregroundIds: number[] = [1]): ImageData {\r\n  if (Array.isArray(personOrPartSegmentation) &&\r\n      personOrPartSegmentation.length === 0) {\r\n    return null;\r\n  }\r\n\r\n  let multiPersonOrPartSegmentation:\r\n      Array<SemanticPersonSegmentation|SemanticPartSegmentation|\r\n            PersonSegmentation|PartSegmentation>;\r\n\r\n  if (!Array.isArray(personOrPartSegmentation)) {\r\n    multiPersonOrPartSegmentation = [personOrPartSegmentation];\r\n  } else {\r\n    multiPersonOrPartSegmentation = personOrPartSegmentation;\r\n  }\r\n\r\n  const {width, height} = multiPersonOrPartSegmentation[0];\r\n  const bytes = new Uint8ClampedArray(width * height * 4);\r\n\r\n  function drawStroke(\r\n      bytes: Uint8ClampedArray, row: number, column: number, width: number,\r\n      radius: number, color: Color = {r: 0, g: 255, b: 255, a: 255}) {\r\n    for (let i = -radius; i <= radius; i++) {\r\n      for (let j = -radius; j <= radius; j++) {\r\n        if (i !== 0 && j !== 0) {\r\n          const n = (row + i) * width + (column + j);\r\n          bytes[4 * n + 0] = color.r;\r\n          bytes[4 * n + 1] = color.g;\r\n          bytes[4 * n + 2] = color.b;\r\n          bytes[4 * n + 3] = color.a;\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  function isSegmentationBoundary(\r\n      segmentationData: Uint8Array|Int32Array,\r\n      row: number,\r\n      column: number,\r\n      width: number,\r\n      foregroundIds: number[] = [1],\r\n      radius = 1,\r\n      ): boolean {\r\n    let numberBackgroundPixels = 0;\r\n    for (let i = -radius; i <= radius; i++) {\r\n      for (let j = -radius; j <= radius; j++) {\r\n        if (i !== 0 && j !== 0) {\r\n          const n = (row + i) * width + (column + j);\r\n          if (!foregroundIds.some(id => id === segmentationData[n])) {\r\n            numberBackgroundPixels += 1;\r\n          }\r\n        }\r\n      }\r\n    }\r\n    return numberBackgroundPixels > 0;\r\n  }\r\n\r\n  for (let i = 0; i < height; i += 1) {\r\n    for (let j = 0; j < width; j += 1) {\r\n      const n = i * width + j;\r\n      bytes[4 * n + 0] = background.r;\r\n      bytes[4 * n + 1] = background.g;\r\n      bytes[4 * n + 2] = background.b;\r\n      bytes[4 * n + 3] = background.a;\r\n      for (let k = 0; k < multiPersonOrPartSegmentation.length; k++) {\r\n        if (foregroundIds.some(\r\n                id => id === multiPersonOrPartSegmentation[k].data[n])) {\r\n          bytes[4 * n] = foreground.r;\r\n          bytes[4 * n + 1] = foreground.g;\r\n          bytes[4 * n + 2] = foreground.b;\r\n          bytes[4 * n + 3] = foreground.a;\r\n          const isBoundary = isSegmentationBoundary(\r\n              multiPersonOrPartSegmentation[k].data, i, j, width,\r\n              foregroundIds);\r\n          if (drawContour && i - 1 >= 0 && i + 1 < height && j - 1 >= 0 &&\r\n              j + 1 < width && isBoundary) {\r\n            drawStroke(bytes, i, j, width, 1);\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  return new ImageData(bytes, width, height);\r\n}\r\n\r\nconst RAINBOW_PART_COLORS: Array<[number, number, number]> = [\r\n  [110, 64, 170], [143, 61, 178], [178, 60, 178], [210, 62, 167],\r\n  [238, 67, 149], [255, 78, 125], [255, 94, 99],  [255, 115, 75],\r\n  [255, 140, 56], [239, 167, 47], [217, 194, 49], [194, 219, 64],\r\n  [175, 240, 91], [135, 245, 87], [96, 247, 96],  [64, 243, 115],\r\n  [40, 234, 141], [28, 219, 169], [26, 199, 194], [33, 176, 213],\r\n  [47, 150, 224], [65, 125, 224], [84, 101, 214], [99, 81, 195]\r\n];\r\n\r\n/**\r\n * Given the output from person body part segmentation (or multi-person\r\n * instance body part segmentation) and an array of colors indexed by part id,\r\n * generates an image with the corresponding color for each part at each pixel,\r\n * and white pixels where there is no part.\r\n *\r\n * @param partSegmentation The output from segmentPersonParts\r\n * or segmentMultiPersonParts. The former is a SemanticPartSegmentation\r\n * object and later is an array of PartSegmentation object.\r\n *\r\n * @param partColors A multi-dimensional array of rgb colors indexed by\r\n * part id.  Must have 24 colors, one for every part.\r\n *\r\n * @returns An ImageData with the same width and height of all the element in\r\n * multiPersonPartSegmentation, with the corresponding color for each part at\r\n * each pixel, and black pixels where there is no part.\r\n */\r\nexport function toColoredPartMask(\r\n    partSegmentation: SemanticPartSegmentation|PartSegmentation[],\r\n    partColors: Array<[number, number, number]> =\r\n        RAINBOW_PART_COLORS): ImageData {\r\n  if (Array.isArray(partSegmentation) && partSegmentation.length === 0) {\r\n    return null;\r\n  }\r\n\r\n  let multiPersonPartSegmentation;\r\n  if (!Array.isArray(partSegmentation)) {\r\n    multiPersonPartSegmentation = [partSegmentation];\r\n  } else {\r\n    multiPersonPartSegmentation = partSegmentation;\r\n  }\r\n  const {width, height} = multiPersonPartSegmentation[0];\r\n  const bytes = new Uint8ClampedArray(width * height * 4);\r\n\r\n  for (let i = 0; i < height * width; ++i) {\r\n    // invert mask.  Invert the segmentation mask.\r\n    const j = i * 4;\r\n    bytes[j + 0] = 255;\r\n    bytes[j + 1] = 255;\r\n    bytes[j + 2] = 255;\r\n    bytes[j + 3] = 255;\r\n    for (let k = 0; k < multiPersonPartSegmentation.length; k++) {\r\n      const partId = multiPersonPartSegmentation[k].data[i];\r\n      if (partId !== -1) {\r\n        const color = partColors[partId];\r\n        if (!color) {\r\n          throw new Error(`No color could be found for part id ${partId}`);\r\n        }\r\n        bytes[j + 0] = color[0];\r\n        bytes[j + 1] = color[1];\r\n        bytes[j + 2] = color[2];\r\n        bytes[j + 3] = 255;\r\n      }\r\n    }\r\n  }\r\n  return new ImageData(bytes, width, height);\r\n}\r\n\r\nconst CANVAS_NAMES = {\r\n  blurred: 'blurred',\r\n  blurredMask: 'blurred-mask',\r\n  mask: 'mask',\r\n  lowresPartMask: 'lowres-part-mask',\r\n};\r\n\r\n/**\r\n * Given an image and a maskImage of type ImageData, draws the image with the\r\n * mask on top of it onto a canvas.\r\n *\r\n * @param canvas The canvas to be drawn onto.\r\n *\r\n * @param image The original image to apply the mask to.\r\n *\r\n * @param maskImage An ImageData containing the mask.  Ideally this should be\r\n * generated by toMask or toColoredPartMask.\r\n *\r\n * @param maskOpacity The opacity of the mask when drawing it on top of the\r\n * image. Defaults to 0.7. Should be a float between 0 and 1.\r\n *\r\n * @param maskBlurAmount How many pixels to blur the mask by. Defaults to 0.\r\n * Should be an integer between 0 and 20.\r\n *\r\n * @param flipHorizontal If the result should be flipped horizontally.  Defaults\r\n * to false.\r\n */\r\nexport function drawMask(\r\n    canvas: HTMLCanvasElement, image: ImageType, maskImage: ImageData|null,\r\n    maskOpacity = 0.7, maskBlurAmount = 0, flipHorizontal = false) {\r\n  const [height, width] = getInputSize(image);\r\n  canvas.width = width;\r\n  canvas.height = height;\r\n\r\n  const ctx = canvas.getContext('2d');\r\n  ctx.save();\r\n  if (flipHorizontal) {\r\n    flipCanvasHorizontal(canvas);\r\n  }\r\n\r\n  ctx.drawImage(image, 0, 0);\r\n\r\n  ctx.globalAlpha = maskOpacity;\r\n  if (maskImage) {\r\n    assertSameDimensions({width, height}, maskImage, 'image', 'mask');\r\n\r\n    const mask = renderImageDataToOffScreenCanvas(maskImage, CANVAS_NAMES.mask);\r\n\r\n    const blurredMask = drawAndBlurImageOnOffScreenCanvas(\r\n        mask, maskBlurAmount, CANVAS_NAMES.blurredMask);\r\n    ctx.drawImage(blurredMask, 0, 0, width, height);\r\n  }\r\n  ctx.restore();\r\n}\r\n\r\n/**\r\n * Given an image and a maskImage of type ImageData, draws the image with the\r\n * pixelated mask on top of it onto a canvas.\r\n *\r\n * @param canvas The canvas to be drawn onto.\r\n *\r\n * @param image The original image to apply the mask to.\r\n *\r\n * @param maskImage An ImageData containing the mask.  Ideally this should be\r\n * generated by toColoredPartMask.\r\n *\r\n * @param maskOpacity The opacity of the mask when drawing it on top of the\r\n * image. Defaults to 0.7. Should be a float between 0 and 1.\r\n *\r\n * @param maskBlurAmount How many pixels to blur the mask by. Defaults to 0.\r\n * Should be an integer between 0 and 20.\r\n *\r\n * @param flipHorizontal If the result should be flipped horizontally.  Defaults\r\n * to false.\r\n *\r\n * @param pixelCellWidth The width of each pixel cell. Default to 10 px.\r\n */\r\nexport function drawPixelatedMask(\r\n    canvas: HTMLCanvasElement, image: ImageType, maskImage: ImageData,\r\n    maskOpacity = 0.7, maskBlurAmount = 0, flipHorizontal = false,\r\n    pixelCellWidth = 10.0) {\r\n  const [height, width] = getInputSize(image);\r\n  assertSameDimensions({width, height}, maskImage, 'image', 'mask');\r\n\r\n  const mask = renderImageDataToOffScreenCanvas(maskImage, CANVAS_NAMES.mask);\r\n  const blurredMask = drawAndBlurImageOnOffScreenCanvas(\r\n      mask, maskBlurAmount, CANVAS_NAMES.blurredMask);\r\n\r\n  canvas.width = blurredMask.width;\r\n  canvas.height = blurredMask.height;\r\n\r\n  const ctx = canvas.getContext('2d');\r\n  ctx.save();\r\n  if (flipHorizontal) {\r\n    flipCanvasHorizontal(canvas);\r\n  }\r\n\r\n  const offscreenCanvas =\r\n      ensureOffscreenCanvasCreated(CANVAS_NAMES.lowresPartMask);\r\n  const offscreenCanvasCtx = offscreenCanvas.getContext('2d');\r\n  offscreenCanvas.width = blurredMask.width * (1.0 / pixelCellWidth);\r\n  offscreenCanvas.height = blurredMask.height * (1.0 / pixelCellWidth);\r\n  offscreenCanvasCtx.drawImage(\r\n      blurredMask, 0, 0, blurredMask.width, blurredMask.height, 0, 0,\r\n      offscreenCanvas.width, offscreenCanvas.height);\r\n  ctx.imageSmoothingEnabled = false;\r\n  ctx.drawImage(\r\n      offscreenCanvas, 0, 0, offscreenCanvas.width, offscreenCanvas.height, 0,\r\n      0, canvas.width, canvas.height);\r\n\r\n  // Draws vertical grid lines that are `pixelCellWidth` apart from each other.\r\n  for (let i = 0; i < offscreenCanvas.width; i++) {\r\n    ctx.beginPath();\r\n    ctx.strokeStyle = '#ffffff';\r\n    ctx.moveTo(pixelCellWidth * i, 0);\r\n    ctx.lineTo(pixelCellWidth * i, canvas.height);\r\n    ctx.stroke();\r\n  }\r\n\r\n  // Draws horizontal grid lines that are `pixelCellWidth` apart from each\r\n  // other.\r\n  for (let i = 0; i < offscreenCanvas.height; i++) {\r\n    ctx.beginPath();\r\n    ctx.strokeStyle = '#ffffff';\r\n    ctx.moveTo(0, pixelCellWidth * i);\r\n    ctx.lineTo(canvas.width, pixelCellWidth * i);\r\n    ctx.stroke();\r\n  }\r\n\r\n  ctx.globalAlpha = 1.0 - maskOpacity;\r\n  ctx.drawImage(image, 0, 0, blurredMask.width, blurredMask.height);\r\n  ctx.restore();\r\n}\r\n\r\nfunction createPersonMask(\r\n    multiPersonSegmentation: PersonSegmentation[]|SemanticPersonSegmentation,\r\n    edgeBlurAmount: number): HTMLCanvasElement {\r\n  const backgroundMaskImage = toMask(\r\n      multiPersonSegmentation, {r: 0, g: 0, b: 0, a: 255},\r\n      {r: 0, g: 0, b: 0, a: 0});\r\n\r\n  const backgroundMask =\r\n      renderImageDataToOffScreenCanvas(backgroundMaskImage, CANVAS_NAMES.mask);\r\n  if (edgeBlurAmount === 0) {\r\n    return backgroundMask;\r\n  } else {\r\n    return drawAndBlurImageOnOffScreenCanvas(\r\n        backgroundMask, edgeBlurAmount, CANVAS_NAMES.blurredMask);\r\n  }\r\n}\r\n\r\n/**\r\n * Given a personSegmentation and an image, draws the image with its background\r\n * blurred onto the canvas.\r\n *\r\n * @param canvas The canvas to draw the background-blurred image onto.\r\n *\r\n * @param image The image to blur the background of and draw.\r\n *\r\n * @param personSegmentation A SemanticPersonSegmentation or an array of\r\n * PersonSegmentation object.\r\n *\r\n * @param backgroundBlurAmount How many pixels in the background blend into each\r\n * other.  Defaults to 3. Should be an integer between 1 and 20.\r\n *\r\n * @param edgeBlurAmount How many pixels to blur on the edge between the person\r\n * and the background by.  Defaults to 3. Should be an integer between 0 and 20.\r\n *\r\n * @param flipHorizontal If the output should be flipped horizontally.  Defaults\r\n * to false.\r\n */\r\nexport function drawBokehEffect(\r\n    canvas: HTMLCanvasElement, image: ImageType,\r\n    multiPersonSegmentation: SemanticPersonSegmentation|PersonSegmentation[],\r\n    backgroundBlurAmount = 3, edgeBlurAmount = 3, flipHorizontal = false) {\r\n  const blurredImage = drawAndBlurImageOnOffScreenCanvas(\r\n      image, backgroundBlurAmount, CANVAS_NAMES.blurred);\r\n  canvas.width = blurredImage.width;\r\n  canvas.height = blurredImage.height;\r\n\r\n  const ctx = canvas.getContext('2d');\r\n\r\n  if (Array.isArray(multiPersonSegmentation) &&\r\n      multiPersonSegmentation.length === 0) {\r\n    ctx.drawImage(blurredImage, 0, 0);\r\n    return;\r\n  }\r\n\r\n  const personMask = createPersonMask(multiPersonSegmentation, edgeBlurAmount);\r\n\r\n  ctx.save();\r\n  if (flipHorizontal) {\r\n    flipCanvasHorizontal(canvas);\r\n  }\r\n  // draw the original image on the final canvas\r\n  const [height, width] = getInputSize(image);\r\n  ctx.drawImage(image, 0, 0, width, height);\r\n\r\n  // \"destination-in\" - \"The existing canvas content is kept where both the\r\n  // new shape and existing canvas content overlap. Everything else is made\r\n  // transparent.\"\r\n  // crop what's not the person using the mask from the original image\r\n  drawWithCompositing(ctx, personMask, 'destination-in');\r\n  // \"destination-over\" - \"The existing canvas content is kept where both the\r\n  // new shape and existing canvas content overlap. Everything else is made\r\n  // transparent.\"\r\n  // draw the blurred background on top of the original image where it doesn't\r\n  // overlap.\r\n  drawWithCompositing(ctx, blurredImage, 'destination-over');\r\n  ctx.restore();\r\n}\r\n\r\nfunction createBodyPartMask(\r\n    multiPersonPartSegmentation: SemanticPartSegmentation|PartSegmentation[],\r\n    bodyPartIdsToMask: number[], edgeBlurAmount: number): HTMLCanvasElement {\r\n  const backgroundMaskImage = toMask(\r\n      multiPersonPartSegmentation, {r: 0, g: 0, b: 0, a: 0},\r\n      {r: 0, g: 0, b: 0, a: 255}, true, bodyPartIdsToMask);\r\n\r\n  const backgroundMask =\r\n      renderImageDataToOffScreenCanvas(backgroundMaskImage, CANVAS_NAMES.mask);\r\n  if (edgeBlurAmount === 0) {\r\n    return backgroundMask;\r\n  } else {\r\n    return drawAndBlurImageOnOffScreenCanvas(\r\n        backgroundMask, edgeBlurAmount, CANVAS_NAMES.blurredMask);\r\n  }\r\n}\r\n\r\n/**\r\n * Given a personSegmentation and an image, draws the image with its background\r\n * blurred onto the canvas.\r\n *\r\n * @param canvas The canvas to draw the background-blurred image onto.\r\n *\r\n * @param image The image to blur the background of and draw.\r\n *\r\n * @param partSegmentation A SemanticPartSegmentation or an array of\r\n * PartSegmentation object.\r\n *\r\n * @param bodyPartIdsToBlur Default to [0, 1] (left-face and right-face). An\r\n * array of body part ids to blur. Each must be one of the 24 body part ids.\r\n *\r\n * @param backgroundBlurAmount How many pixels in the background blend into each\r\n * other.  Defaults to 3. Should be an integer between 1 and 20.\r\n *\r\n * @param edgeBlurAmount How many pixels to blur on the edge between the person\r\n * and the background by.  Defaults to 3. Should be an integer between 0 and 20.\r\n *\r\n * @param flipHorizontal If the output should be flipped horizontally.  Defaults\r\n * to false.\r\n */\r\nexport function blurBodyPart(\r\n    canvas: HTMLCanvasElement, image: ImageType,\r\n    partSegmentation: SemanticPartSegmentation|PartSegmentation[],\r\n    bodyPartIdsToBlur = [0, 1], backgroundBlurAmount = 3, edgeBlurAmount = 3,\r\n    flipHorizontal = false) {\r\n  const blurredImage = drawAndBlurImageOnOffScreenCanvas(\r\n      image, backgroundBlurAmount, CANVAS_NAMES.blurred);\r\n  canvas.width = blurredImage.width;\r\n  canvas.height = blurredImage.height;\r\n\r\n  const ctx = canvas.getContext('2d');\r\n\r\n  if (Array.isArray(partSegmentation) && partSegmentation.length === 0) {\r\n    ctx.drawImage(blurredImage, 0, 0);\r\n    return;\r\n  }\r\n  const bodyPartMask =\r\n      createBodyPartMask(partSegmentation, bodyPartIdsToBlur, edgeBlurAmount);\r\n\r\n  ctx.save();\r\n  if (flipHorizontal) {\r\n    flipCanvasHorizontal(canvas);\r\n  }\r\n  // draw the original image on the final canvas\r\n  const [height, width] = getInputSize(image);\r\n  ctx.drawImage(image, 0, 0, width, height);\r\n\r\n  // \"destination-in\" - \"The existing canvas content is kept where both the\r\n  // new shape and existing canvas content overlap. Everything else is made\r\n  // transparent.\"\r\n  // crop what's not the person using the mask from the original image\r\n  drawWithCompositing(ctx, bodyPartMask, 'destination-in');\r\n  // \"destination-over\" - \"The existing canvas content is kept where both the\r\n  // new shape and existing canvas content overlap. Everything else is made\r\n  // transparent.\"\r\n  // draw the blurred background on top of the original image where it doesn't\r\n  // overlap.\r\n  drawWithCompositing(ctx, blurredImage, 'destination-over');\r\n  ctx.restore();\r\n}\r\n","/**\r\n * @license\r\n * Copyright 2020 Google Inc. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n *\r\n * =============================================================================\r\n */\r\n\r\nexport const PART_CHANNELS: string[] = [\r\n  'left_face',\r\n  'right_face',\r\n  'left_upper_arm_front',\r\n  'left_upper_arm_back',\r\n  'right_upper_arm_front',\r\n  'right_upper_arm_back',\r\n  'left_lower_arm_front',\r\n  'left_lower_arm_back',\r\n  'right_lower_arm_front',\r\n  'right_lower_arm_back',\r\n  'left_hand',\r\n  'right_hand',\r\n  'torso_front',\r\n  'torso_back',\r\n  'left_upper_leg_front',\r\n  'left_upper_leg_back',\r\n  'right_upper_leg_front',\r\n  'right_upper_leg_back',\r\n  'left_lower_leg_front',\r\n  'left_lower_leg_back',\r\n  'right_lower_leg_front',\r\n  'right_lower_leg_back',\r\n  'left_feet',\r\n  'right_feet'\r\n];\r\n","/** @license See the LICENSE file. */\r\n\r\n// This code is auto-generated, do not modify this file!\r\nconst version = '2.0.5';\r\nexport {version};\r\n"],"names":["toFlattenedOneHotPartMap","partHeatmapScores","numParts","shape","partMapFlattened","argMax","reshape","tf.oneHot","clipByMask2d","image","mask","mul","toMaskTensor","segmentScores","threshold","tf.tidy","greater","tf.scalar","toInt","decodePartSegmentation","segmentationMask","_a","partMapHeight","partMapWidth","flattenedMap","partNumbers","tf.range","expandDims","matMul","add","sub","decodeOnlyPartSegmentation","model","outputStride","this","inputShape","inputs","tf.util","assert","BaseModel","input","asBatch","_this","preprocessInput","toFloat","results3d","predict","map","y","squeeze","namedResults","nameOutputResults","heatmapScores","heatmap","sigmoid","offsets","displacementFwd","displacementBwd","segmentation","partHeatmaps","longOffsets","partOffsets","dispose","tslib_1.__extends","MobileNet","tf.div","results","PART_NAMES","NUM_KEYPOINTS","length","PART_IDS","reduce","result","jointName","i","CONNECTED_PART_NAMES","POSE_CHAIN","CONNECTED_PART_INDICES","jointNameA","jointNameB","getScale","_b","padding","height","width","inputResolutionY","inputResolutionX","padT","padB","getOffsetPoint","x","keypoint","get","getImageCoords","part","heatmapX","heatmapY","clamp","a","min","max","squaredDistance","y1","x1","y2","x2","dy","dx","addVectors","b","computeDistance","embedding","pose","minPartScore","distance","numKpt","p","keypoints","score","Math","position","Infinity","convertToPositionInOuput","stride","padL","scaleX","scaleY","round","getEmbedding","location","keypointIndex","convertToPosition","outputResolutionX","refineSteps","newLocation","nn","t","newPos","nn_1","matchEmbeddingToInstance","poses","numKptForMatching","_c","embed","pair","keypointsIndex","push","kMin","kMinDist","k","dist","getOutputResolution","decodeMultipleMasksCPU","posesAboveScore","inHeight","inWidth","dataArrays","Uint8Array","fill","j","n","decodeMultiplePartMasksCPU","partSegmentaion","Int32Array","decodeMultipleMasksWebGl","minKptScore","maxNumPeople","origHeight","origWidth","outHeight","outWidth","shapedLongOffsets","poseVals","Float32Array","poseOffset","kp","offset","_d","posesTensor","tf.tensor","program","variableNames","outputShape","userCode","tf.backend","compileAndRun","toPersonKSegmentation","equal","toPersonKPartSegmentation","bodyParts","isWebGlBackend","getBackend","decodePersonInstanceMasks","minPoseScore","minKeypointScore","filter","personSegmentations","masksTensor","_","Promise","all","data","personSegmentationsData","forEach","segmentationsData","longOffsetsData","decodePersonInstancePartMasks","partSegmentation","partSegmentations","partSegmentationsByPersonData","partSegmentaionData","half","floor","maxSize","getElementValue","priorityQueue","Array","numberOfElements","MaxHeap","swim","exchange","sink","slice","less","getValueAt","scoreIsMaximumInLocalWindow","keypointId","localMaximumRadius","scores","localMaximum","yStart","yEnd","yCurrent","xStart","xEnd","xCurrent","buildPartWithScoreQueue","scoreThreshold","numKeypoints","queue","enqueue","id","parentChildrenTuples","parentJoinName","childJoinName","parentToChildEdges","childToParentEdges","getDisplacement","edgeId","point","displacements","numEdges","getStridedIndexNearPoint","traverseToTargetKeypoint","sourceKeypoint","targetKeypointId","scoresBuffer","offsetRefineStep","displacement","targetKeypoint","targetKeypointIndices","offsetPoint","targetKeyPointIndices","decodePose","root","displacementsFwd","displacementsBwd","instanceKeypoints","rootPart","rootScore","rootPoint","edge","sourceKeypointId","withinNmsRadiusOfCorrespondingPoint","squaredNmsRadius","some","correspondingKeypoint","getInstanceScore","existingPoses","kLocalMaximumRadius","decodeMultiplePoses","offsetsBuffer","displacementsFwdBuffer","displacementsBwdBuffer","maxPoseDetections","nmsRadius","empty","dequeue","imageNetMean","ResNet","RESNET50_BASE_URL","MOBILENET_BASE_URL","resNet50SavedModel","quantBytes","graphJson","mobileNetSavedModel","multiplier","toStr","1","0.75","0.5","getSizeFromImageLikeElement","offsetHeight","offsetWidth","Error","getSizeFromVideoElement","videoHeight","videoWidth","getInputSize","HTMLCanvasElement","HTMLImageElement","ImageData","HTMLVideoElement","tf.Tensor","isValidInputResolution","resolution","toValidInputResolution","inputResolution","INTERNAL_RESOLUTION_STRING_OPTIONS","low","medium","high","full","INTERNAL_RESOLUTION_PERCENTAGES","MIN_INTERNAL_RESOLUTION","MAX_INTERNAL_RESOLUTION","toInternalResolutionPercentage","internalResolution","Object","values","join","toInputResolutionHeightAndWidth","inputHeight","inputWidth","internalResolutionPercentage","toInputTensor","tf.browser","fromPixels","resizeAndPadTo","imageTensor","flipHorizontal","targetH","targetW","resizeW","resizeH","padR","aspect","padHeight","ceil","padWidth","resizedAndPadded","resized","reverse","resizeBilinear","tf.pad3d","paddedBy","scaleAndCropToInputTensorShape","tensor","applySigmoidActivation","inputTensorHeight","inputTensorWidth","resizedAndPaddedHeight","resizedAndPaddedWidth","_e","inResizedAndPadded","removePaddingAndResizeBack","originalHeight","originalWidth","batchedImage","tf.image","cropAndResize","padAndResizeTo","targetAspect","top","left","right","bottom","toTensorBuffers3D","tensors","buffer","scalePose","offsetY","offsetX","scalePoses","flipPoseHorizontal","imageWidth","flipPosesHorizontal","scaleAndFlipPoses","inputResolutionHeight","inputResolutionWidth","scaledPoses","APPLY_SIGMOID_ACTIVATION","FLIP_POSES_AFTER_SCALING","MOBILENET_V1_CONFIG","architecture","VALID_ARCHITECTURE","VALID_STRIDE","MobileNetV1","ResNet50","VALID_MULTIPLIER","VALID_QUANT_BYTES","validateModelConfig","config","indexOf","PERSON_INFERENCE_CONFIG","segmentationThreshold","maxDetections","MULTI_PERSON_INSTANCE_INFERENCE_CONFIG","validatePersonInferenceConfig","validateMultiPersonInstanceInferenceConfig","net","baseModel","BodyPix","segmentLogits","partHeatmapLogits","internalResolutionHeightAndWidth","segmentationScores","segmentPersonActivation","tensorBuffers","scoresBuf","offsetsBuf","displacementsFwdBuf","displacementsBwdBuf","allPoses","scaledLongOffsets","heatmapScoresRaw","offsetsRaw","displacementFwdRaw","displacementBwdRaw","instanceMasks","segmentPersonPartsActivation","scaledSegmentScores","scaledPartSegmentationScores","loadMobileNet","tf","url","tfconv.loadGraphModel","modelUrl","graphModel","mobilenet","loadResNet","resnet","load","cpuBlur","canvas","blur","ctx","getContext","sum","alphaLeft","PI","step","exp","globalAlpha","drawImage","offScreenCanvases","isSafari","test","navigator","userAgent","assertSameDimensions","nameA","nameB","widthA","heightA","widthB","heightB","flipCanvasHorizontal","scale","translate","drawWithCompositing","compositOperation","globalCompositeOperation","createOffScreenCanvas","document","createElement","ensureOffscreenCanvasCreated","drawAndBlurImageOnCanvas","blurAmount","clearRect","save","restore","drawAndBlurImageOnOffScreenCanvas","offscreenCanvasName","renderImageToCanvas","renderImageDataToCanvas","putImageData","renderImageDataToOffScreenCanvas","canvasName","toMask","personOrPartSegmentation","foreground","background","drawContour","foregroundIds","r","g","isArray","multiPersonOrPartSegmentation","bytes","Uint8ClampedArray","drawStroke","row","column","radius","color","isSegmentationBoundary","segmentationData","numberBackgroundPixels","n_1","isBoundary","RAINBOW_PART_COLORS","toColoredPartMask","partColors","multiPersonPartSegmentation","partId","CANVAS_NAMES","blurred","blurredMask","lowresPartMask","drawMask","maskImage","maskOpacity","maskBlurAmount","drawPixelatedMask","pixelCellWidth","offscreenCanvas","offscreenCanvasCtx","imageSmoothingEnabled","beginPath","strokeStyle","moveTo","lineTo","stroke","createPersonMask","multiPersonSegmentation","edgeBlurAmount","backgroundMask","drawBokehEffect","backgroundBlurAmount","blurredImage","personMask","createBodyPartMask","bodyPartIdsToMask","blurBodyPart","bodyPartIdsToBlur","bodyPartMask","PART_CHANNELS","version"],"mappings":";;;;;;;;;;;;;;;;wlEAyBA,SAASA,yBAAyBC,GAChC,IAAMC,EAAWD,EAAkBE,MAAM,GAGnCC,EAFmBH,EAAkBI,OAAO,GAERC,UAAU,IAEpD,OAAOC,OAAUH,EAAkBF,GAGrC,SAASM,aAAaC,EAAoBC,GACxC,OAAOD,EAAME,IAAID,GAgBnB,SAAgBE,aACZC,EAA4BC,GAC9B,OAAOC,KACH,WACI,OAACF,EAAcG,QAAQC,OAAUH,IAAYI,UAkBvD,SAAgBC,uBACZC,EACAnB,GACI,IAAAoB,UAACC,OAAeC,OAAcrB,OACpC,OAAOa,KAAQ,WACb,IAAMS,EAAexB,yBAAyBC,GACxCwB,EAAcC,MAAS,EAAGxB,EAAU,EAAG,SAASyB,WAAW,GASjE,OAAOnB,aANHgB,EAAaI,OAAOH,GAA4BP,QAEnBZ,SAASgB,EAAeC,IAEbM,IAAIZ,OAAU,EAAG,UAGNG,GAClDU,IAAIb,OAAU,EAAG,YAI1B,SAAgBc,2BAA2B9B,GAEnC,IAAAoB,UAACC,OAAeC,OAAcrB,OACpC,OAAOa,KAAQ,WACb,IAAMS,EAAexB,yBAAyBC,GACxCwB,EAAcC,MAAS,EAAGxB,EAAU,EAAG,SAASyB,WAAW,GAKjE,OAFIH,EAAaI,OAAOH,GAA4BP,QAE5BZ,SAASgB,EAAeC,MCzEpD,yBACE,WACuBS,EACHC,GADGC,WAAAF,EACHE,kBAAAD,EAClB,IAAME,EACFD,KAAKF,MAAMI,OAAO,GAAGjC,MACzBkC,KAAQC,QACgB,IAAnBH,EAAW,KAAkC,IAAnBA,EAAW,GACtC,WAAM,MAAA,gBAAgBA,EAAW,QAAOA,EAAW,qCAyE3D,OAjDEI,oBAAA,SAAQC,GAAR,WAUE,OAAOzB,KAAQ,WACb,IACM0B,EADUC,EAAKC,gBAAgBH,EAAMI,WACnBjB,WAAW,GAE7BkB,EADUH,EAAKV,MAAMc,QAAQL,GACMM,IAAI,SAAAC,GAAK,OAAAA,EAAEC,SAAS,MACvDC,EAAeR,EAAKS,kBAAkBN,GAE5C,OACEO,cAAeF,EAAaG,QAAQC,UACpCC,QAASL,EAAaK,QACtBC,gBAAiBN,EAAaM,gBAC9BC,gBAAiBP,EAAaO,gBAC9BC,aAAcR,EAAaQ,aAC3BC,aAAcT,EAAaS,aAC3BC,YAAaV,EAAaU,YAC1BC,YAAaX,EAAaW,gBAqBhCtB,oBAAA,WACEL,KAAKF,MAAM8B,sCCzFf,4DA4BA,OA5B+BC,eAC7BC,4BAAA,SAAgBxB,GAEd,OAAOzB,KAAQ,WAAM,OAAAkD,IAAOzB,EAAO,OAAOV,IAAI,MAGhDkC,8BAAA,SAAkBE,GAWhB,OACEX,aACAG,kBACAC,kBACAC,iBACAP,aACAG,qBACAC,qBACAI,sBAzByBtB,WCAlB4B,YACX,OAAQ,UAAW,WAAY,UAAW,WAAY,eACtD,gBAAiB,YAAa,aAAc,YAAa,aACzD,UAAW,WAAY,WAAY,YAAa,YAAa,cAGlDC,cAAgBD,WAAWE,OAM3BC,SACTH,WAAWI,OAAO,SAACC,EAAoBC,EAAWC,GAEhD,OADAF,EAAOC,GAAaC,EACbF,OAGPG,uBACH,UAAW,iBAAkB,YAAa,iBAC1C,YAAa,cAAe,UAAW,aACvC,WAAY,cAAe,WAAY,kBACvC,aAAc,kBAAmB,aAAc,eAC/C,WAAY,cAAe,YAAa,eACxC,eAAgB,kBAAmB,UAAW,aASpCC,aACV,OAAQ,YAAa,UAAW,YAAa,OAAQ,aACrD,WAAY,aAAc,OAAQ,iBAClC,eAAgB,cAAe,YAAa,cAC5C,eAAgB,YAAa,UAAW,aACxC,WAAY,cAAe,OAAQ,kBACnC,gBAAiB,eAAgB,aAAc,eAC/C,gBAAiB,aAAc,WAAY,cAC3C,YAAa,eAGHC,uBAAyBF,qBAAqB5B,IACvD,SAAC1B,OAACyD,OAAYC,OACV,OAAET,SAASQ,GAAaR,SAASS,eC/CzBC,SACZ3D,EACA4D,EACAC,OAFCC,OAAQC,OACRC,OAAkBC,OAEdC,QAAWC,WAGlB,OADeF,kBAAkCF,GADlCC,GAAoBE,EAAOC,EAAOL,IAKnD,SAAgBM,eACZzC,EAAW0C,EAAWC,EAAkBpC,GAC1C,OACEP,EAAGO,EAAQqC,IAAI5C,EAAG0C,EAAGC,GACrBD,EAAGnC,EAAQqC,IAAI5C,EAAG0C,EAAGC,EAAWvB,gBAIpC,SAAgByB,eACZC,EAAY7D,EAAsBsB,GAC7B,IACDlC,+CAAC2B,MAAG0C,MACV,OACEA,EAAGI,EAAKC,SAAW9D,EAAeyD,EAClC1C,EAAG8C,EAAKE,SAAW/D,EAAee,GAItC,SAUgBiD,MAAMC,EAAWC,EAAaC,GAC5C,OAAIF,EAAIC,EACCA,EAELD,EAAIE,EACCA,EAEFF,EAGT,SAAgBG,gBACZC,EAAYC,EAAYC,EAAYC,GACtC,IAAMC,EAAKF,EAAKF,EACVK,EAAKF,EAAKF,EAChB,OAAOG,EAAKA,EAAKC,EAAKA,EAGxB,SAAgBC,WAAWV,EAAaW,GACtC,OAAQnB,EAAGQ,EAAER,EAAImB,EAAEnB,EAAG1C,EAAGkD,EAAElD,EAAI6D,EAAE7D,GCjDnC,SAAS8D,gBAAgBC,EAAmBC,EAAYC,gBAAAA,MAGtD,IAFA,IAAIC,EAAW,EACXC,EAAS,EACJC,EAAI,EAAGA,EAAIL,EAAU1C,OAAQ+C,IAChCJ,EAAKK,UAAUD,GAAGE,MAAQL,IAC5BE,GAAU,EACVD,GAAYK,SAACR,EAAUK,GAAG1B,EAAIsB,EAAKK,UAAUD,GAAGI,SAAS9B,EAAM,GAC3D6B,SAACR,EAAUK,GAAGpE,EAAIgE,EAAKK,UAAUD,GAAGI,SAASxE,EAAM,IAQ3D,OALe,IAAXmE,EACFD,EAAWO,EAAAA,EAEXP,GAAsBC,EAEjBD,EAGT,SAASQ,yBACLF,EAAgBnG,EAChB4D,EAAoC0C,OADnBpC,OAAMqC,OACtBC,OAAQC,OACL9E,EAAIuE,KAAKQ,QAAQxC,EAAOiC,EAASxE,EAAI,GAAO8E,EAAS,GAAOH,GAElE,OAAQjC,EADE6B,KAAKQ,QAAQH,EAAOJ,EAAS9B,EAAI,GAAOmC,EAAS,GAAOF,GACvD3E,KAGb,SAASgF,aACLC,EAAgBC,EAChBC,EAAyCC,EACzCxE,EAA2ByE,EAC3BhH,GAQF,QARG8D,OAAQC,OACLkD,EAAcH,EAAkBF,GAEhCM,EAAKD,EAAYtF,EAAIoF,EAAoBE,EAAY5C,EACvDgB,EAAK9C,EAAYQ,eAAiB,EAAImE,GAAML,GAC5CvB,EAAK/C,EAAYQ,eAAiB,EAAImE,EAAK,GAAKL,GAChDlF,EAAIiF,EAASjF,EAAI0D,EACjBhB,EAAIuC,EAASvC,EAAIiB,EACZ6B,EAAI,EAAGA,EAAIH,EAAaG,IAAK,CACpCxF,EAAIuE,KAAKpB,IAAInD,EAAGmC,EAAS,GAEzB,IAAMsD,EAASN,GAAmBzC,EADlCA,EAAI6B,KAAKpB,IAAIT,EAAGN,EAAQ,GACapC,MAC/B0F,EAAKD,EAAOzF,EAAIoF,EAAoBK,EAAO/C,EAGjD1C,GAFA0D,EAAK9C,EAAYQ,eAAiB,EAAIsE,GAAMR,GAG5CxC,GAFAiB,EAAK/C,EAAYQ,eAAiB,EAAIsE,EAAK,GAAKR,GAKlD,OAAQxC,IAAG1C,KAGb,SAAS2F,yBACLV,EAAgBrE,EAA2BgF,EAC3CC,EAA2BxH,EAC3B4D,EAAoCmD,EACpCU,EAAmCnB,EACnCU,GAKF,QAR8B9C,OAAMqC,OACjCC,OAAQC,OACR3C,OAAQC,OAEL2D,KACAZ,EAAoB,SAACa,GACvB,OAAAtB,yBAAyBsB,GAAOzD,EAAMqC,IAAQC,EAAQC,GAASH,IAE1DsB,EAAiB,EAAGA,EAAiBJ,EACzCI,IAAkB,CACrB,IAAMlC,EAAYiB,aACdC,EAAUgB,EAAgBd,EAAmBC,EAC7CxE,EAAayE,GAAclD,EAAQC,IAEvC2D,EAAMG,KAAKnC,GAKb,IAFA,IAAIoC,GAAQ,EACRC,EAAW3B,EAAAA,EACN4B,EAAI,EAAGA,EAAIT,EAAMvE,OAAQgF,IAAK,CACrC,IAAMC,EAAOxC,gBAAgBiC,EAAOH,EAAMS,IACtCC,EAAOF,IACTD,EAAOE,EACPD,EAAWE,GAGf,OAAOH,EAGT,SAASI,oBACLlI,EACAsG,OADCtC,OAAkBC,OAIrB,OAF0BiC,KAAKQ,OAAOzC,EAAmB,GAAOqC,EAAS,GAC/CJ,KAAKQ,OAAO1C,EAAmB,GAAOsC,EAAS,IAI3E,SAAgB6B,uBACZ9F,EAA0BE,EAC1B6F,EAAyBtE,EAAgBC,EAAeuC,EACxDtG,EAAuC6D,EACvCmD,EAAqBQ,OADpBa,OAAUC,oBACUd,KAUvB,IATA,IAAMe,EACFH,EAAgB1G,IAAI,SAAA2C,GAAK,OAAA,IAAImE,WAAW1E,EAASC,GAAO0E,KAAK,KAE1DvE,QAAWqC,SAEZ3C,0BAAC4C,OAAQC,OAERM,kCAEE1D,EAAI,EAAGA,EAAIS,EAAQT,GAAK,EAC/B,IAAK,IAAIqF,EAAI,EAAGA,EAAI3E,EAAO2E,GAAK,EAAG,CACjC,IAAMC,EAAItF,EAAIU,EAAQ2E,EAEtB,GAAa,IADArG,EAAasG,GACV,CACd,IAAMb,EAAOR,0BACRjD,EAAGqE,EAAG/G,EAAG0B,GAAId,EAAa6F,EAAiBZ,GAC3CtD,EAAMqC,IAAQC,EAAQC,GAASM,GAAoBjD,EAAQC,GAC5DuC,EAAQU,GACRc,GAAQ,IACVS,EAAWT,GAAMa,GAAK,IAM9B,OAAOJ,EAGT,SAAgBK,2BACZvG,EAA0BE,EAC1BsG,EAA6BT,EAAyBtE,EACtDC,EAAeuC,EAAgBtG,EAC/B6D,EAAkBmD,EAClBQ,OAFgCa,OAAUC,oBAE1Cd,KAWF,IAVA,IAAMe,EACFH,EAAgB1G,IAAI,SAAA2C,GAAK,OAAA,IAAIyE,WAAWhF,EAASC,GAAO0E,MAAM,KAE3DvE,QAAWqC,SAEZ3C,0BAAC4C,OAAQC,OAERM,kCAGE1D,EAAI,EAAGA,EAAIS,EAAQT,GAAK,EAC/B,IAAK,IAAIqF,EAAI,EAAGA,EAAI3E,EAAO2E,GAAK,EAAG,CACjC,IAAMC,EAAItF,EAAIU,EAAQ2E,EAEtB,GAAa,IADArG,EAAasG,GACV,CACd,IAAMb,EAAOR,0BACRjD,EAAGqE,EAAG/G,EAAG0B,GAAId,EAAa6F,EAAiBZ,GAC3CtD,EAAMqC,IAAQC,EAAQC,GAASM,GAAoBjD,EAAQC,GAC5DuC,EAAQU,GACRc,GAAQ,IACVS,EAAWT,GAAMa,GAAKE,EAAgBF,KAM9C,OAAOJ,WChKOQ,yBACZ1G,EAA2BE,EAC3B6F,EAAyBtE,EAAgBC,EAAeuC,EACxDtG,EAAuC6D,EACvCmD,EAAqBgC,EACrBC,GAaF,QAfGZ,OAAUC,OAIP1E,UAACsF,OAAYC,OAEb1B,qBAAC2B,OAAWC,OAEZC,EACF/G,EAAYtD,SAASmK,EAAWC,EAAU,EAAGtG,gBAK3CwG,EAAW,IAAIC,aAAaP,EAAelG,cAAgB,GAAG0F,KAAK,GAChEpF,EAAI,EAAGA,EAAI+E,EAAgBpF,OAAQK,IAG1C,IAFA,IAAMoG,EAAapG,EAAIN,cAAgB,EACjC4C,EAAOyC,EAAgB/E,GACpBqG,EAAK,EAAGA,EAAK3G,cAAe2G,IAAM,CACzC,IAAMpF,EAAWqB,EAAKK,UAAU0D,GAC1BC,EAASF,EAAkB,EAALC,EAC5BH,EAASI,GAAUrF,EAAS2B,MAC5BsD,EAASI,EAAS,GAAKrF,EAAS6B,SAASxE,EACzC4H,EAASI,EAAS,GAAKrF,EAAS6B,SAAS9B,EAIvC,IAAAuF,0BAACpD,OAAQC,OAGToD,EAAcC,OAAUP,GAAWN,EAAclG,cAAe,IAE/DmB,QAAWqC,SAEZwD,GACJC,eAAgB,eAAgB,cAAe,SAC/CC,aAAcf,EAAYC,GAC1Be,SAAU,gyCAsCDhG,OAASuC,OAAWH,4EAEpBC,OAASC,OAAWF,6FAIL2C,qGAGElG,2QAOEiE,8DACgBlD,EAAS,2DACTC,EAAQ,oGAG9BG,OAASuC,OAAWH,+FAEpBC,OAASC,OAAWF,0XAYlB0C,mfAqB1B,OADqBmB,UACDC,cAChBL,GAAU1H,EAAciH,EAAmBO,aCrIjCQ,sBACZhI,EAA2B2F,GAC7B,OAAOtI,KACH,WAAM,OAAC2C,EAAaiI,MAAM1K,OAAUoI,IAAInI,UAG9C,SAAgB0K,0BACZlI,EAA2BmI,EAAwBxC,GACrD,OAAOtI,KACH,WAAM,OAAA2C,EAAaiI,MAAM1K,OAAUoI,IACxBnI,QACAP,IAAIkL,EAAUhK,IAAI,IAClBC,IAAI,KAGrB,SAASgK,iBACP,MAAwB,UAAjBC,aAGT,SAAsBC,0BAClBtI,EAA2BE,EAA0BgF,EACrDzD,EAAgBC,EAAeuC,EAC/BtG,EAAuC6D,EAAkB+G,EACzD5D,EAAiB6D,EACjB5B,OAFCZ,OAAUC,2BAA8CsC,mBACzD5D,kBAAiB6D,mBACjB5B,8HAEIb,EAAkBb,EAAMuD,OAAO,SAAAnF,GAAQ,OAAAA,EAAKM,OAAS2E,IAIvDH,kBACIM,EAAsBrL,KAAQ,WAClC,IAAMsL,EAAcjC,yBAChB1G,EAAcE,EAAa6F,EAAiBtE,EAAQC,EAAOuC,GAC1D+B,EAAUC,GAAUzE,EAASmD,EAAa6D,EAC3C5B,GAEJ,OAAOb,EAAgB1G,IACnB,SAACuJ,EAAGjD,GAAM,OAAAqC,sBAAsBW,EAAahD,UAIxCkD,QAAQC,IAAIJ,EAAoBrJ,IAAI,SAAArC,GAAQ,OAAAA,EAAK+L,gCAD5DC,EACKzH,SAGLmH,EAAoBO,QAAQ,SAAAjH,GAAK,OAAAA,EAAE5B,yBAET,SAAMJ,EAAa+I,eACrB,OADlBG,EAAoB3H,YACIrB,EAAY6I,eAApCI,EAAkB5H,SAExByH,EAA0BlD,uBACtBoD,EAAmBC,EAAiBpD,EAAiBtE,EAAQC,EAC7DuC,GAAS+B,EAAUC,GAAUzE,EAASmD,oBAG5C,SAAOqE,EAAwB3J,IAC3B,SAAC0J,EAAM/H,GAAM,OAAE+H,OAAMzF,KAAMyC,EAAgB/E,GAAIU,QAAOD,kBAG5D,SAAsB2H,8BAClBpJ,EAA2BE,EAC3BmJ,EAA+BnE,EAAezD,EAAgBC,EAC9DuC,EAAgBtG,EAAuC6D,EACvD+G,EAAoB5D,EAAiB6D,EACrC5B,OAFiBZ,OAAUC,2BAC3BsC,mBAAoB5D,kBAAiB6D,mBACrC5B,gIACIb,EAAkBb,EAAMuD,OAAO,SAAAnF,GAAQ,OAAAA,EAAKM,OAAS2E,IAIvDH,kBACIkB,EAAoBjM,KAAQ,WAChC,IAAMsL,EAAcjC,yBAChB1G,EAAcE,EAAa6F,EAAiBtE,EAAQC,EAAOuC,GAC1D+B,EAAUC,GAAUzE,EAASmD,EAAa6D,EAC3C5B,GAEJ,OAAOb,EAAgB1G,IACnB,SAACuJ,EAAGjD,GACA,OAAAuC,0BAA0BS,EAAaU,EAAkB1D,UAIxDkD,QAAQC,IAAIQ,EAAkBjK,IAAI,SAAA2C,GAAK,OAAAA,EAAE+G,gCADpDQ,EACKhI,SAGL+H,EAAkBL,QAAQ,SAAAjH,GAAK,OAAAA,EAAE5B,yBAEP,SAAMJ,EAAa+I,eACrB,OADlBG,EAAoB3H,YACIrB,EAAY6I,eACd,OADtBI,EAAkB5H,YACU8H,EAAiBN,eAA7CS,EAAsBjI,SAE5BgI,EAAgChD,2BAC5B2C,EAAmBC,EAAiBK,EACpCzD,EAAiBtE,EAAQC,EAAOuC,GAAS+B,EAAUC,GAAUzE,EAC7DmD,oBAGN,SAAO4E,EAA8BlK,IACjC,SAAC0J,EAAMpD,GAAM,OAAErC,KAAMyC,EAAgBJ,GAAIoD,OAAMtH,SAAQC,iBCvG7D,SAAS+H,KAAK9D,GACZ,OAAO9B,KAAK6F,MAAM/D,EAAI,GAGxB,uBAKE,WAAYgE,EAAiBC,GAC3BpL,KAAKqL,cAAgB,IAAIC,MAAMH,GAC/BnL,KAAKuL,kBAAoB,EACzBvL,KAAKoL,gBAAkBA,EAkE3B,OA/DSI,oBAAP,SAAehI,GACbxD,KAAKqL,gBAAgBrL,KAAKuL,kBAAoB/H,EAC9CxD,KAAKyL,KAAKzL,KAAKuL,mBAGVC,oBAAP,WACE,IAAMtH,EAAMlE,KAAKqL,cAAc,GAI/B,OAHArL,KAAK0L,SAAS,EAAG1L,KAAKuL,oBACtBvL,KAAK2L,KAAK,GACV3L,KAAKqL,cAAcrL,KAAKuL,iBAAmB,GAAK,KACzCrH,GAGFsH,kBAAP,WACE,OAAkC,IAA3BxL,KAAKuL,kBAGPC,iBAAP,WACE,OAAOxL,KAAKuL,iBAAmB,GAG1BC,gBAAP,WACE,OAAOxL,KAAKqL,cAAcO,MAAM,EAAG5L,KAAKuL,iBAAmB,IAGtDC,gBAAP,WACE,OAAOxL,KAAKqL,cAAc,IAGpBG,iBAAR,SAAarE,GACX,KAAOA,EAAI,GAAKnH,KAAK6L,KAAKZ,KAAK9D,GAAIA,IACjCnH,KAAK0L,SAASvE,EAAG8D,KAAK9D,IACtBA,EAAI8D,KAAK9D,IAILqE,iBAAR,SAAarE,GACX,KAAO,EAAIA,GAAKnH,KAAKuL,kBAAkB,CACrC,IAAI1D,EAAI,EAAIV,EAIZ,GAHIU,EAAI7H,KAAKuL,kBAAoBvL,KAAK6L,KAAKhE,EAAGA,EAAI,IAChDA,KAEG7H,KAAK6L,KAAK1E,EAAGU,GAChB,MAEF7H,KAAK0L,SAASvE,EAAGU,GACjBV,EAAIU,IAIA2D,uBAAR,SAAmBhJ,GACjB,OAAOxC,KAAKoL,gBAAgBpL,KAAKqL,cAAc7I,KAGzCgJ,iBAAR,SAAahJ,EAAWqF,GACtB,OAAO7H,KAAK8L,WAAWtJ,GAAKxC,KAAK8L,WAAWjE,IAGtC2D,qBAAR,SAAiBhJ,EAAWqF,GAC1B,IAAMvB,EAAItG,KAAKqL,cAAc7I,GAC7BxC,KAAKqL,cAAc7I,GAAKxC,KAAKqL,cAAcxD,GAC3C7H,KAAKqL,cAAcxD,GAAKvB,QC3E5B,SAASyF,4BACLC,EAAoB5G,EAAetB,EAAkBD,EACrDoI,EAA4BC,GAM9B,IALM,IAAA/M,UAAC8D,OAAQC,OAEXiJ,GAAe,EACbC,EAAS/G,KAAKnB,IAAIJ,EAAWmI,EAAoB,GACjDI,EAAOhH,KAAKpB,IAAIH,EAAWmI,EAAqB,EAAGhJ,GAChDqJ,EAAWF,EAAQE,EAAWD,IAAQC,EAAU,CAGvD,IAFA,IAAMC,EAASlH,KAAKnB,IAAIL,EAAWoI,EAAoB,GACjDO,EAAOnH,KAAKpB,IAAIJ,EAAWoI,EAAqB,EAAG/I,GAChDuJ,EAAWF,EAAQE,EAAWD,IAAQC,EAC7C,GAAIP,EAAOxI,IAAI4I,EAAUG,EAAUT,GAAc5G,EAAO,CACtD+G,GAAe,EACf,MAGJ,IAAKA,EACH,MAIJ,OAAOA,EAQT,SAAgBO,wBACZC,EAAwBV,EACxBC,GAMF,IALM,IAAA/M,UAAC8D,OAAQC,OAAO0J,OAEhBC,EAAQ,IAAIrB,QACdvI,EAASC,EAAQ0J,EAAc,SAACzN,GAAY,iBAEvC2E,EAAW,EAAGA,EAAWb,IAAUa,EAC1C,IAAK,IAAID,EAAW,EAAGA,EAAWX,IAASW,EACzC,IAAK,IAAImI,EAAa,EAAGA,EAAaY,IAAgBZ,EAAY,CAChE,IAAM5G,EAAQ8G,EAAOxI,IAAII,EAAUD,EAAUmI,GAIzC5G,EAAQuH,GAKRZ,4BACIC,EAAY5G,EAAOtB,EAAUD,EAAUoI,EACvCC,IACNW,EAAMC,SAAS1H,QAAOxB,MAAOE,WAAUD,WAAUkJ,GAAIf,KAM7D,OAAOa,ECzDT,IAAMG,qBAAsCtK,WAAW7B,IACnD,SAAC1B,OAAC8N,OAAgBC,OACd,OAAE9K,SAAS6K,GAAiB7K,SAAS8K,MAEvCC,mBACFH,qBAAqBnM,IAAI,SAAC1B,GAAqB,cAE7CiO,mBACFJ,qBAAqBnM,IAAI,SAAC1B,GAEK,cAEnC,SAASkO,gBACLC,EAAgBC,EAAiBC,GACnC,IAAMC,EAAWD,EAAcvP,MAAM,GAAK,EAC1C,OACE6C,EAAG0M,EAAc9J,IAAI6J,EAAMzM,EAAGyM,EAAM/J,EAAG8J,GACvC9J,EAAGgK,EAAc9J,IAAI6J,EAAMzM,EAAGyM,EAAM/J,EAAGiK,EAAWH,IAItD,SAASI,yBACLH,EAAiBxN,EAAsBkD,EACvCC,GACF,OACEpC,EAAGiD,MAAMsB,KAAKQ,MAAM0H,EAAMzM,EAAIf,GAAe,EAAGkD,EAAS,GACzDO,EAAGO,MAAMsB,KAAKQ,MAAM0H,EAAM/J,EAAIzD,GAAe,EAAGmD,EAAQ,IAW5D,SAASyK,yBACLL,EAAgBM,EAA0BC,EAC1CC,EAA8BzM,EAAyBtB,EACvDyN,EAA+BO,gBAAAA,KAYjC,IAXM,IAAA5O,UAAC8D,OAAQC,OAMT8K,EACFX,gBAAgBC,EAJUI,yBAC1BE,EAAetI,SAAUvF,EAAckD,EAAQC,GAGAsK,GAG/CS,EADmBvJ,WAAWkJ,EAAetI,SAAU0I,GAElDxL,EAAI,EAAGA,EAAIuL,EAAkBvL,IAAK,CACzC,IAAM0L,EACFR,yBAAyBO,EAAgBlO,EAAckD,EAAQC,GAE7DiL,EAAc5K,eAChB2K,EAAsBpN,EAAGoN,EAAsB1K,EAAGqK,EAClDxM,GAEJ4M,EAAiBvJ,YAEXlB,EAAG0K,EAAsB1K,EAAIzD,EAC7Be,EAAGoN,EAAsBpN,EAAIf,IAE9ByD,EAAG2K,EAAY3K,EAAG1C,EAAGqN,EAAYrN,IAExC,IAAMsN,EACFV,yBAAyBO,EAAgBlO,EAAckD,EAAQC,GAC7DkC,EAAQ0I,EAAapK,IACvB0K,EAAsBtN,EAAGsN,EAAsB5K,EAAGqK,GAEtD,OAAQvI,SAAU2I,EAAgBrK,KAAM3B,WAAW4L,GAAmBzI,SASxE,SAAgBiJ,WACZC,EAAqBpC,EAAwB7K,EAC7CtB,EAAsBwO,EACtBC,GACF,IAAMxQ,EAAWkO,EAAOjO,MAAM,GACxBwP,EAAWN,mBAAmBhL,OAE9BsM,EAAgC,IAAInD,MAAMtN,GAEzC0Q,SAAgBC,UACjBC,EAAYjL,eAAe+K,EAAU3O,EAAcsB,GAEzDoN,EAAkBC,EAAS3B,KACzB3H,MAAOuJ,EACP/K,KAAM3B,WAAWyM,EAAS3B,IAC1BzH,SAAUsJ,GAKZ,IAAK,IAAIC,EAAOpB,EAAW,EAAGoB,GAAQ,IAAKA,EAAM,CAC/C,IAAMC,EAAmB3B,mBAAmB0B,GACtChB,EAAmBT,mBAAmByB,GACxCJ,EAAkBK,KACjBL,EAAkBZ,KACrBY,EAAkBZ,GAAoBF,yBAClCkB,EAAMJ,EAAkBK,GAAmBjB,EAAkB3B,EAC7D7K,EAAStB,EAAcyO,IAM/B,IAASK,EAAO,EAAGA,EAAOpB,IAAYoB,EAAM,CACpCC,EAAmB1B,mBAAmByB,GACtChB,EAAmBV,mBAAmB0B,GACxCJ,EAAkBK,KACjBL,EAAkBZ,KACrBY,EAAkBZ,GAAoBF,yBAClCkB,EAAMJ,EAAkBK,GAAmBjB,EAAkB3B,EAC7D7K,EAAStB,EAAcwO,IAI/B,OAAOE,EC7HT,SAASM,oCACLrI,EAAesI,EAA0B7P,EACzC6M,OAD0CxI,MAAG1C,MAE/C,OAAO4F,EAAMuI,KAAK,SAAC9P,OACX+P,cAAkClD,GAAY1G,SACpD,OAAOnB,gBACIrD,EAAG0C,EAAG0L,EAAsBpO,EAAGoO,EAAsB1L,IAC5DwL,IAQR,SAASG,iBACLC,EAAuBJ,EACvBP,GAUF,OATkCA,EAAkBpM,OAChD,SAACC,EAAQnD,EAAmB6M,OAAlB1G,aAAUF,UAKlB,OAJK2J,oCACGK,EAAeJ,EAAkB1J,EAAU0G,KACjD1J,GAAU8C,GAEL9C,GACN,GAE+BmM,EAAkBtM,OAM1D,IAAMkN,oBAAsB,EAyD5B,SAAgBC,oBACZxB,EAA8ByB,EAC9BC,EACAC,EAAwC1P,EACxC2P,EAA2B/C,EAAsBgD,gBAAtBhD,mBAAsBgD,MAUnD,IATA,IAAMjJ,KAEAmG,EAAQH,wBACVC,EAAgB0C,oBAAqBvB,GAEnCkB,EAAmBW,EAAYA,EAI9BjJ,EAAMvE,OAASuN,IAAsB7C,EAAM+C,SAAS,CAEzD,IAAMtB,EAAOzB,EAAMgD,UAOnB,IAAId,oCACIrI,EAAOsI,EAFXrL,eAAe2K,EAAK1K,KAAM7D,EAAcwP,GAEMjB,EAAK1K,KAAKmJ,IAD5D,CAMA,IAAM5H,EAAYkJ,WACdC,EAAMR,EAAcyB,EAAexP,EAAcyP,EACjDC,GAEErK,EAAQ+J,iBAAiBzI,EAAOsI,EAAkB7J,GAExDuB,EAAMM,MAAM7B,YAAWC,WAGzB,OAAOsB,EClIT,OAAMoJ,eAAiB,QAAS,OAAS,2BAEzC,4DA2BA,OA3B4BjO,eAC1BkO,4BAAA,SAAgBzP,GACd,OAAOA,EAAMX,IAAImQ,eAGnBC,8BAAA,SAAkB/N,GAEd,IAAAT,OACAD,OACAH,OACAO,OACAL,OACAI,OAIF,OACEJ,UACAG,kBACAC,eACAC,cACAP,UACAG,kBACAC,kBACAI,sBAxBsBtB,WCNtB2P,kBACF,0EACEC,mBACF,2EAIJ,SAAgBC,mBAAmBzK,EAAgB0K,GACjD,IAAMC,EAAY,eAAe3K,UAEjC,OAAmB,IAAf0K,EACKH,kBAAoB,SAAWI,EAE/BJ,kBAAoB,QAAQG,MAAgBC,EAMvD,SAAgBC,oBACZ5K,EAAgB6K,EAAoBH,GACtC,IAAMI,GAAkCC,EAAK,MAAOC,IAAM,MAAOC,GAAM,OACjEN,EAAY,eAAe3K,UAEjC,OAAmB,IAAf0K,EACKF,mBAAqB,SAASM,EAAMD,OAAiBF,EAErDH,mBAAqB,QAAQE,MAAcI,EAAMD,OACpDF,WCrBCO,4BAA4BrQ,GAEnC,GAA2B,IAAvBA,EAAMsQ,cAA4C,IAAtBtQ,EAAMuQ,YACpC,OAAQvQ,EAAMsQ,aAActQ,EAAMuQ,aAC7B,GAAoB,MAAhBvQ,EAAM2C,QAAiC,MAAf3C,EAAM4C,MACvC,OAAQ5C,EAAM2C,OAAQ3C,EAAM4C,OAE5B,MAAM,IAAI4N,MACN,+DAIR,SAASC,wBAAwBzQ,GAC/B,OAAoB,MAAhBA,EAAM2C,QAAiC,MAAf3C,EAAM4C,OAExB5C,EAAM2C,OAAQ3C,EAAM4C,QAEpB5C,EAAM0Q,YAAa1Q,EAAM2Q,YAIrC,SAAgBC,aAAa5Q,GAC3B,GAAoC,uCAC/BA,aAAiB6Q,mBACa,sCAC9B7Q,aAAiB8Q,iBACpB,OAAOT,4BAA4BrQ,GAC9B,GAA2B,+BAAeA,aAAiB+Q,UAChE,OAAQ/Q,EAAM2C,OAAQ3C,EAAM4C,OACvB,GAC2B,sCAC9B5C,aAAiBgR,iBACnB,OAAOP,wBAAwBzQ,GAC1B,GAAIA,aAAiBiR,OAC1B,OAAQjR,EAAMrC,MAAM,GAAIqC,EAAMrC,MAAM,IAEpC,MAAM,IAAI6S,MAAM,8BAA8BxQ,OAIlD,SAASkR,uBACLC,EAAoB1R,GACtB,OAAQ0R,EAAa,GAAK1R,GAAiB,EAG7C,SAAgB2R,uBACZC,EAAyB5R,GAC3B,OAAIyR,uBAAuBG,EAAiB5R,GACnC4R,EAGFtM,KAAK6F,MAAMyG,EAAkB5R,GAAgBA,EAAe,EAGrE,IAAM6R,oCACJC,IAAK,MACLC,OAAQ,SACRC,KAAM,OACNC,KAAM,QAGFC,yCACHL,mCAAmCC,KAAM,IAC1C1S,GAACyS,mCAAmCE,QAAS,GAC7C3S,GAACyS,mCAAmCG,MAAO,IAC3C5S,GAACyS,mCAAmCI,MAAO,MAGvCE,wBAA0B,GAC1BC,wBAA0B,EAEhC,SAASC,+BACLC,GACF,GAAkC,iBAAvBA,EAAiC,CAC1C,IAAM/P,EAAS2P,gCAAgCI,GAO/C,OALAlS,KAAQC,OACc,iBAAXkC,EACP,WAAM,MAAA,kDACFgQ,OAAOC,OAAOX,oCACTY,KAAK,iBAAgBH,QAC3B/P,EAWP,OATAnC,KAAQC,OAC0B,iBAAvBiS,GACHA,GAAsBF,yBACtBE,GAAsBH,wBAC1B,WACI,MAAA,sDACIA,gCAA+BC,qCAC5BE,IAERA,EAIX,SAAgBI,gCACZJ,EACAtS,EACAZ,OAACuT,OAAaC,OACVC,EACFR,+BAA+BC,GAEnC,OACEX,uBACIgB,EAAcE,EAA8B7S,GAChD2R,uBACIiB,EAAaC,EAA8B7S,IAInD,SAAgB8S,cAAcvS,GAC5B,OAAOA,aAAiBiR,OAAYjR,EAAQwS,QAAWC,WAAWzS,GAGpE,SAAgB0S,eACZC,EAA0B9T,EAC1B+T,OAD2BC,OAASC,oBACpCF,MAII,IAKFG,EACAC,EACA5N,EACA6N,EACAlQ,EACAC,EAVEP,UAACE,OAGDuQ,OAAiBvQ,EASvB,GAAIuQ,EAViBJ,EAAUD,EAUJ,CAEzBE,EAAUD,EAGV,IAAMK,EAAYN,GAFlBG,EAAUjO,KAAKqO,KAAKL,EAAUG,IAG9B9N,EAAO,EACP6N,EAAO,EACPlQ,EAAOgC,KAAK6F,MAAMuI,EAAY,GAC9BnQ,EAAO6P,GAAWG,EAAUjQ,OACvB,CACLiQ,EAAUH,EAGV,IAAMQ,EAAWP,GAFjBC,EAAUhO,KAAKqO,KAAKP,EAAUK,IAG9B9N,EAAOL,KAAK6F,MAAMyI,EAAW,GAC7BJ,EAAOH,GAAWC,EAAU3N,GAC5BrC,EAAO,EACPC,EAAO,EAiBT,OAAQsQ,iBAdiB/U,KAAQ,WAE/B,IAAIgV,EASJ,OAPEA,EADEX,EACQD,EAAYa,QAAQ,GAAGC,gBAAgBT,EAASD,IAEhDJ,EAAYc,gBAAgBT,EAASD,IAGlCW,MAASH,IAAWxQ,EAAMC,IAAQoC,EAAM6N,IAAQ,EAAG,OAK1CU,WAAY5Q,EAAMC,IAAQoC,EAAM6N,KAG5D,SAAgBW,+BACZC,EACAhV,EACA4D,EACA6D,EACAwN,OAHCC,OAAmBC,OACnBC,OAAwBC,OACxBzL,OAAC1F,OAAMC,OAAOmR,OAAC/O,OAAM6N,OAExB,oBADEa,MACKvV,KAAQ,WACb,IAAI6V,EAAkCP,EAAOJ,gBACxCQ,EAAwBC,IAAwB,GAMrD,OAJIJ,IACFM,EAAqBA,EAAmBtT,WAGnCuT,2BACHD,GAAqBL,EAAmBC,KACtCjR,EAAMC,IAAQoC,EAAM6N,OAI9B,SAAgBoB,2BACZf,EACAzU,EACA4D,OADC6R,OAAgBC,OAChBjO,OAACvD,OAAMC,OAAOyF,OAACrD,OAAM6N,OAExB,OAAO1U,KAAQ,WACb,IAAMiW,EAA4BlB,EAAiBnU,aACnD,OAAOsV,MACFC,cACGF,IACEzR,GAAQuR,EAAiBvR,EAAOC,EAAO,GACvCoC,GAAQmP,EAAgBnP,EAAO6N,EAAO,IACrClQ,EAAOuR,EAAiB,IACpBA,EAAiBvR,EAAOC,EAAO,IACnCoC,EAAOmP,EAAgB,IAAQA,EAAgBnP,EAAO6N,EAAO,MAE/D,IAAKqB,EAAgBC,IACzB9T,SAAS,MAIlB,SASgBkU,eACZ3U,EAAqBnB,OAACgU,OAASC,OAE3BrQ,kBAACE,OAAQC,OACTgS,EAAe9B,EAAUD,EAE3BvM,YAACvD,OAAMC,OAAMoC,OAAM6N,OAsBvB,OAvBerQ,EAAQD,EAEViS,GAEX7R,EAAO,EACPC,EAAO,EACPoC,EAAOL,KAAKQ,MAAM,IAAOqP,EAAejS,EAASC,IACjDqQ,EAAOlO,KAAKQ,MAAM,IAAOqP,EAAejS,EAASC,MAGjDG,EAAOgC,KAAKQ,MAAM,IAAQ,EAAMqP,EAAgBhS,EAAQD,IACxDK,EAAO+B,KAAKQ,MAAM,IAAQ,EAAMqP,EAAgBhS,EAAQD,IACxDyC,EAAO,EACP6N,EAAO,IAUDM,QAPqBhV,KAAQ,WACnC,IAAIoU,EAAcJ,cAAcvS,GAGhC,OAFA2S,EAAce,MAASf,IAAe5P,EAAMC,IAAQoC,EAAM6N,IAAQ,EAAG,MAElDQ,gBAAgBZ,EAASC,MAG7BpQ,SAAUmS,IAAK9R,EAAM+R,KAAM1P,EAAM2P,MAAO9B,EAAM+B,OAAQhS,IAGzE,SAAsBiS,kBAAkBC,sFAEtC,SAAOnL,QAAQC,IAAIkL,EAAQ3U,IAAI,SAAAsT,GAAU,OAAAA,EAAOsB,iBAGlD,SAAgBC,UACZ5Q,EAAYc,EAAgBD,EAAgBgQ,EAC5CC,GACF,oBAF8CD,kBAC5CC,MAEAxQ,MAAON,EAAKM,MACZD,UAAWL,EAAKK,UAAUtE,IAAI,SAAC1B,OAACiG,UAAOxB,SAAM0B,aAAc,OAC3BF,QACAxB,OACA0B,UACE9B,EAAG8B,EAAS9B,EAAImC,EAASiQ,EACzB9U,EAAGwE,EAASxE,EAAI8E,EAAS+P,OAM/D,SAAgBE,WACZnP,EAAed,EAAgBD,EAAgBgQ,EAAaC,GAC9D,oBADiDD,kBAAaC,KAC/C,IAAXjQ,GAA2B,IAAXC,GAA4B,IAAZ+P,GAA6B,IAAZC,EAC5ClP,EAEFA,EAAM7F,IAAI,SAAAiE,GAAQ,OAAA4Q,UAAU5Q,EAAMc,EAAQD,EAAQgQ,EAASC,KAGpE,SAAgBE,mBAAmBhR,EAAYiR,GAC7C,OACE3Q,MAAON,EAAKM,MACZD,UAAWL,EAAKK,UAAUtE,IACtB,SAAC1B,OAACiG,UAAOxB,SAAM0B,aAAc,OAC3BF,QACAxB,OACA0B,UAAW9B,EAAGuS,EAAa,EAAIzQ,EAAS9B,EAAG1C,EAAGwE,EAASxE,OAKjE,SAAgBkV,oBAAoBtP,EAAeqP,GACjD,OAAIA,GAAc,EACTrP,EAEFA,EAAM7F,IAAI,SAAAiE,GAAQ,OAAAgR,mBAAmBhR,EAAMiR,KAGpD,SAAgBE,kBACZvP,EAAevH,EACf4D,EACAC,EAAkBkQ,OAFFjQ,OAAQC,OACvBgT,OAAuBC,OAOpBC,EACFP,WAAWnP,GALVzD,EAASD,EAAQmS,IAAMnS,EAAQsS,WAE/BpS,EAAQF,EAAQoS,KAAOpS,EAAQqS,UAGGrS,EAAQmS,KAAMnS,EAAQoS,MAE7D,OAAIlC,EACK8C,oBAAoBI,EAAalT,GAEjCkT,ECnTX,IAAMC,0BAA2B,EAC3BC,0BAA2B,EAoD3BC,qBACJC,aAAc,cACdzW,aAAc,GACdoQ,WAAY,EACZG,WAAY,KAGRmG,oBAA6C,cAAe,YAC5DC,cACJC,aAAgB,EAAG,GAAI,IACvBC,UAAa,GAAI,KAEbC,kBACJF,aAAgB,GAAM,IAAM,GAC5BC,UAAa,IAETE,mBAA0C,EAAG,EAAG,GAEtD,SAASC,oBAAoBC,GAM3B,GAH2B,OAF3BA,EAASA,GAAUT,qBAERC,eACTQ,EAAOR,aAAe,eAEpBC,mBAAmBQ,QAAQD,EAAOR,cAAgB,EACpD,MAAM,IAAI1F,MACN,wBAAwBkG,EAAOR,mCACXC,oBAK1B,GAH2B,MAAvBO,EAAOjX,eACTiX,EAAOjX,aAAe,IAEpB2W,aAAaM,EAAOR,cAAcS,QAAQD,EAAOjX,cAAgB,EACnE,MAAM,IAAI+Q,MACN,wBAAwBkG,EAAOjX,mCACX2W,aAAaM,EAAOR,mCACpBQ,EAAOR,kBAMjC,GAHyB,MAArBQ,EAAO1G,aACT0G,EAAO1G,WAAa,GAElBuG,iBAAiBG,EAAOR,cAAcS,QAAQD,EAAO1G,YAAc,EACrE,MAAM,IAAIQ,MACN,sBAAsBkG,EAAO1G,iCACTuG,iBAAiBG,EAAOR,mCACxBQ,EAAOR,kBAMjC,GAHyB,MAArBQ,EAAO7G,aACT6G,EAAO7G,WAAa,GAElB2G,kBAAkBG,QAAQD,EAAO7G,YAAc,EACjD,MAAM,IAAIW,MACN,sBAAsBkG,EAAO7G,iCACT2G,uCACAE,EAAOR,kBAGjC,OAAOQ,EAkFT,IAAaE,yBACXhE,gBAAgB,EAChBb,mBAAoB,SACpB8E,sBAAuB,GACvBC,cAAe,GACfzK,eAAgB,GAChBgD,UAAW,IAGA0H,wCAEPnE,gBAAgB,EAChBb,mBAAoB,SACpB8E,sBAAuB,GACvBC,cAAe,GACfzK,eAAgB,GAChBgD,UAAW,GACX3F,iBAAkB,GAClB7D,YAAa,IAGnB,SAASmR,8BAA8BN,GAC9B,IAAAG,0BAAuBC,kBAAezK,mBAAgBgD,cAG7D,GAAIwH,EAAwB,GAAOA,EAAwB,EACzD,MAAM,IAAIrG,MACN,yBAAyBqG,qCAI/B,GAAIC,GAAiB,EACnB,MAAM,IAAItG,MACN,yBAAyBsG,qBAI/B,GAAIzK,EAAiB,GAAOA,EAAiB,EAC3C,MAAM,IAAImE,MACN,0BAA0BnE,qCAIhC,GAAIgD,GAAa,EACf,MAAM,IAAImB,MAAM,qBAAqBnB,OAIzC,SAAS4H,2CACLP,GAEA,IAAAG,0BACAC,kBACAzK,mBACAgD,cACA3F,qBACA7D,gBAGF,GAAIgR,EAAwB,GAAOA,EAAwB,EACzD,MAAM,IAAIrG,MACN,yBAAyBqG,qCAI/B,GAAIC,GAAiB,EACnB,MAAM,IAAItG,MACN,yBAAyBsG,qBAI/B,GAAIzK,EAAiB,GAAOA,EAAiB,EAC3C,MAAM,IAAImE,MACN,0BAA0BnE,qCAIhC,GAAIgD,GAAa,EACf,MAAM,IAAImB,MAAM,qBAAqBnB,OAGvC,GAAI3F,EAAmB,GAAKA,EAAmB,EAC7C,MAAM,IAAI8G,MACN,4BAA4B9G,oCAIlC,GAAI7D,GAAe,GAAKA,EAAc,GACpC,MAAM,IAAI2K,MACN,uBAAuB3K,iCAK/B,uBAGE,WAAYqR,GACVxX,KAAKyX,UAAYD,EAspBrB,OAnpBUE,yCAAR,SAAqCpX,GAO7B,IAAAnB,4BAON,OACEwY,6BACAzW,8BACAG,kBACAC,kCACAC,oCAIImW,gDAAR,SAA4CpX,GAQpC,IAAAnB,4BAQN,OACEwY,6BACAC,iCACA1W,8BACAG,kBACAC,kCACAC,oCAIImW,6DAAR,SAAyDpX,GAUjD,IAAAnB,4BASN,OACEwY,6BACAjW,0BACAR,8BACAG,kBACAC,kCACAC,kCACAE,8BAuCJiW,oCAAA,SACIpX,EAAqB+R,EACrB8E,GAFJ,wBAEIA,MAUI,IAAAhY,kBAAC8D,OAAQC,OACT2U,EAAmCpF,gCACrCJ,EAAoBrS,KAAKyX,UAAU1X,cAAekD,EAAQC,IACxDH,sBAAC8Q,YAAS7Q,YAGV4D,6ZACJkR,uBACAtW,iBACAN,kBACAG,YACAC,oBACAC,oBA4BF,OADAsS,EAAQjS,WAENkW,qBACAtW,eACAN,gBACAG,UACAC,kBACAC,kBACAyB,UACA6U,qCA6BEH,0BAAN,SACIpX,EACA0W,uBAAAA,0KAqBa,OAjBfM,8BAFAN,cAAaE,wBAA4BF,IAInC7X,EAUFa,KAAK+X,wBACDzX,EAAO0W,EAAO3E,mBAAoB2E,EAAOG,uBAV/CW,uBACAtW,iBACAN,kBACAG,YACAC,oBACAC,oBACAyB,YACA6U,qCAKI9U,EAAkBvB,EAAavD,MAA9BgF,OAAQC,UAEM1B,EAAa+I,eAEnB,OAFTjI,EAASsE,SACfpF,EAAaI,aACQkW,EAAmBvN,eAGlB,OAHhB2B,EAAStF,SACfkR,EAAmBlW,aAES2T,mBACvBrU,EAAeG,EAASC,EAAiBC,YAkB9C,OAnBMyW,EAAgBpR,SAEfqR,EACHD,KADcE,EACdF,KAD0BG,EAC1BH,KAD+CI,EAC/CJ,KAOJtR,EAAQuP,kBALJvP,EAAQ4I,oBACR2I,EAAWC,EAAYC,EAAqBC,EAC5CpY,KAAKyX,UAAU1X,aAAciX,EAAOI,cACpCJ,EAAOrK,eAAgBqK,EAAOrH,YAGtB1M,EAAQC,GAAQ2U,EAAkC7U,EAC1DsT,0BAEJpV,EAAcU,UACdP,EAAQO,UACRN,EAAgBM,UAChBL,EAAgBK,cAERqB,SAAQC,QAAOqH,KAAMjI,EAAQ4J,SAAQmM,SAAU3R,UA0BnDgR,+BAAN,SACIpX,EACA0W,uBAAAA,kMAwDoB,OApDtBO,2CADAP,cAAaK,uCAA2CL,IAElD7X,EAAkB+R,aAAa5Q,GAA9B2C,OAAQC,OACT2U,EAAmCpF,gCACrCuE,EAAO3E,mBAAoBrS,KAAKyX,UAAU1X,cACzCkD,EAAQC,IAEPH,EACFkS,eAAe3U,EAAOuX,GADnBhE,YAAS7Q,YAEV4D,EAOF/H,KAAQ,WACJ,IAaFyZ,EAbEnZ,wDACJwY,kBACAjW,gBACAR,kBACAG,YACAC,oBACAC,oBAoBF,OANE+W,EAAoB5W,GAOpBF,aAJmB9C,aAfOwV,+BACxByD,GAAgB1U,EAAQC,GAAQ2U,IAC9B7U,EAAQmS,IAAKnS,EAAQsS,SAAUtS,EAAQoS,KAAMpS,EAAQqS,QACvDgB,0BAaoBtV,UAAWiW,EAAOG,uBAIxCzV,YAAa4W,EACbC,iBAAkBrX,EAClBsX,WAAYnX,EACZoX,mBAAoBnX,EACpBoX,mBAAoBnX,KAvCtBC,iBACAE,gBACA6W,qBACAC,eACAC,uBACAC,0BAsC0BnD,mBACvBgD,EAAkBC,EAAYC,EAAoBC,YAajC,OAdhBV,EAAgBjP,SAEfkP,EACHD,KADcE,EACdF,KAD0BG,EAC1BH,KAD+CI,EAC/CJ,KAOJtR,EAAQuP,kBALJvP,EAAQ4I,oBACR2I,EAAWC,EAAYC,EAAqBC,EAC5CpY,KAAKyX,UAAU1X,aAAciX,EAAOI,cACpCJ,EAAOrK,eAAgBqK,EAAOrH,YAGtB1M,EAAQC,GAAQ2U,EAAkC7U,EAC1DsT,6BAEwBxM,0BACxBtI,EAAcE,EAAagF,EAAOzD,EAAQC,EAC1ClD,KAAKyX,UAAU1X,aAAc8X,EAAkC7U,EAC/DgU,EAAOrK,eAAgBqK,EAAO7Q,YAAa6Q,EAAOhN,iBAClDgN,EAAOI,uBAUX,OAdMuB,EAAgB5P,SAMtB8K,EAAQjS,UACRJ,EAAaI,UACbF,EAAYE,UACZ2W,EAAiB3W,UACjB4W,EAAW5W,UACX6W,EAAmB7W,UACnB8W,EAAmB9W,aAEZ+W,SAuCTjB,yCAAA,SACIpX,EAAqB+R,EACrB8E,GAFJ,wBAEIA,MASI,IAAAhY,kBAAC8D,OAAQC,OACT2U,EAAmCpF,gCACrCJ,EAAoBrS,KAAKyX,UAAU1X,cAAekD,EAAQC,IACxDH,sBACJ8Q,YACA7Q,YAGI4D,gjBACJiE,qBACA3J,kBACAG,YACAC,oBACAC,oBAkCF,OADAsS,EAAQjS,WAENiJ,mBACA3J,gBACAG,UACAC,kBACAC,kBACAyB,UACA6U,qCA8BEH,+BAAN,SACIpX,EACA0W,uBAAAA,sKAkBW,OAdbM,8BAFAN,cAAaE,wBAA4BF,IAGnC7X,EASFa,KAAK4Y,6BACDtY,EAAO0W,EAAO3E,mBAAoB2E,EAAOG,uBAT/CtM,qBACA3J,kBACAG,YACAC,oBACAC,oBACAyB,YACA6U,qCAKI9U,EAAkB8H,EAAiB5M,MAAlCgF,OAAQC,UACI2H,EAAiBN,eAGd,OAHhBA,EAAO3D,SACbiE,EAAiBjJ,aAEW2T,mBACvBrU,EAAeG,EAASC,EAAiBC,YAkB9C,OAnBMyW,EAAgBpR,SAEfqR,EACHD,KADcE,EACdF,KAD0BG,EAC1BH,KAD+CI,EAC/CJ,KAOJtR,EAAQuP,kBALJvP,EAAQ4I,oBACR2I,EAAWC,EAAYC,EAAqBC,EAC5CpY,KAAKyX,UAAU1X,aAAciX,EAAOI,cACpCJ,EAAOrK,eAAgBqK,EAAOrH,YAGtB1M,EAAQC,GAAQ2U,EAAkC7U,EAC1DsT,0BAEJpV,EAAcU,UACdP,EAAQO,UACRN,EAAgBM,UAChBL,EAAgBK,cAERqB,SAAQC,QAAOqH,OAAM8N,SAAU3R,UA0BnCgR,oCAAN,SACIpX,EACA0W,uBAAAA,oMA0DoB,OAtDtBO,2CAFAP,cAAaK,uCAA2CL,IAGlD7X,EAAkB+R,aAAa5Q,GAA9B2C,OAAQC,OACT2U,EAAmCpF,gCACrCuE,EAAO3E,mBAAoBrS,KAAKyX,UAAU1X,cACzCkD,EAAQC,IACPH,EACFkS,eAAe3U,EAAOuX,GADnBhE,YAAS7Q,YAEV4D,EAQF/H,KAAQ,WACJ,IAAAM,wDACJwY,kBACAjW,gBACAR,kBACAG,YACAC,oBACAC,oBACAE,iBAIIoX,EAAsB3E,+BACxByD,GAAgB1U,EAAQC,GAAQ2U,IAC9B7U,EAAQmS,IAAKnS,EAAQsS,SAAUtS,EAAQoS,KAAMpS,EAAQqS,QACvDgB,0BAGEyC,EAA+B5E,+BACjCzS,GAAewB,EAAQC,GAAQ2U,IAC7B7U,EAAQmS,IAAKnS,EAAQsS,SAAUtS,EAAQoS,KAAMpS,EAAQqS,QACvDgB,0BAEEiC,EAAoB5W,EAK1B,OACEF,aALmB9C,aACjBma,EAAoB9X,UAAWiW,EAAOG,uBAKxCzV,YAAa4W,EACbC,iBAAkBrX,EAClBsX,WAAYnX,EACZoX,mBAAoBnX,EACpBoX,mBAAoBnX,EACpBsJ,iBAREhL,2BAA2BiZ,MAlC/BtX,iBACAE,gBACA6W,qBACAC,eACAC,uBACAC,uBACA7N,wBAwC0B0K,mBACvBgD,EAAkBC,EAAYC,EAAoBC,YAajC,OAdhBV,EAAgBjP,SAEfkP,EACHD,KADcE,EACdF,KAD0BG,EAC1BH,KAD+CI,EAC/CJ,KAOJtR,EAAQuP,kBALJvP,EAAQ4I,oBACR2I,EAAWC,EAAYC,EAAqBC,EAC5CpY,KAAKyX,UAAU1X,aAAciX,EAAOI,cACpCJ,EAAOrK,eAAgBqK,EAAOrH,YAGtB1M,EAAQC,GAAQ2U,EAAkC7U,EAC1DsT,6BAEwB1L,8BACxBpJ,EAAcE,EAAamJ,EAAkBnE,EAAOzD,EAAQC,EAC5DlD,KAAKyX,UAAU1X,aAAc8X,EAAkC7U,EAC/DgU,EAAOrK,eAAgBqK,EAAO7Q,YAAa6Q,EAAOhN,iBAClDgN,EAAOI,uBAWX,OAfMuB,EAAgB5P,SAMtB8K,EAAQjS,UACRJ,EAAaI,UACbF,EAAYE,UACZ2W,EAAiB3W,UACjB4W,EAAW5W,UACX6W,EAAmB7W,UACnB8W,EAAmB9W,UACnBiJ,EAAiBjJ,aAEV+W,SAGFjB,oBAAP,WACE1X,KAAKyX,UAAU7V,yBAOJmX,cAAc/B,6HAI3B,GAHMjX,EAAeiX,EAAOjX,aACtBoQ,EAAa6G,EAAO7G,WACpBG,EAAa0G,EAAO1G,WAChB,MAAN0I,GACF,MAAM,IAAIlI,MACN,kJAMa,OADbmI,EAAM5I,oBAAoBtQ,EAAcuQ,EAAYH,MACjC+I,eAAsBlC,EAAOmC,UAAYF,WAElE,OAFMG,EAAaja,SACbka,EAAY,IAAIvX,UAAUsX,EAAYrZ,MACrC,IAAI2X,QAAQ2B,SAMrB,SAAeC,WAAWtC,2HAGxB,GAFMjX,EAAeiX,EAAOjX,aACtBoQ,EAAa6G,EAAO7G,WAChB,MAAN6I,GACF,MAAM,IAAIlI,MACN,kJAMa,OADbmI,EAAM/I,mBAAmBnQ,EAAcoQ,MACpB+I,eAAsBlC,EAAOmC,UAAYF,WAElE,OAFMG,EAAaja,SACboa,EAAS,IAAIxJ,OAAOqJ,EAAYrZ,MAC/B,IAAI2X,QAAQ6B,SAerB,SAAsBC,KAAKxC,uBAAAA,mGAGzB,MAA4B,cAD5BA,EAASD,oBAAoBC,IAClBR,gBACF8C,WAAWtC,IACe,gBAAxBA,EAAOR,gBACTuC,cAAc/B,OAEd,mBCrgCKyC,QACZC,EACAnb,EAA4Dob,GAO9D,IANA,IAAMC,EAAMF,EAAOG,WAAW,MAE1BC,EAAM,EAEJC,EAAY,GAAK,EAAI1U,KAAK2U,GADlB,EAAA,GAERC,EAAON,EAAO,EAAI,EAAI,EACnB7Y,GAAK6Y,EAAM7Y,GAAK6Y,EAAM7Y,GAAKmZ,EAClC,IAAK,IAAIzW,GAAKmW,EAAMnW,GAAKmW,EAAMnW,GAAKyW,EAAM,CAGxCH,GADIC,EAAY1U,KAAK6U,MAAM1W,EAAIA,EAAI1C,EAAIA,OAI3C,IAASA,GAAK6Y,EAAM7Y,GAAK6Y,EAAM7Y,GAAKmZ,EAClC,IAASzW,GAAKmW,EAAMnW,GAAKmW,EAAMnW,GAAKyW,EAClCL,EAAIO,YAAcJ,EACd1U,KAAK6U,MAAM1W,EAAIA,EAAI1C,EAAIA,OAA4BgZ,EAAMH,EAC7DC,EAAIQ,UAAU7b,EAAOiF,EAAG1C,GAG5B8Y,EAAIO,YAAc,ECnBpB,IAAME,qBAQN,SAASC,WACP,MAAQ,iCAAiCC,KAAKC,UAAUC,WAG1D,SAASC,qBACLvb,EACA4D,EAAiD4X,EACjDC,OAFCC,UAAeC,WACfC,UAAeC,WAElB,GAAIH,IAAWE,GAAUD,IAAYE,EACnC,MAAM,IAAIlK,MAAM,iCAAiC6J,qBAC7CE,MAAUC,OAAYF,qBAAwBG,MAAUC,GAIhE,SAASC,qBAAqBvB,GAC5B,IAAME,EAAMF,EAAOG,WAAW,MAC9BD,EAAIsB,OAAO,EAAG,GACdtB,EAAIuB,WAAWzB,EAAOxW,MAAO,GAG/B,SAASkY,oBACLxB,EAA+Brb,EAC/B8c,GACFzB,EAAI0B,yBAA2BD,EAC/BzB,EAAIQ,UAAU7b,EAAO,EAAG,GAG1B,SAASgd,wBAEP,OADwBC,SAASC,cAAc,UAIjD,SAASC,6BAA6B3O,GAIpC,OAHKsN,kBAAkBtN,KACrBsN,kBAAkBtN,GAAMwO,yBAEnBlB,kBAAkBtN,GAG3B,SAAS4O,yBACLpd,EAAkBqd,EAAoBlC,GACjC,IAAAzW,WAAQC,UACT0W,EAAMF,EAAOG,WAAW,MAC9BH,EAAOxW,MAAQA,EACfwW,EAAOzW,OAASA,EAChB2W,EAAIiC,UAAU,EAAG,EAAG3Y,EAAOD,GAC3B2W,EAAIkC,OACAxB,WACFb,QAAQC,EAAQnb,EAAOqd,IAGtBhC,EAAY3P,OAAS,QAAQ2R,QAC9BhC,EAAIQ,UAAU7b,EAAO,EAAG,EAAG2E,EAAOD,IAEpC2W,EAAImC,UAGN,SAASC,kCACLzd,EAAkBqd,EAClBK,GACF,IAAMvC,EAASgC,6BAA6BO,GAM5C,OALmB,IAAfL,EACFM,oBAAoB3d,EAAOmb,GAE3BiC,yBAAyBpd,EAAOqd,EAAYlC,GAEvCA,EAGT,SAASwC,oBAAoB3d,EAAkBmb,GACtC,IAAAxW,UAAOD,WACdyW,EAAOxW,MAAQA,EACfwW,EAAOzW,OAASA,EACJyW,EAAOG,WAAW,MAE1BO,UAAU7b,EAAO,EAAG,EAAG2E,EAAOD,GAKpC,SAASkZ,wBAAwB5d,EAAkBmb,GACjDA,EAAOxW,MAAQ3E,EAAM2E,MACrBwW,EAAOzW,OAAS1E,EAAM0E,OACVyW,EAAOG,WAAW,MAE1BuC,aAAa7d,EAAO,EAAG,GAG7B,SAAS8d,iCACL9d,EAAkB+d,GACpB,IAAM5C,EAASgC,6BAA6BY,GAG5C,OAFAH,wBAAwB5d,EAAOmb,GAExBA,EAkCT,SAAgB6C,OACZC,EAEAC,EAMAC,EAMAC,EAAqBC,GACvB,gBAbEH,GACEI,EAAG,EACHC,EAAG,EACHnY,EAAG,EACHX,EAAG,iBAEL0Y,GACEG,EAAG,EACHC,EAAG,EACHnY,EAAG,EACHX,EAAG,mBAEL2Y,mBAAqBC,GAA2B,IAC9CtR,MAAMyR,QAAQP,IACsB,IAApCA,EAAyBra,OAC3B,OAAO,KAGT,IAAI6a,EAUE7d,GAHJ6d,EAHG1R,MAAMyR,QAAQP,GAGeA,GAFCA,OAK5BtZ,UAAOD,WACRga,EAAQ,IAAIC,kBAAkBha,EAAQD,EAAS,GAErD,SAASka,EACLF,EAA0BG,EAAaC,EAAgBna,EACvDoa,EAAgBC,gBAAAA,GAAgBV,EAAG,EAAGC,EAAG,IAAKnY,EAAG,IAAKX,EAAG,MAC3D,IAAK,IAAIxB,GAAK8a,EAAQ9a,GAAK8a,EAAQ9a,IACjC,IAAK,IAAIqF,GAAKyV,EAAQzV,GAAKyV,EAAQzV,IACjC,GAAU,IAANrF,GAAiB,IAANqF,EAAS,CACtB,IAAMC,GAAKsV,EAAM5a,GAAKU,GAASma,EAASxV,GACxCoV,EAAM,EAAInV,EAAI,GAAKyV,EAAMV,EACzBI,EAAM,EAAInV,EAAI,GAAKyV,EAAMT,EACzBG,EAAM,EAAInV,EAAI,GAAKyV,EAAM5Y,EACzBsY,EAAM,EAAInV,EAAI,GAAKyV,EAAMvZ,GAMjC,SAASwZ,EACLC,EACAL,EACAC,EACAna,EACA0Z,EACAU,gBADAV,GAA2B,iBAC3BU,KAGF,IADA,IAAII,EAAyB,EACpBlb,GAAK8a,EAAQ9a,GAAK8a,EAAQ9a,IACjC,mBAASqF,GACP,GAAU,IAANrF,GAAiB,IAANqF,EAAS,CACtB,IAAM8V,GAAKP,EAAM5a,GAAKU,GAASma,EAASxV,GACnC+U,EAAc3N,KAAK,SAAAlC,GAAM,OAAAA,IAAO0Q,EAAiBE,OACpDD,GAA0B,KAJvB7V,GAAKyV,EAAQzV,GAAKyV,EAAQzV,MAA1BA,GASX,OAAO6V,EAAyB,EAGlC,IAAK,IAAIlb,EAAI,EAAGA,EAAIS,EAAQT,GAAK,EAC/B,mBAASqF,GACP,IAAMC,EAAItF,EAAIU,EAAQ2E,EACtBoV,EAAM,EAAInV,EAAI,GAAK4U,EAAWG,EAC9BI,EAAM,EAAInV,EAAI,GAAK4U,EAAWI,EAC9BG,EAAM,EAAInV,EAAI,GAAK4U,EAAW/X,EAC9BsY,EAAM,EAAInV,EAAI,GAAK4U,EAAW1Y,EAC9B,mBAASmD,GACP,GAAIyV,EAAc3N,KACV,SAAAlC,GAAM,OAAAA,IAAOiQ,EAA8B7V,GAAGoD,KAAKzC,KAAK,CAC9DmV,EAAM,EAAInV,GAAK2U,EAAWI,EAC1BI,EAAM,EAAInV,EAAI,GAAK2U,EAAWK,EAC9BG,EAAM,EAAInV,EAAI,GAAK2U,EAAW9X,EAC9BsY,EAAM,EAAInV,EAAI,GAAK2U,EAAWzY,EAC9B,IAAM4Z,EAAaJ,EACfR,EAA8B7V,GAAGoD,KAAM/H,EAAGqF,EAAG3E,EAC7C0Z,GACAD,GAAena,EAAI,GAAK,GAAKA,EAAI,EAAIS,GAAU4E,EAAI,GAAK,GACxDA,EAAI,EAAI3E,GAAS0a,GACnBT,EAAWF,EAAOza,EAAGqF,EAAG3E,EAAO,KAZ5BiE,EAAI,EAAGA,EAAI6V,EAA8B7a,OAAQgF,MAAjDA,IANFU,EAAI,EAAGA,EAAI3E,EAAO2E,GAAK,IAAvBA,GAyBX,OAAO,IAAIwJ,UAAU4L,EAAO/Z,EAAOD,GAGrC,IAAM4a,sBACH,IAAK,GAAI,MAAO,IAAK,GAAI,MAAO,IAAK,GAAI,MAAO,IAAK,GAAI,MACzD,IAAK,GAAI,MAAO,IAAK,GAAI,MAAO,IAAK,GAAI,KAAO,IAAK,IAAK,KAC1D,IAAK,IAAK,KAAM,IAAK,IAAK,KAAM,IAAK,IAAK,KAAM,IAAK,IAAK,KAC1D,IAAK,IAAK,KAAM,IAAK,IAAK,KAAM,GAAI,IAAK,KAAO,GAAI,IAAK,MACzD,GAAI,IAAK,MAAO,GAAI,IAAK,MAAO,GAAI,IAAK,MAAO,GAAI,IAAK,MACzD,GAAI,IAAK,MAAO,GAAI,IAAK,MAAO,GAAI,IAAK,MAAO,GAAI,GAAI,MAoB3D,SAAgBC,kBACZjT,EACAkT,GAEF,gBAFEA,uBAEEzS,MAAMyR,QAAQlS,IAAiD,IAA5BA,EAAiB1I,OACtD,OAAO,KAYT,IATA,IAAI6b,EAME7e,GAFJ6e,EAHG1S,MAAMyR,QAAQlS,GAGaA,GAFCA,OAI1B3H,UAAOD,WACRga,EAAQ,IAAIC,kBAAkBha,EAAQD,EAAS,GAE5CT,EAAI,EAAGA,EAAIS,EAASC,IAASV,EAAG,CAEvC,IAAMqF,EAAQ,EAAJrF,EACVya,EAAMpV,EAAI,GAAK,IACfoV,EAAMpV,EAAI,GAAK,IACfoV,EAAMpV,EAAI,GAAK,IACfoV,EAAMpV,EAAI,GAAK,IACf,IAAK,IAAIV,EAAI,EAAGA,EAAI6W,EAA4B7b,OAAQgF,IAAK,CAC3D,IAAM8W,EAASD,EAA4B7W,GAAGoD,KAAK/H,GACnD,IAAgB,IAAZyb,EAAe,CACjB,IAAMV,EAAQQ,EAAWE,GACzB,IAAKV,EACH,MAAM,IAAIzM,MAAM,uCAAuCmN,GAEzDhB,EAAMpV,EAAI,GAAK0V,EAAM,GACrBN,EAAMpV,EAAI,GAAK0V,EAAM,GACrBN,EAAMpV,EAAI,GAAK0V,EAAM,GACrBN,EAAMpV,EAAI,GAAK,MAIrB,OAAO,IAAIwJ,UAAU4L,EAAO/Z,EAAOD,GAGrC,IAAMib,cACJC,QAAS,UACTC,YAAa,eACb5f,KAAM,OACN6f,eAAgB,oBAuBlB,SAAgBC,SACZ5E,EAA2Bnb,EAAkBggB,EAC7CC,EAAmBC,EAAoBvL,gBAAvCsL,mBAAmBC,kBAAoBvL,MACnC,IAAA/T,kBAAC8D,OAAQC,OACfwW,EAAOxW,MAAQA,EACfwW,EAAOzW,OAASA,EAEhB,IAAM2W,EAAMF,EAAOG,WAAW,MAS9B,GARAD,EAAIkC,OACA5I,GACF+H,qBAAqBvB,GAGvBE,EAAIQ,UAAU7b,EAAO,EAAG,GAExBqb,EAAIO,YAAcqE,EACdD,EAAW,CACb7D,sBAAsBxX,QAAOD,UAASsb,EAAW,QAAS,QAE1D,IAEMH,EAAcpC,kCAFPK,iCAAiCkC,EAAWL,aAAa1f,MAG5DigB,EAAgBP,aAAaE,aACvCxE,EAAIQ,UAAUgE,EAAa,EAAG,EAAGlb,EAAOD,GAE1C2W,EAAImC,UAyBN,SAAgB2C,kBACZhF,EAA2Bnb,EAAkBggB,EAC7CC,EAAmBC,EAAoBvL,EACvCyL,gBADAH,mBAAmBC,kBAAoBvL,mBACvCyL,MACI,IAAAxf,kBAAC8D,OACPyX,sBAAsBxX,WAAOD,UAASsb,EAAW,QAAS,QAE1D,IACMH,EAAcpC,kCADPK,iCAAiCkC,EAAWL,aAAa1f,MAE5DigB,EAAgBP,aAAaE,aAEvC1E,EAAOxW,MAAQkb,EAAYlb,MAC3BwW,EAAOzW,OAASmb,EAAYnb,OAE5B,IAAM2W,EAAMF,EAAOG,WAAW,MAC9BD,EAAIkC,OACA5I,GACF+H,qBAAqBvB,GAGvB,IAAMkF,EACFlD,6BAA6BwC,aAAaG,gBACxCQ,EAAqBD,EAAgB/E,WAAW,MACtD+E,EAAgB1b,MAAQkb,EAAYlb,OAAS,EAAMyb,GACnDC,EAAgB3b,OAASmb,EAAYnb,QAAU,EAAM0b,GACrDE,EAAmBzE,UACfgE,EAAa,EAAG,EAAGA,EAAYlb,MAAOkb,EAAYnb,OAAQ,EAAG,EAC7D2b,EAAgB1b,MAAO0b,EAAgB3b,QAC3C2W,EAAIkF,uBAAwB,EAC5BlF,EAAIQ,UACAwE,EAAiB,EAAG,EAAGA,EAAgB1b,MAAO0b,EAAgB3b,OAAQ,EACtE,EAAGyW,EAAOxW,MAAOwW,EAAOzW,QAG5B,IAAK,IAAIT,EAAI,EAAGA,EAAIoc,EAAgB1b,MAAOV,IACzCoX,EAAImF,YACJnF,EAAIoF,YAAc,UAClBpF,EAAIqF,OAAON,EAAiBnc,EAAG,GAC/BoX,EAAIsF,OAAOP,EAAiBnc,EAAGkX,EAAOzW,QACtC2W,EAAIuF,SAKN,IAAS3c,EAAI,EAAGA,EAAIoc,EAAgB3b,OAAQT,IAC1CoX,EAAImF,YACJnF,EAAIoF,YAAc,UAClBpF,EAAIqF,OAAO,EAAGN,EAAiBnc,GAC/BoX,EAAIsF,OAAOxF,EAAOxW,MAAOyb,EAAiBnc,GAC1CoX,EAAIuF,SAGNvF,EAAIO,YAAc,EAAMqE,EACxB5E,EAAIQ,UAAU7b,EAAO,EAAG,EAAG6f,EAAYlb,MAAOkb,EAAYnb,QAC1D2W,EAAImC,UAGN,SAASqD,iBACLC,EACAC,GACF,IAIMC,EACFlD,iCALwBE,OACxB8C,GAA0BxC,EAAG,EAAGC,EAAG,EAAGnY,EAAG,EAAGX,EAAG,MAC9C6Y,EAAG,EAAGC,EAAG,EAAGnY,EAAG,EAAGX,EAAG,IAGgCka,aAAa1f,MACvE,OAAuB,IAAnB8gB,EACKC,EAEAvD,kCACHuD,EAAgBD,EAAgBpB,aAAaE,aAwBrD,SAAgBoB,gBACZ9F,EAA2Bnb,EAC3B8gB,EACAI,EAA0BH,EAAoBpM,gBAA9CuM,kBAA0BH,kBAAoBpM,MAChD,IAAMwM,EAAe1D,kCACjBzd,EAAOkhB,EAAsBvB,aAAaC,SAC9CzE,EAAOxW,MAAQwc,EAAaxc,MAC5BwW,EAAOzW,OAASyc,EAAazc,OAE7B,IAAM2W,EAAMF,EAAOG,WAAW,MAE9B,GAAIvO,MAAMyR,QAAQsC,IACqB,IAAnCA,EAAwBld,OAC1ByX,EAAIQ,UAAUsF,EAAc,EAAG,OAFjC,CAMA,IAAMC,EAAaP,iBAAiBC,EAAyBC,GAE7D1F,EAAIkC,OACA5I,GACF+H,qBAAqBvB,GAGjB,IAAAva,kBAAC8D,OAAQC,OACf0W,EAAIQ,UAAU7b,EAAO,EAAG,EAAG2E,EAAOD,GAMlCmY,oBAAoBxB,EAAK+F,EAAY,kBAMrCvE,oBAAoBxB,EAAK8F,EAAc,oBACvC9F,EAAImC,WAGN,SAAS6D,mBACL5B,EACA6B,EAA6BP,GAC/B,IAIMC,EACFlD,iCALwBE,OACxByB,GAA8BnB,EAAG,EAAGC,EAAG,EAAGnY,EAAG,EAAGX,EAAG,IAClD6Y,EAAG,EAAGC,EAAG,EAAGnY,EAAG,EAAGX,EAAG,MAAM,EAAM6b,GAGoB3B,aAAa1f,MACvE,OAAuB,IAAnB8gB,EACKC,EAEAvD,kCACHuD,EAAgBD,EAAgBpB,aAAaE,aA2BrD,SAAgB0B,aACZpG,EAA2Bnb,EAC3BsM,EACAkV,EAA4BN,EAA0BH,EACtDpM,gBADA6M,GAAqB,EAAG,iBAAIN,kBAA0BH,kBACtDpM,MACF,IAAMwM,EAAe1D,kCACjBzd,EAAOkhB,EAAsBvB,aAAaC,SAC9CzE,EAAOxW,MAAQwc,EAAaxc,MAC5BwW,EAAOzW,OAASyc,EAAazc,OAE7B,IAAM2W,EAAMF,EAAOG,WAAW,MAE9B,GAAIvO,MAAMyR,QAAQlS,IAAiD,IAA5BA,EAAiB1I,OACtDyX,EAAIQ,UAAUsF,EAAc,EAAG,OADjC,CAIA,IAAMM,EACFJ,mBAAmB/U,EAAkBkV,EAAmBT,GAE5D1F,EAAIkC,OACA5I,GACF+H,qBAAqBvB,GAGjB,IAAAva,kBAAC8D,OAAQC,OACf0W,EAAIQ,UAAU7b,EAAO,EAAG,EAAG2E,EAAOD,GAMlCmY,oBAAoBxB,EAAKoG,EAAc,kBAMvC5E,oBAAoBxB,EAAK8F,EAAc,oBACvC9F,EAAImC,eCrlBOkE,eACX,YACA,aACA,uBACA,sBACA,wBACA,uBACA,uBACA,sBACA,wBACA,uBACA,YACA,aACA,cACA,aACA,uBACA,sBACA,wBACA,uBACA,uBACA,sBACA,wBACA,uBACA,YACA,cCvCIC,QAAU"}